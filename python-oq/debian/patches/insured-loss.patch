--- /dev/null
+++ b/demos/probabilistic_event_based_risk/ins_config.gem
@@ -0,0 +1,136 @@
+[general]
+
+CALCULATION_MODE = Event Based
+
+# NOTE: The order of the vertices is to be kept!!!
+# lat, lon of polygon vertices (in clock or counter-clock wise order)
+REGION_VERTEX = 38.30, 15.40, 38.30, 15.63, 38.01, 15.63, 38.01, 15.40
+# degrees
+REGION_GRID_SPACING = 0.05
+
+[HAZARD]
+
+DEPTHTO1PT0KMPERSEC = 100.0
+VS30_TYPE = measured
+SOURCE_MODEL_LT_RANDOM_SEED = 23
+GMPE_LT_RANDOM_SEED = 5
+
+# NRML serialization of gmf-* files
+SAVE_GMFS = false
+
+GMF_RANDOM_SEED = 3
+
+# file containing erf logic tree structure
+SOURCE_MODEL_LOGIC_TREE_FILE = source_model_logic_tree.xml
+# file containing gmpe logic tree structure
+GMPE_LOGIC_TREE_FILE = gmpe_logic_tree.xml
+# output directory - relative to this file
+OUTPUT_DIR = computed_output
+
+
+# moment magnitude (Mw)
+MINIMUM_MAGNITUDE = 5.0
+# years
+INVESTIGATION_TIME = 50.0
+# bin width of the magnitude frequency distribution
+WIDTH_OF_MFD_BIN = 0.1
+
+
+# (Average Horizontal, Average Horizontal (GMRotI50), Random Horizontal, Greater of Two Horz., Vertical)
+COMPONENT = Average Horizontal (GMRotI50)
+# (PGA (g), PGD (cm), PGV (cm/s), SA (g), IA (m/s), RSD (s))
+INTENSITY_MEASURE_TYPE = PGA
+# seconds, used only for Spectral Acceleration
+PERIOD = 0.0
+# in percent
+DAMPING = 5.0
+#(in the same units of the intensity measure type)
+# TODO make it a comma separated list and adapt code (CalculatorConfigHelper.makeArbitrarilyDiscretizedFunc())
+INTENSITY_MEASURE_LEVELS = 0.005, 0.007, 0.0098, 0.0137, 0.0192, 0.0269, 0.0376, 0.0527, 0.0738, 0.103, 0.145, 0.203, 0.284, 0.397, 0.556, 0.778, 1.09, 1.52, 2.13
+# (None, 1 Sided, 2 Sided)
+GMPE_TRUNCATION_TYPE = 2 Sided
+# (1,2,3,...)
+TRUNCATION_LEVEL = 1
+# (Total, Inter-Event, Intra-Event, None (zero), Total (Mag Dependent), Total (PGA Dependent), Intra-Event (Mag Dependent))
+STANDARD_DEVIATION_TYPE = Total
+# (m/s)
+REFERENCE_VS30_VALUE = 760.0
+# The depth to where shear-wave velocity = 2.5 km/sec.
+# Cambpell basin depth. Measure is (km)
+REFERENCE_DEPTH_TO_2PT5KM_PER_SEC_PARAM = 5.0
+
+# Rock, Deep-Soil
+SADIGH_SITE_TYPE = Rock
+# if true compute ground motion fields using correlated model of Jayaram and Baker 2009
+GROUND_MOTION_CORRELATION = false
+
+# true or false
+INCLUDE_AREA_SOURCES = false
+# (Point Sources, Line Sources (random or given strike), Cross Hair Line Sources, 16 Spoked Line Sources)
+TREAT_AREA_SOURCE_AS = Point Sources
+# degrees
+AREA_SOURCE_DISCRETIZATION = 0.1
+# (W&C 1994 Mag-Length Rel.)
+AREA_SOURCE_MAGNITUDE_SCALING_RELATIONSHIP = W&C 1994 Mag-Length Rel.
+
+
+# true or false
+INCLUDE_GRID_SOURCES = false
+# (Point Sources, Line Sources (random or given strike), Cross Hair Line Sources, 16 Spoked Line Sources)
+TREAT_GRID_SOURCE_AS = Point Sources
+# (W&C 1994 Mag-Length Rel.)
+GRID_SOURCE_MAGNITUDE_SCALING_RELATIONSHIP = W&C 1994 Mag-Length Rel.
+
+
+# true or false
+INCLUDE_FAULT_SOURCE = true
+# km
+FAULT_RUPTURE_OFFSET = 5.0
+# km
+FAULT_SURFACE_DISCRETIZATION = 1.0
+# (W&C 1994 Mag-Length Rel.)
+FAULT_MAGNITUDE_SCALING_RELATIONSHIP = W&C 1994 Mag-Length Rel.
+FAULT_MAGNITUDE_SCALING_SIGMA = 0.0
+# (rupture length/rupture width)
+RUPTURE_ASPECT_RATIO = 1.5
+# (Only along strike ( rupture full DDW), Along strike and down dip, Along strike & centered down dip)
+RUPTURE_FLOATING_TYPE = Along strike and down dip
+
+
+# true or false
+INCLUDE_SUBDUCTION_FAULT_SOURCE = false
+# km
+SUBDUCTION_FAULT_RUPTURE_OFFSET = 10.0
+# km
+SUBDUCTION_FAULT_SURFACE_DISCRETIZATION = 10.0
+# (W&C 1994 Mag-Length Rel.)
+SUBDUCTION_FAULT_MAGNITUDE_SCALING_RELATIONSHIP = W&C 1994 Mag-Length Rel.
+SUBDUCTION_FAULT_MAGNITUDE_SCALING_SIGMA = 0.0
+# (rupture length/rupture width)
+SUBDUCTION_RUPTURE_ASPECT_RATIO = 1.5
+# (Only along strike ( rupture full DDW), Along strike and down dip, Along strike & centered down dip)
+SUBDUCTION_RUPTURE_FLOATING_TYPE = Along strike and down dip
+
+
+# (used if Event Based approach is chosen)
+NUMBER_OF_LOGIC_TREE_SAMPLES = 1
+# (used if probabilistic event based approach is chosen)
+NUMBER_OF_SEISMICITY_HISTORIES = 5
+
+[RISK]
+
+# file containing the exposure in nrml format
+EXPOSURE = ins_exposure.xml
+
+# file containing the vulnerability functions
+VULNERABILITY = ins_vulnerability_model.xml
+
+# file containing the hazard curves in nrml format
+# HAZARD_CURVES = hazard_curves.xml
+
+LOSS_CURVES_OUTPUT_PREFIX = loss_curves
+
+LOSS_HISTOGRAM_BINS = 10
+
+INSURED_LOSSES = True
+
--- /dev/null
+++ b/demos/probabilistic_event_based_risk/ins_exposure.xml
@@ -0,0 +1,41 @@
+<?xml version="1.0"?>
+<nrml xmlns="http://openquake.org/xmlns/nrml/0.3" xmlns:gml="http://www.opengis.net/gml" gml:id="nrml">
+    <exposureModel gml:id="ep">
+    <exposureList gml:id="Messina" stcoType="aggregated" stcoUnit="USD" assetCategory="buildings">
+    <gml:description>Collection of existing building in the region of Messina, Italy</gml:description>
+	<assetDefinition gml:id="a1">
+		<site>
+			<gml:Point srsName="epsg:4326">
+			<gml:pos>15.48 38.09</gml:pos>
+			</gml:Point>
+		</site>
+		<deductible>40</deductible>
+		<limit>125</limit>
+		<stco>3000</stco>
+		<taxonomy>RM</taxonomy>
+	</assetDefinition>
+	<assetDefinition gml:id="a2">
+		<site>
+			<gml:Point srsName="epsg:4326">
+				<gml:pos>15.56 38.17</gml:pos>
+			</gml:Point>
+		</site>
+        <deductible>15</deductible>
+        <limit>50</limit>
+		<stco>2000</stco>
+		<taxonomy>RC</taxonomy>
+	</assetDefinition>
+	<assetDefinition gml:id="a3">
+		<site>
+			<gml:Point srsName="epsg:4326">
+			<gml:pos>15.48 38.25</gml:pos>
+			</gml:Point>
+		</site>
+        <deductible>13</deductible>
+        <limit>24</limit>
+		<stco>1000</stco>
+		<taxonomy>RM</taxonomy>
+	</assetDefinition>
+</exposureList>
+</exposureModel>
+</nrml>
\ No newline at end of file
--- /dev/null
+++ b/demos/probabilistic_event_based_risk/ins_vulnerability_model.xml
@@ -0,0 +1,16 @@
+<?xml version="1.0"?>
+<nrml xmlns="http://openquake.org/xmlns/nrml/0.3" xmlns:gml="http://www.opengis.net/gml" gml:id="nrml">
+	<vulnerabilityModel>
+		<discreteVulnerabilitySet vulnerabilitySetID="Messina" assetCategory="buildings" lossCategory="economic_loss">
+			<IML IMT="PGA">0.001 0.2 0.3 0.5 0.7</IML>
+		<discreteVulnerability vulnerabilityFunctionID="RM" probabilisticDistribution="LN">
+				<lossRatio>0.05 0.1 0.2 0.4 0.8</lossRatio>
+				<coefficientsVariation>0.0 0.0 0.0 0.0 0.0</coefficientsVariation>
+		</discreteVulnerability>
+		<discreteVulnerability vulnerabilityFunctionID="RC" probabilisticDistribution="LN">
+				<lossRatio>0.035 0.07 0.14 0.28 0.56</lossRatio>
+				<coefficientsVariation>0.0 0.0 0.0 0.0 0.0</coefficientsVariation>
+		</discreteVulnerability>
+		</discreteVulnerabilitySet>
+	</vulnerabilityModel>
+</nrml>
\ No newline at end of file
--- a/openquake/calculators/risk/event_based/core.py
+++ b/openquake/calculators/risk/event_based/core.py
@@ -161,15 +161,12 @@
             point = self.job_ctxt.region.grid.point_at(site)
             gmvs = self._get_gmvs_at(general.hazard_input_site(
                     self.job_ctxt, site))
-
             gmf = {"IMLs": gmvs, "TSES": self._tses(),
                     "TimeSpan": self._time_span()}
-
             assets = general.BaseRiskCalculator.assets_at(
                 self.job_ctxt.job_id, site)
 
             for asset in assets:
-
                 # loss ratios, used both to produce the curve
                 # and to aggregate the losses
                 loss_ratios = self.compute_loss_ratios(asset, gmf)
@@ -190,6 +187,14 @@
                                 self.job_ctxt.job_id, point.column,
                                 point.row, loss_curve, asset, loss_poe)
 
+                    if self.job_ctxt.params.get("INSURED_LOSSES"):
+                        insured_curve = general.compute_insured_loss_curve(
+                            asset, loss_curve)
+                        key = kvs.tokens.insured_loss_curve_key(
+                            self.job_ctxt.job_id, point.row, point.column,
+                            asset.asset_ref)
+                        kvs.get_client().set(key, insured_curve.to_json())
+
         return aggregate_curve.losses
 
     def _compute_bcr(self, block_id):
--- a/openquake/calculators/risk/general.py
+++ b/openquake/calculators/risk/general.py
@@ -292,10 +292,15 @@
                 self.job_ctxt.params["LOSS_CURVES_OUTPUT_PREFIX"],
                 self.job_ctxt.job_id,
                 block_id)
+        elif kwargs['curve_mode'] == 'insured_loss_curve':
+            serialize_filename = "%s-insured-loss-block=#%s-block#%s.xml" % (
+                'insured_loss_curves',
+                self.job_ctxt.job_id,
+                block_id)
 
         serialize_path = os.path.join(self.job_ctxt.base_path,
-                                      self.job_ctxt.params['OUTPUT_DIR'],
-                                      serialize_filename)
+            self.job_ctxt.params['OUTPUT_DIR'],
+            serialize_filename)
 
         LOG.debug("Serializing %s" % kwargs['curve_mode'])
         writer = risk_output.create_loss_curve_writer(
@@ -329,6 +334,8 @@
 
         loss_curves = []
         loss_ratio_curves = []
+        insured_loss_curves = []
+
         block = Block.from_kvs(job_id, block_id)
 
         for site in block.sites:
@@ -344,6 +351,10 @@
                     kvs.tokens.loss_ratio_key(
                     job_id, point.row, point.column, asset.asset_ref))
 
+                insured_loss_curve = kvs.get_client().get(
+                    kvs.tokens.insured_loss_curve_key(
+                        job_id, point.row, point.column, asset.asset_ref))
+
                 if loss_curve:
                     loss_curve = shapes.Curve.from_json(loss_curve)
                     loss_curves.append((site, (loss_curve, asset)))
@@ -352,6 +363,13 @@
                     loss_ratio_curve = shapes.Curve.from_json(loss_ratio_curve)
                     loss_ratio_curves.append((site, (loss_ratio_curve, asset)))
 
+                if insured_loss_curve:
+                    insured_loss_curve = shapes.Curve.from_json(
+                        insured_loss_curve)
+
+                    insured_loss_curves.append((site,
+                        (insured_loss_curve, asset)))
+
         results = self._serialize(block_id, curves=loss_ratio_curves,
                 curve_mode="loss_ratio")
 
@@ -360,6 +378,13 @@
                 block_id, curves=loss_curves, curve_mode="loss",
                 curve_mode_prefix="loss_curve", render_multi=True))
 
+        if insured_loss_curves:
+            results.extend(self._serialize(
+                block_id, curves=insured_loss_curves,
+                curve_mode="insured_loss_curve",
+                curve_mode_prefix="insured_loss_curve",
+                render_multi=True))
+
         return results
 
     def asset_losses_per_site(self, loss_poe, assets_iterator):
@@ -454,11 +479,11 @@
 
         for loss_poe in conditional_loss_poes(job_ctxt.params):
             path = os.path.join(job_ctxt.base_path,
-                                job_ctxt.params['OUTPUT_DIR'],
-                                "losses_at-%s.xml" % loss_poe)
+                job_ctxt.params['OUTPUT_DIR'],
+                "losses_at-%s.xml" % loss_poe)
             writer = risk_output.create_loss_map_writer(
-                job_ctxt.job_id, job_ctxt.serialize_results_to, path,
-                False)
+                job_ctxt.job_id, job_ctxt.serialize_results_to,
+                path, False)
 
             if writer:
                 metadata = {
@@ -1110,6 +1135,20 @@
     return _generate_curve(loss_ratios_range, probs_of_exceedance)
 
 
+def compute_insured_loss_curve(asset, loss_curve):
+    """
+    Compute an insured loss curve.
+    :param asset: the asset used to compute the insured loss curve.
+    :type asset: :py:class:`dict` as provided by
+        :py:class:`openquake.parser.exposure.ExposureModelFile`
+    :param loss_curve: a loss curve.
+    :type loss_curve: a :py:class:`openquake.shapes.Curve` instance.
+    """
+    insured_losses = compute_insured_losses(asset, loss_curve.x_values)
+
+    return shapes.Curve(zip(insured_losses, loss_curve.y_values))
+
+
 def _generate_curve(losses, probs_of_exceedance):
     """Generate a loss ratio (or loss) curve, given a set of losses
     and corresponding PoEs (Probabilities of Exceedance).
@@ -1223,3 +1262,39 @@
         return site
     else:
         return job_ctxt.region.grid.point_at(site).site
+
+
+def insurance_boundaries_defined(asset):
+    """
+    Check if limit and deductibles values have been defined for the asset.
+
+    :param asset: the asset used to compute the losses.
+    :type asset: an :py:class:`openquake.db.model.ExposureData` instance
+    """
+
+    if (asset.ins_limit >= 0 and asset.deductible >= 0):
+        return True
+    else:
+        raise RuntimeError('Insurance boundaries for asset %s are not defined'
+        % asset.asset_ref)
+
+
+def compute_insured_losses(asset, losses):
+    """
+    Compute insured losses for the given asset using the related set of ground
+    motion values and vulnerability function.
+
+    :param asset: the asset used to compute the loss ratios and losses.
+    :type asset: an :py:class:`openquake.db.model.ExposureData` instance.
+    :param losses: an array of loss values multiplied by the asset value.
+    :type losses: a 1-dimensional :py:class:`numpy.ndarray` instance.
+    """
+
+    if insurance_boundaries_defined(asset):
+        for i, value in enumerate(losses):
+            if value < asset.deductible:
+                losses[i] = 0
+            else:
+                if value > asset.ins_limit:
+                    losses[i] = asset.ins_limit
+    return losses
--- a/openquake/calculators/risk/scenario/core.py
+++ b/openquake/calculators/risk/scenario/core.py
@@ -53,16 +53,15 @@
         # loss of each asset
         self._loss_map_data = None
 
-        # algorithm used to compute the losses
-        # (standard or insured)
-        self._loss_ratios_calculator = compute_uninsured_losses
+        # compute insured losses
+        self._insured_losses = False
 
     def pre_execute(self):
         super(ScenarioRiskCalculator, self).pre_execute()
 
         if self.job_ctxt.params.get("INSURED_LOSSES"):
             self._output_filename = "insured-loss-map%s.xml"
-            self._loss_ratios_calculator = compute_insured_losses
+            self._insured_losses = True
 
     def post_execute(self):
         loss_map_path = os.path.join(
@@ -109,7 +108,7 @@
         region_data = distribute(
             general.compute_risk, ("block_id", self.job_ctxt.blocks_keys),
             tf_args=dict(job_id=self.job_ctxt.job_id,
-            vuln_model=vuln_model, calculator=self._loss_ratios_calculator))
+            vuln_model=vuln_model, insured_losses=self._insured_losses))
 
         for block_data in region_data:
             region_losses.append(block_data[0])
@@ -182,7 +181,7 @@
         """
 
         vuln_model = kwargs["vuln_model"]
-        compute_losses = kwargs["calculator"]
+        insured_losses = kwargs["insured_losses"]
         epsilon_provider = general.EpsilonProvider(self.job_ctxt.params)
         block = general.Block.from_kvs(self.job_ctxt.job_id, block_id)
 
@@ -200,8 +199,12 @@
             for asset in assets:
                 vuln_function = vuln_model[asset.taxonomy]
 
-                losses = compute_losses(
-                        vuln_function, gmvs, epsilon_provider, asset)
+                loss_ratios = general.compute_loss_ratios(
+                    vuln_function, gmvs, epsilon_provider, asset)
+                losses = loss_ratios * asset.value
+
+                if insured_losses:
+                    losses = general.compute_insured_losses(asset, losses)
 
                 asset_site = shapes.Site(asset.site.x, asset.site.y)
 
@@ -239,76 +242,3 @@
     data.append(asset_data)
     loss_data[asset_site] = data
 
-
-def compute_uninsured_losses(vuln_function, gmvs, epsilon_provider, asset):
-    """
-    Compute losses for the given asset using the related set of ground
-    motion values and vulnerability function.
-
-    :param vuln_function: the vulnerability function used to compute the loss
-        ratios.
-    :type vuln_function: :py:class:`openquake.shapes.VulnerabilityFunction`
-    :param gmvs: the set of ground motion values used to compute the loss
-        ratios.
-    :type gmvs: :py:class:`dict` with the following keys: **IMLs** - tuple
-        of ground motion values (float).
-    :param epsilon_provider: service used to get the epsilon when using the
-        sampled based algorithm.
-    :type epsilon_provider: object that defines an :py:meth:`epsilon` method
-    :param asset: the asset used to compute the loss ratios and losses.
-    :type asset: an :py:class:`openquake.db.model.ExposureData` instance
-    """
-
-    loss_ratios = general.compute_loss_ratios(
-        vuln_function, gmvs, epsilon_provider, asset)
-
-    losses = loss_ratios * asset.value
-
-    return losses
-
-
-def insurance_boundaries_defind(asset):
-    """
-    Check if limit and deductibles values have been defined for the asset.
-
-    :param asset: the asset used to compute the losses.
-    :type asset: an :py:class:`openquake.db.model.ExposureData` instance
-    """
-
-    if (asset.ins_limit >= 0 and asset.deductible >= 0):
-        return True
-    else:
-        raise RuntimeError('Insurance boundaries for asset %s are not defined'
-            % asset.asset_ref)
-
-
-def compute_insured_losses(vuln_function, gmvs, epsilon_provider, asset):
-    """
-    Compute insured losses for the given asset using the related set of ground
-    motion values and vulnerability function.
-
-    :param vuln_function: the vulnerability function used to compute the loss
-        ratios.
-    :type vuln_function: :py:class:`openquake.shapes.VulnerabilityFunction`
-    :param gmvs: the set of ground motion values used to compute the loss
-        ratios.
-    :type gmvs: :py:class:`dict` with the following keys: **IMLs** - tuple
-        of ground motion values (float).
-    :param epsilon_provider: service used to get the epsilon when using the
-        sampled based algorithm.
-    :type epsilon_provider: object that defines an :py:meth:`epsilon` method
-    :param asset: the asset used to compute the loss ratios and losses.
-    :type asset: an :py:class:`openquake.db.model.ExposureData` instance
-    """
-
-    losses = compute_uninsured_losses(vuln_function, gmvs,
-                epsilon_provider, asset)
-
-    if insurance_boundaries_defind(asset):
-        for i, value in enumerate(losses):
-            if value < asset.deductible:
-                losses[i] = 0
-            else:
-                if value > asset.ins_limit:
-                    losses[i] = asset.ins_limit
-    return losses
--- a/openquake/job/params.py
+++ b/openquake/job/params.py
@@ -410,5 +410,7 @@
              modes=('classical', 'event_based', 'disaggregation', 'uhs',
                     'classical_bcr', 'event_based_bcr'),
              to_job=float)
+define_param('INSURED_LOSSES', 'insured_losses',
+             modes=('scenario', 'event_based'), to_job=str2bool)
 # TODO: remove me when nhlib integration is complete
 define_param('WORKAROUND_1027041', 'workaround_1027041', to_job=str2bool)
--- a/openquake/kvs/tokens.py
+++ b/openquake/kvs/tokens.py
@@ -42,6 +42,7 @@
 GMF_KEY_TOKEN = 'GMF'
 LOSS_RATIO_CURVE_KEY_TOKEN = 'LOSS_RATIO_CURVE'
 LOSS_CURVE_KEY_TOKEN = 'LOSS_CURVE'
+INSURED_LOSS_CURVE_KEY_TOKEN = 'INSURED_LOSS_CURVE'
 VULNERABILITY_CURVE_KEY_TOKEN = 'VULNERABILITY_CURVE'
 BCR_BLOCK_KEY_TOKEN = 'BCR_BLOCK'
 
@@ -157,6 +158,12 @@
                          "retrofitted" if retrofitted else "normal")
 
 
+def insured_loss_curve_key(job_id, row, col, asset_id):
+    """ Return a insured loss curve key """
+    return _generate_key(job_id, INSURED_LOSS_CURVE_KEY_TOKEN, asset_id, row,
+        col)
+
+
 def loss_key(job_id, row, col, asset_id, poe):
     """ Return a loss key """
     return _generate_key(job_id, CONDITIONAL_LOSS_KEY_TOKEN, asset_id, poe,
--- a/openquake/output/risk.py
+++ b/openquake/output/risk.py
@@ -833,7 +833,7 @@
         :py:class:`output.risk.LossRatioCurveXMLWriter`
     """
 
-    assert curve_mode in ('loss', 'loss_ratio')
+    assert curve_mode in ('loss', 'loss_ratio', 'insured_loss_curve')
 
     writers = []
 
@@ -844,15 +844,15 @@
 
         if curve_mode == 'loss':
             writers.append(LossCurveDBWriter(nrml_path, job_id))
-        elif curve_mode == 'loss_ratio':
+        elif curve_mode in ('loss_ratio', 'insured_loss_curve'):
             # We are non interested in storing loss ratios in the db
             pass
 
     if 'xml' in serialize_to:
-        if curve_mode == 'loss':
-            writer_class = LossCurveXMLWriter
-        elif curve_mode == 'loss_ratio':
+        if curve_mode == 'loss_ratio':
             writer_class = LossRatioCurveXMLWriter
+        elif curve_mode  in ('loss', 'insured_loss_curve'):
+            writer_class = LossCurveXMLWriter
 
         writers.append(writer_class(nrml_path))
 
--- a/openquake/shapes.py
+++ b/openquake/shapes.py
@@ -30,7 +30,6 @@
 
 from shapely import geometry
 from scipy.interpolate import interp1d
-
 from nhlib import geo as nhlib_geo
 
 from openquake import java
@@ -63,7 +62,6 @@
 
         :returns: :py:class:`openquake.shapes.Region` instance
         """
-
         # Constrain the precision for the coordinates:
         coordinates = [(round_float(pt[0]), round_float(pt[1]))
                 for pt in coordinates]
@@ -306,7 +304,6 @@
         Return the site corresponding to the center of the
         cell identified by the given grid point.
         """
-
         return Site(self._column_to_longitude(point.column),
                 self._row_to_latitude(point.row))
 
@@ -460,11 +457,11 @@
     def from_json(cls, json_str):
         """Construct a curve from a serialized version in
         json format."""
-        as_dict = json.JSONDecoder().decode(json_str)
-        return cls.from_dict(as_dict)
+        as_list = json.JSONDecoder().decode(json_str)
+        return cls.from_list(as_list)
 
     @classmethod
-    def from_dict(cls, values):
+    def from_list(cls, values):
         """Construct a curve from a dictionary.
 
         The dictionary keys can be unordered and of
@@ -473,8 +470,8 @@
 
         data = []
 
-        for key, val in values.items():
-            data.append((float(key), val))
+        for x, y in values:
+            data.append((x, y))
 
         return cls(data)
 
@@ -582,15 +579,15 @@
 
     def to_json(self):
         """Serialize this curve in json format."""
-        as_dict = {}
+        curve = []
 
         for index, x_value in enumerate(self.x_values):
             if self.y_values.ndim > 1:
-                as_dict[str(x_value)] = list(self.y_values[index])
+                curve.append([x_value, list(self.y_values[index])])
             else:
-                as_dict[str(x_value)] = self.y_values[index]
+                curve.append([x_value, self.y_values[index]])
 
-        return json.JSONEncoder().encode(as_dict)
+        return json.JSONEncoder().encode(curve)
 
 
 class VulnerabilityFunction(object):
@@ -814,8 +811,8 @@
 
         :returns: :py:class:`openquake.shapes.VulnerabilityFunction` instance
         """
-        as_dict = json.JSONDecoder().decode(json_str)
-        return cls.from_tuple(as_dict)
+        as_list = json.JSONDecoder().decode(json_str)
+        return cls.from_tuple(as_list)
 
 
 EMPTY_CURVE = Curve(())
