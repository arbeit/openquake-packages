--- a/openquake/hazard/classical_psha.py
+++ b/openquake/hazard/classical_psha.py
@@ -21,6 +21,7 @@
 as input data produced with the classical psha method.
 """
 
+import json
 import math
 import numpy
 
@@ -35,6 +36,20 @@
 POES_PARAM_NAME = "POES"
 
 
+def mget_decoded(keys):
+    """
+    Retrieve multiple JSON values from the KVS
+
+    :param keys: keys to retrieve (the corresponding value must be a
+        JSON string)
+    :type keys: list
+    :returns: one value for each key in the list
+    """
+    decoder = json.JSONDecoder()
+
+    return [decoder.decode(value) for value in kvs.get_client().mget(keys)]
+
+
 def compute_mean_curve(curves):
     """Compute a mean hazard curve.
 
@@ -76,7 +91,7 @@
     keys = [kvs.tokens.hazard_curve_poes_key(job_id, realization, site)
                 for realization in xrange(realizations)]
     # get the probablity of exceedence for each curve in the site
-    return kvs.mget_decoded(keys)
+    return mget_decoded(keys)
 
 
 def compute_mean_hazard_curves(job_id, sites, realizations):
--- a/openquake/hazard/general.py
+++ b/openquake/hazard/general.py
@@ -123,7 +123,8 @@
     LOG.info("Storing source model from job config")
     key = kvs.tokens.source_model_key(job_id)
     mfd_bin_width = float(params.get('WIDTH_OF_MFD_BIN'))
-    calc.sample_and_save_source_model_logictree(kvs, key, seed, mfd_bin_width)
+    calc.sample_and_save_source_model_logictree(
+        kvs.get_client(), key, seed, mfd_bin_width)
 
 
 def store_gmpe_map(job_id, seed, calc):
@@ -137,7 +138,7 @@
     """
     LOG.info("Storing GMPE map from job config")
     key = kvs.tokens.gmpe_key(job_id)
-    calc.sample_and_save_gmpe_logictree(kvs, key, seed)
+    calc.sample_and_save_gmpe_logictree(kvs.get_client(), key, seed)
 
 
 def set_gmpe_params(gmpe_map, params):
--- a/openquake/hazard/opensha.py
+++ b/openquake/hazard/opensha.py
@@ -60,10 +60,15 @@
     @functools.wraps(fn)
     def decorated(self, *args, **kwargs):  # pylint: disable=C0111
         kvs_data = (config.get("kvs", "host"), int(config.get("kvs", "port")))
-        key = hashlib.md5(repr(kvs_data)).hexdigest()
-        if key not in __KVS_CONN_CACHE:
-            __KVS_CONN_CACHE[key] = java.jclass("KVS")(*kvs_data)
-        self.cache = __KVS_CONN_CACHE[key]
+
+        if kvs.cache_connections():
+            key = hashlib.md5(repr(kvs_data)).hexdigest()
+            if key not in __KVS_CONN_CACHE:
+                __KVS_CONN_CACHE[key] = java.jclass("KVS")(*kvs_data)
+            self.cache = __KVS_CONN_CACHE[key]
+        else:
+            self.cache = java.jclass("KVS")(*kvs_data)
+
         return fn(self, *args, **kwargs)
 
     return decorated
@@ -513,7 +518,7 @@
             curve_key = kvs.tokens.hazard_curve_poes_key(
                 self.job_id, realization, site)
 
-            kvs.set(curve_key, poes)
+            kvs.get_client().set(curve_key, poes)
 
             curve_keys.append(curve_key)
 
--- a/openquake/job/params.py
+++ b/openquake/job/params.py
@@ -26,6 +26,7 @@
 from collections import namedtuple
 
 from openquake.db.models import OqParams
+from openquake.utils.general import str2bool
 
 
 ARRAY_RE = re.compile('[\s,]+')
@@ -164,7 +165,6 @@
 # from the config file into a Job. Shortened names for the sake of brevity.
 cttl = config_text_to_list
 cttfl = lambda x: cttl(x, float)  # config text to float list
-str2bool = lambda x: x.lower() in ("true", "yes", "t", "1")
 
 
 # general params
--- a/openquake/kvs/__init__.py
+++ b/openquake/kvs/__init__.py
@@ -22,13 +22,13 @@
 the underlying kvs systems.
 """
 
-import hashlib
 import json
 import numpy
-
+import redis
 from openquake import logs
 from openquake.kvs import tokens
-from openquake.kvs.redis import Redis
+from openquake.utils import config
+from openquake.utils import general
 
 
 LOG = logs.LOG
@@ -39,86 +39,20 @@
 SITES_KEY_TOKEN = "sites"
 
 
-def flush():
-    """Flush (delete) all the values stored in the underlying kvs system."""
-    get_client().flushall()
-
-
-def get_keys(regexp):
-    """Get all KVS keys that match a given regexp pattern."""
-    return get_client().keys(regexp)
-
-
-def mget(keys):
-    """
-    Retrieve multiple keys from the KVS.
-
-    :param keys: keys to retrieve
-    :type keys: list
-    :returns: one value for each key in the list
-    """
-    return get_client().mget(keys)
-
-
-def mget_decoded(keys):
-    """
-    Retrieve multiple JSON values from the KVS
-
-    :param keys: keys to retrieve (the corresponding value must be a
-        JSON string)
-    :type keys: list
-    :returns: one value for each key in the list
-    """
-    decoder = json.JSONDecoder()
-
-    return [decoder.decode(value) for value in get_client().mget(keys)]
-
-
-def get_pattern(regexp):
-    """Get all the values whose keys satisfy the given regexp.
-
-    Return an empty list if there are no keys satisfying the given regxep.
-    """
-
-    values = []
-
-    keys = get_client().keys(regexp)
-
-    if keys:
-        values = get_client().mget(keys)
-
-    return values
-
-
-def get_pattern_decoded(regexp):
-    """Get and decode (from json format) all the values whose keys
-    satisfy the given regexp."""
-
-    decoded_values = []
-    decoder = json.JSONDecoder()
-
-    for value in get_pattern(regexp):
-        decoded_values.append(decoder.decode(value))
-
-    return decoded_values
-
-
-def get(key):
-    """Get value from kvs for external decoding"""
-    return get_client().get(key)
-
-
-# Module-private kvs connection cache, to be used by get_client().
-__KVS_CONN_CACHE = {}
+# Module-private kvs connection pool, to be used by get_client().
+__KVS_CONN_POOL = None
 
 
+# pylint: disable=W0603
 def get_client(**kwargs):
     """Return a redis kvs client connection object."""
-    key = hashlib.md5(repr(kwargs)).hexdigest()
-    if key not in __KVS_CONN_CACHE:
-        __KVS_CONN_CACHE[key] = Redis(**kwargs)
-
-    return __KVS_CONN_CACHE[key]
+    global __KVS_CONN_POOL
+    if __KVS_CONN_POOL is None:
+        cfg = config.get_section("kvs")
+        __KVS_CONN_POOL = redis.ConnectionPool(
+            max_connections=1, host=cfg["host"], port=int(cfg["port"]))
+    kwargs.update({"connection_pool": __KVS_CONN_POOL})
+    return redis.Redis(**kwargs)
 
 
 def get_value_json_decoded(key):
@@ -174,13 +108,6 @@
     return True
 
 
-def set(key, encoded_value):  # pylint: disable=W0622
-    """ Set value in kvs, for objects that have their own encoding method. """
-
-    get_client().set(key, encoded_value)
-    return True
-
-
 def mark_job_as_current(job_id):
     """
     Add a job to the set of current jobs, to be later garbage collected.
@@ -250,3 +177,11 @@
             '%s is not recognized as a current job.' % job_id
         LOG.error(msg)
         return None
+
+
+def cache_connections():
+    """True if kvs connections should be cached."""
+    setting = config.get("kvs", "cache_connections")
+    if setting is None:
+        return False
+    return general.str2bool(setting)
--- a/openquake/kvs/redis.py
+++ /dev/null
@@ -1,76 +0,0 @@
-# -*- coding: utf-8 -*-
-
-#   Redis Client from https://github.com/ChristopherMacGown/pynpoint
-#   Copyright 2010 Christopher MacGown (http://github.com/ChristopherMacGown)
-#
-#   Licensed under the Apache License, Version 2.0 (the "License");
-#   you may not use this file except in compliance with the License.
-#   You may obtain a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#   Unless required by applicable law or agreed to in writing, software
-#   distributed under the License is distributed on an "AS IS" BASIS,
-#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#   See the License for the specific language governing permissions and
-#   limitations under the License.
-#
-#   Modifications by Global Earthquake Model Foundation
-#   Copyright 2010 Global Earthquake Model Foundation
-#
-#   This program is free software: you can redistribute it and/or modify
-#   it under the terms of the GNU Lesser General Public License as published by
-#   the Free Software Foundation, either version 3 of the License, or
-#   (at your option) any later version.
-#
-#   This program is distributed in the hope that it will be useful,
-#   but WITHOUT ANY WARRANTY; without even the implied warranty of
-#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#   GNU Lesser General Public License for more details.
-#
-#   You should have received a copy of the GNU Lesser General Public License
-#   along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-""" Redis class """
-
-from __future__ import absolute_import
-import redis
-
-from openquake.utils import config
-
-
-class Redis(object):
-    """ A Borg-style wrapper for Redis client class. """
-    __shared_state = {}
-
-    def __new__(cls, host=config.get("kvs", "host"),
-                     port=int(config.get("kvs", "port")),
-                     **kwargs):  # pylint: disable=W0613
-        self = object.__new__(cls)
-        self.__dict__ = cls.__shared_state
-        return self
-
-    def __init__(self, host=config.get("kvs", "host"),
-                       port=int(config.get("kvs", "port")),
-                       **kwargs):
-        if not self.__dict__:
-            args = {"host": host,
-                    "port": port,
-                    "db": kwargs.get('db', 0)}
-
-            self.conn = redis.Redis(**args)
-
-    def __getattr__(self, name):
-        def call(*args, **kwargs):
-            """ Pass through the query to our redis connection """
-            cmd = getattr(self.conn, name)
-            return cmd(*args, **kwargs)
-
-        if name in self.__dict__:
-            return self.__dict__.get(name)
-
-        return call
-
-    def get_multi(self, keys):
-        """ Return value of multiple keys identically to the kvs way """
-        return dict(zip(keys, self.mget(keys)))
--- a/openquake/risk/job/classical_psha.py
+++ b/openquake/risk/job/classical_psha.py
@@ -134,7 +134,7 @@
         loss_key = kvs.tokens.loss_curve_key(self.job_id, point.row,
             point.column, asset['assetID'])
 
-        kvs.set(loss_key, loss_curve.to_json())
+        kvs.get_client().set(loss_key, loss_curve.to_json())
 
         return loss_curve
 
@@ -172,7 +172,7 @@
         loss_ratio_key = kvs.tokens.loss_ratio_key(
             self.job_id, point.row, point.column, asset['assetID'])
 
-        kvs.set(loss_ratio_key, loss_ratio_curve.to_json())
+        kvs.get_client().set(loss_ratio_key, loss_ratio_curve.to_json())
 
         return loss_ratio_curve
 
--- a/openquake/risk/job/general.py
+++ b/openquake/risk/job/general.py
@@ -118,7 +118,7 @@
     LOG.debug("Conditional loss is %s, write to key %s" %
             (loss_conditional, key))
 
-    kvs.set(key, loss_conditional)
+    kvs.get_client().set(key, loss_conditional)
 
 
 @task
@@ -232,16 +232,12 @@
                 block.grid(self.region)):
             site = shapes.Site(asset['lon'], asset['lat'])
 
-            loss_curve = kvs.get(
-                            kvs.tokens.loss_curve_key(job_id,
-                                                        point.row,
-                                                        point.column,
-                                                        asset["assetID"]))
-            loss_ratio_curve = kvs.get(
-                            kvs.tokens.loss_ratio_key(job_id,
-                                                        point.row,
-                                                        point.column,
-                                                        asset["assetID"]))
+            loss_curve = kvs.get_client().get(
+                kvs.tokens.loss_curve_key(
+                    job_id, point.row, point.column, asset["assetID"]))
+            loss_ratio_curve = kvs.get_client().get(
+                kvs.tokens.loss_ratio_key(
+                    job_id, point.row, point.column, asset["assetID"]))
 
             if loss_curve:
                 loss_curve = shapes.Curve.from_json(loss_curve)
@@ -255,11 +251,10 @@
                                            curves=loss_ratio_curves,
                                            curve_mode='loss_ratio')
         if loss_curves:
-            results.extend(self._serialize(block_id,
-                                                curves=loss_curves,
-                                                curve_mode='loss',
-                                                curve_mode_prefix='loss_curve',
-                                                render_multi=True))
+            results.extend(
+                self._serialize(
+                    block_id, curves=loss_curves, curve_mode='loss',
+                    curve_mode_prefix='loss_curve', render_multi=True))
         return results
 
     def asset_losses_per_site(self, loss_poe, assets_iterator):
@@ -291,7 +286,8 @@
             key = kvs.tokens.loss_key(self.job_id, point.row, point.column,
                     asset["assetID"], loss_poe)
 
-            loss_value = kvs.get(key)
+            loss_value = kvs.get_client().get(key)
+
             LOG.debug("Loss for asset %s at %s %s is %s" %
                 (asset["assetID"], asset['lon'], asset['lat'], loss_value))
 
--- a/openquake/risk/job/probabilistic.py
+++ b/openquake/risk/job/probabilistic.py
@@ -264,7 +264,7 @@
         key = kvs.tokens.loss_ratio_key(
             self.job_id, row, col, asset["assetID"])
 
-        kvs.set(key, loss_ratio_curve.to_json())
+        kvs.get_client().set(key, loss_ratio_curve.to_json())
 
         LOGGER.debug("Loss ratio curve is %s, write to key %s" %
                 (loss_ratio_curve, key))
@@ -303,7 +303,7 @@
             self.job_id, row, column, asset["assetID"])
 
         LOGGER.debug("Loss curve is %s, write to key %s" % (loss_curve, key))
-        kvs.set(key, loss_curve.to_json())
+        kvs.get_client().set(key, loss_curve.to_json())
 
         return loss_curve
 
--- a/openquake/utils/general.py
+++ b/openquake/utils/general.py
@@ -52,3 +52,8 @@
             self.memo[key] = self.fun(*args, **kwds)
 
         return self.memo[key]
+
+
+def str2bool(value):
+    """Convert a string representation of a boolean value to a bool."""
+    return value.lower() in ("true", "yes", "t", "1")
