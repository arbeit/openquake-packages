--- a/openquake/db/schema/openquake.sql
+++ b/openquake/db/schema/openquake.sql
@@ -615,11 +615,8 @@
         CHECK(((job_type = 'uhs') AND (imt = 'sa'))
             OR (imt IN ('pga', 'sa', 'pgv', 'pgd', 'ia', 'rsd', 'mmi'))),
     period float CONSTRAINT period_is_set
-        -- The 'period' parameter is only used when the intensity measure type is SA.
-        -- This rule only applies to job types != 'uhs' (the Uniform Hazard Spectra
-        -- calculator instead defines an array of periods).
-        CHECK(((imt = 'sa' AND job_type != 'uhs') AND (period IS NOT NULL))
-              OR ((imt != 'sa' OR job_type = 'uhs') AND (period IS NULL))),
+        CHECK(((imt = 'sa') AND (period IS NOT NULL))
+              OR ((imt != 'sa') AND (period IS NULL))),
     damping float CONSTRAINT damping_is_set
         CHECK(((imt = 'sa') AND (damping IS NOT NULL))
               OR ((imt != 'sa') AND (damping IS NULL))),
@@ -731,7 +728,7 @@
         CHECK(
             (job_type IN ('deterministic', 'event_based'))
             OR
-            ((job_type IN ('classical', 'disaggregation', 'uhs'))
+            ((job_type IN ('classical', 'disaggregation'))
              AND (gmf_random_seed IS NULL))),
     gmpe_lt_random_seed integer
         CONSTRAINT gmpe_lt_random_seed_is_set
@@ -790,7 +787,7 @@
             ((job_type = 'classical')
              AND (quantile_levels IS NOT NULL))
             OR
-            ((job_type IN ('deterministic', 'event_based', 'disaggregation', 'uhs'))
+            ((job_type IN ('deterministic', 'event_based', 'disaggregation'))
              AND (quantile_levels IS NULL))),
     reference_depth_to_2pt5km_per_sec_param float,
     risk_cell_size float,
@@ -809,7 +806,7 @@
     rupture_floating_type VARCHAR
         CONSTRAINT rupture_floating_type_is_set
         CHECK(
-            ((job_type IN ('classical', 'event_based', 'disaggregation', 'uhs'))
+            ((job_type IN ('classical', 'event_based', 'disaggregation'))
              AND (rupture_floating_type IN ('alongstrike', 'downdip', 'centereddowndip')))
             OR
             ((job_type = 'deterministic')
--- a/openquake/hazard/deterministic.py
+++ b/openquake/hazard/deterministic.py
@@ -40,7 +40,7 @@
     Job class, and thus has access to the self.params dict, full of config
     params loaded from the job configuration file."""
 
-    @java.unpack_exception
+    @java.jexception
     def execute(self):
         """Entry point to trigger the computation."""
 
@@ -169,6 +169,7 @@
             jpype.JDouble(float(self.params["DAMPING"])),
             self.params["GMPE_TRUNCATION_TYPE"],
             jpype.JDouble(float(self.params["TRUNCATION_LEVEL"])), "Total",
+            jpype.JDouble(float(self.params["REFERENCE_VS30_VALUE"])),
             jpype.JObject(gmpe, java.jclass("AttenuationRelationship")))
 
         return gmpe
--- a/openquake/hazard/disagg/core.py
+++ b/openquake/hazard/disagg/core.py
@@ -24,6 +24,8 @@
 import random
 import uuid
 
+from math import log
+
 from openquake import java
 from openquake import job
 from openquake import logs
@@ -32,12 +34,12 @@
 from openquake.hazard import disagg
 from openquake.job import config as job_cfg
 from openquake.output import hazard_disagg as hazard_output
-from openquake.utils import config, list_to_jdouble_array
+from openquake.utils import config
 
 from openquake.hazard.disagg import subsets
 from openquake.hazard.general import (
     preload, generate_erf, generate_gmpe_map, set_gmpe_params,
-    store_source_model, store_gmpe_map, get_iml_list)
+    store_source_model, store_gmpe_map)
 from openquake.job.mixins import Mixin
 from openquake.utils.tasks import check_job_status
 
@@ -46,7 +48,7 @@
 
 
 # pylint: disable=R0914
-@java.unpack_exception
+@java.jexception
 def compute_disagg_matrix(job_id, site, poe, result_dir):
     """ Compute a complete 5D Disaggregation matrix. This task leans heavily
     on the DisaggregationCalculator (in the OpenQuake Java lib) to handle this
@@ -88,15 +90,19 @@
     gmpe_map = generate_gmpe_map(job_id, cache)
     set_gmpe_params(gmpe_map, the_job.params)
 
-    imls = get_iml_list(the_job['INTENSITY_MEASURE_LEVELS'],
-                        the_job['INTENSITY_MEASURE_TYPE'])
+    iml_arraylist = java.jclass('ArrayList')()
+    iml_vals = the_job['INTENSITY_MEASURE_LEVELS']
+    # Map `log` (natural log) to each IML value before passing to the
+    # calculator.
+    iml_vals = [log(x) for x in iml_vals]
+    iml_arraylist.addAll(iml_vals)
     vs30_type = the_job['VS30_TYPE']
     vs30_value = the_job['REFERENCE_VS30_VALUE']
     depth_to_1pt0 = the_job['DEPTHTO1PT0KMPERSEC']
     depth_to_2pt5 = the_job['REFERENCE_DEPTH_TO_2PT5KM_PER_SEC_PARAM']
 
     matrix_result = disagg_calc.computeMatrix(
-        site.latitude, site.longitude, erf, gmpe_map, poe, imls,
+        site.latitude, site.longitude, erf, gmpe_map, poe, iml_arraylist,
         vs30_type, vs30_value, depth_to_1pt0, depth_to_2pt5)
 
     matrix_path = save_5d_matrix_to_h5(result_dir,
@@ -126,6 +132,17 @@
     return file_path
 
 
+def list_to_jdouble_array(float_list):
+    """Convert a 1D list of floats to a 1D Java Double[] (as a jpype object).
+    """
+    jdouble = java.jvm().JArray(java.jvm().java.lang.Double)(len(float_list))
+
+    for i, val in enumerate(float_list):
+        jdouble[i] = java.jvm().JClass('java.lang.Double')(val)
+
+    return jdouble
+
+
 @task
 @java.unpack_exception
 def compute_disagg_matrix_task(job_id, site, realization, poe, result_dir):
--- a/openquake/hazard/general.py
+++ b/openquake/hazard/general.py
@@ -27,7 +27,6 @@
 from openquake import logs
 
 from openquake.input import logictree
-from openquake.utils import list_to_jdouble_array
 
 from openquake.job.mixins import Mixin
 
@@ -52,8 +51,10 @@
     """Build the appropriate Arbitrary Discretized Func from the IMLs,
     based on the IMT"""
 
-    return list_to_jdouble_array(
-        [IML_SCALING[intensity_measure_type](x) for x in imls])
+    iml_list = java.jclass("ArrayList")()
+    for val in imls:
+        iml_list.add(IML_SCALING[intensity_measure_type](val))
+    return iml_list
 
 
 def preload(fn):
@@ -70,7 +71,7 @@
     return preloader
 
 
-@java.unpack_exception
+@java.jexception
 def generate_erf(job_id, cache):
     """ Generate the Earthquake Rupture Forecast from the source model data
     stored in the KVS.
@@ -147,34 +148,18 @@
     :param dict params: job config params
     """
     jpype = java.jvm()
-
-    jd_float = lambda x: jpype.JDouble(float(x))
-
-    component = params.get('COMPONENT')
-    imt = params.get('INTENSITY_MEASURE_TYPE')
-    # PERIOD is not used in UHS calculations.
-    period = (jd_float(params.get('PERIOD'))
-              if params.get('PERIOD') is not None else None)
-    damping = jd_float(params.get('DAMPING'))
-    gmpe_trunc_type = params.get('GMPE_TRUNCATION_TYPE')
-    trunc_level = jd_float(params.get('TRUNCATION_LEVEL'))
-    stddev_type = params.get('STANDARD_DEVIATION_TYPE')
-
     j_set_gmpe_params = java.jclass("GmpeLogicTreeData").setGmpeParams
     for tect_region in gmpe_map.keySet():
         gmpe = gmpe_map.get(tect_region)
-        # There are two overloads for this method; one with 'period'...
-        if period is not None:
-            j_set_gmpe_params(
-                component, imt, period, damping,
-                gmpe_trunc_type, trunc_level, stddev_type,
-                jpype.JObject(gmpe, java.jclass("AttenuationRelationship")))
-        # ... and one without.
-        else:
-            j_set_gmpe_params(
-                component, imt, damping,
-                gmpe_trunc_type, trunc_level, stddev_type,
-                jpype.JObject(gmpe, java.jclass("AttenuationRelationship")))
+        j_set_gmpe_params(params['COMPONENT'],
+            params['INTENSITY_MEASURE_TYPE'],
+            jpype.JDouble(float(params['PERIOD'])),
+            jpype.JDouble(float(params['DAMPING'])),
+            params['GMPE_TRUNCATION_TYPE'],
+            jpype.JDouble(float(params['TRUNCATION_LEVEL'])),
+            params['STANDARD_DEVIATION_TYPE'],
+            jpype.JDouble(float(params['REFERENCE_VS30_VALUE'])),
+            jpype.JObject(gmpe, java.jclass("AttenuationRelationship")))
         gmpe_map.put(tect_region, gmpe)
 
 
--- a/openquake/hazard/opensha.py
+++ b/openquake/hazard/opensha.py
@@ -266,7 +266,7 @@
             for quantile in quantiles:
                 map_serializer(sites, self.poes_hazard_maps, quantile)
 
-    @java.unpack_exception
+    @java.jexception
     @preload
     @create_java_cache
     def execute(self):
@@ -587,7 +587,7 @@
     Job class, and thus has access to the self.params dict, full of config
     params loaded from the Job configuration file."""
 
-    @java.unpack_exception
+    @java.jexception
     @preload
     @create_java_cache
     def execute(self):
--- a/openquake/hazard/uhs/__init__.py
+++ /dev/null
@@ -1,17 +0,0 @@
-# Copyright (c) 2010-2011, GEM Foundation.
-#
-# OpenQuake is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Lesser General Public License version 3
-# only, as published by the Free Software Foundation.
-#
-# OpenQuake is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Lesser General Public License version 3 for more details
-# (a copy is included in the LICENSE file that accompanied this code).
-#
-# You should have received a copy of the GNU Lesser General Public License
-# version 3 along with OpenQuake.  If not, see
-# <http://www.gnu.org/licenses/lgpl-3.0.txt> for a copy of the LGPLv3 License.
-
-"""Uniform Hazard Spectra calculator."""
--- a/openquake/hazard/uhs/core.py
+++ /dev/null
@@ -1,200 +0,0 @@
-# Copyright (c) 2010-2011, GEM Foundation.
-#
-# OpenQuake is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Lesser General Public License version 3
-# only, as published by the Free Software Foundation.
-#
-# OpenQuake is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Lesser General Public License version 3 for more details
-# (a copy is included in the LICENSE file that accompanied this code).
-#
-# You should have received a copy of the GNU Lesser General Public License
-# version 3 along with OpenQuake.  If not, see
-# <http://www.gnu.org/licenses/lgpl-3.0.txt> for a copy of the LGPLv3 License.
-
-
-"""Core functionality of the Uniform Hazard Spectra calculator."""
-
-
-import h5py
-import numpy
-import os
-
-from celery.task import task
-
-from openquake import java
-from openquake.job import Job
-from openquake.logs import LOG
-from openquake.utils import list_to_jdouble_array
-from openquake.hazard.general import (
-    generate_erf, generate_gmpe_map, set_gmpe_params, get_iml_list)
-from openquake.utils import config
-from openquake.utils import tasks as utils_tasks
-
-
-@task(ignore_result=True)
-def touch_result_file(job_id, path, sites, n_samples, n_periods):
-    """Given a path (including the file name), create an empty HDF5 result file
-    containing 1 empty data set for each site. Each dataset will be a matrix
-    with the number of rows = number of samples and number of cols = number of
-    UHS periods.
-
-    :param int job_id:
-        ID of the job record in the DB/KVS.
-    :param str path:
-        Location (including a file name) on an NFS where the empty
-        result file should be created.
-    :param sites:
-        List of :class:`openquake.shapes.Site` objects.
-    :param int n_samples:
-        Number of logic tree samples (the y-dimension of each dataset).
-    :param int n_periods:
-        Number of UHS periods (the x-dimension of each dataset).
-    """
-    utils_tasks.check_job_status(job_id)
-    # TODO: Generate the sites, instead of pumping them through rabbit?
-    with h5py.File(path, 'w') as h5_file:
-        for site in sites:
-            ds_name = 'lon:%s-lat:%s' % (site.longitude, site.latitude)
-            ds_shape = (n_samples, n_periods)
-            h5_file.create_dataset(ds_name, dtype=numpy.float64,
-                                   shape=ds_shape)
-
-
-@task(ignore_results=True)
-@java.unpack_exception
-def compute_uhs_task(job_id, realization, site, result_dir):
-    """Compute Uniform Hazard Spectra for a given site of interest and 1 or
-    more Probability of Exceedance values. The bulk of the computation will
-    be done by utilizing the `UHSCalculator` class in the Java code.
-
-    UHS results (for each poe) will be written as a 1D array into temporary
-    HDF5 files. (The files will later be collected and 'reduced' into final
-    result files.)
-
-    :param int job_id:
-        ID of the job record in the DB/KVS.
-    :param realization:
-        Logic tree sample number (from 1 to N, where N is the
-        NUMBER_OF_LOGIC_TREE_SAMPLES param defined in the job config.
-    :param site:
-        The site of interest (a :class:`openquake.shapes.Site` object).
-    :param result_dir:
-        NFS result directory path. For each poe, a subfolder will be created to
-        contain intermediate calculation results. (Each call to this task will
-        generate 1 result file per poe.)
-    :returns:
-        A list of the resulting file names (1 per poe).
-    """
-    utils_tasks.check_job_status(job_id)
-
-    the_job = Job.from_kvs(job_id)
-
-    log_msg = (
-        "Computing UHS for job_id=%s, site=%s, realization=%s."
-        " UHS results will be serialized to `%s`.")
-    log_msg %= (the_job.job_id, site, realization, result_dir)
-    LOG.info(log_msg)
-
-    uhs_results = compute_uhs(the_job, site)
-
-    return write_uhs_results(result_dir, realization, site, uhs_results)
-
-
-def compute_uhs(the_job, site):
-    """Given a `Job` and a site of interest, compute UHS. The Java
-    `UHSCalculator` is called to do perform the core computation.
-
-    :param the_job:
-        :class:`openquake.job.Job` instance.
-    :param site:
-        :class:`openquake.shapes.Site` instance.
-    :returns:
-        An `ArrayList` (Java object) of `UHSResult` objects, one per PoE.
-    """
-
-    periods = list_to_jdouble_array(the_job['UHS_PERIODS'])
-    poes = list_to_jdouble_array(the_job['POES'])
-    imls = get_iml_list(the_job['INTENSITY_MEASURE_LEVELS'],
-                        the_job['INTENSITY_MEASURE_TYPE'])
-    max_distance = the_job['MAXIMUM_DISTANCE']
-
-    cache = java.jclass('KVS')(
-        config.get('kvs', 'host'),
-        int(config.get('kvs', 'port')))
-
-    erf = generate_erf(the_job.job_id, cache)
-    gmpe_map = generate_gmpe_map(the_job.job_id, cache)
-    set_gmpe_params(gmpe_map, the_job.params)
-
-    uhs_calc = java.jclass('UHSCalculator')(periods, poes, imls, erf, gmpe_map,
-                                            max_distance)
-
-    uhs_results = uhs_calc.computeUHS(
-        site.latitude,
-        site.longitude,
-        the_job['VS30_TYPE'],
-        the_job['REFERENCE_VS30_VALUE'],
-        the_job['DEPTHTO1PT0KMPERSEC'],
-        the_job['REFERENCE_DEPTH_TO_2PT5KM_PER_SEC_PARAM'])
-
-    return uhs_results
-
-
-def write_uhs_results(result_dir, realization, site, uhs_results):
-    """Write intermediate (temporary) UHS results to the specified directory.
-    Results will later be collected and written to the final results file(s).
-
-    :param result_dir:
-        NFS result directory path. For each poe, a subfolder will be created to
-        contain intermediate calculation results. (Each call to this task will
-        generate 1 result file per poe).
-    :param int realization:
-        Logic tree sample number.
-    :param site:
-        :class:`openquake.shapes.Site` associated with the results.
-    :param uhs_results:
-        A sequence of `UHSResult` jpype Java objects.
-    :returns:
-        A list of the resulting file names (1 per poe).
-    """
-    result_files = []
-
-    for result in uhs_results:
-        poe = result.getPoe()
-        uhs = result.getUhs()  # This is a Java Double[]
-
-        # We want intermediate calc results to be organized by PoE,
-        # so that they can be collected and reduced into a single result file
-        # per PoE.
-        # Having results separated this way means that a result collector
-        # is simply assigned a directory to poll and grabs any result files
-        # that it finds (without having to do much/any fitering or searching).
-        poe_path = os.path.join(result_dir, 'poe:%s' % poe)
-        if not os.path.exists(poe_path):
-            os.makedirs(poe_path)
-
-        # Initially, prepend the file name with an underscore.
-        # When the file done being written to, rename it and remove the
-        # underscore.
-        file_name = '_sample:%s-lon:%s-lat:%s.h5'
-        file_name %= (realization, site.longitude, site.latitude)
-        file_path = os.path.join(poe_path, file_name)
-
-        with h5py.File(file_path, 'w') as h5_file:
-            h5_file.create_dataset(
-                'uhs',
-                # We have to get the primitive 'value' for each Double in the
-                # Double[]
-                data=numpy.array([x.value for x in uhs], dtype=numpy.float64))
-
-        # We're done writing so we can rename it. This is an indicator to
-        # result collector code that these results are ready to be collected.
-        complete_file_path = os.path.join(poe_path, file_name[1:])
-        os.rename(file_path, complete_file_path)
-
-        result_files.append(complete_file_path)
-
-    return result_files
--- a/openquake/java.py
+++ b/openquake/java.py
@@ -76,7 +76,6 @@
     "LocationListFormatter": "org.gem.LocationListFormatter",
     "PythonBridgeAppender": "org.gem.log.PythonBridgeAppender",
     "DisaggregationCalculator": "org.gem.calc.DisaggregationCalculator",
-    "UHSCalculator": "org.gem.calc.UHSCalculator",
 }
 
 
@@ -315,15 +314,12 @@
         return trace
 
 
-def unpack_exception(func):
+def jexception(func):
     """
     Decorator to extract the stack trace from a Java exception.
 
     Re-throws a pickleable :class:`JavaException` object containing the
     exception message and Java stack trace.
-
-    This decorator can be used with the celery @task decorator (though the
-    celery @task decorator must be the outermost decorator).
     """
     @wraps(func)
     def unwrap_exception(*targs, **tkwargs):  # pylint: disable=C0111
@@ -337,3 +333,43 @@
             raise JavaException(e), None, trace
 
     return unwrap_exception
+
+
+# alternative implementation using the decorator module; this can be composed
+# with the Celery task decorator
+# import decorator
+#
+# def jexception(func):
+#     @wraps(func)
+#     def unwrap_exception(func, *targs, **tkwargs):
+#         jvm_instance = jvm()
+#
+#         try:
+#             return func(*targs, **tkwargs)
+#         except jvm_instance.JavaException, e:
+#             trace = sys.exc_info()[2]
+#
+#             raise JavaException(e), None, trace
+#
+#     return decorator.decorator(unwrap_exception, func)
+
+
+# Java-exception-aware task decorator for celery
+def unpack_exception(func):
+    """
+    Java-exception aware task decorator for Celery.
+
+    Re-throws the exception as a pickleable :class:`JavaException` object.
+    """
+    @wraps(func)
+    def wrapper(*args, **kwargs):
+        """The actual decorator."""
+        jvm_instance = jvm()
+
+        try:
+            return func(*args, **kwargs)
+        except jvm_instance.JavaException, e:
+            trace = sys.exc_info()[2]
+            raise JavaException(e), None, trace
+
+    return wrapper
--- a/openquake/job/__init__.py
+++ b/openquake/job/__init__.py
@@ -475,10 +475,9 @@
 
     def __getitem__(self, name):
         defined_param = job_params.PARAMS.get(name)
-        if (hasattr(defined_param, 'to_job')
-            and defined_param.to_job is not None
-            and self.params.get(name) is not None):
-            return defined_param.to_job(self.params.get(name))
+        if defined_param.to_job is not None:
+            if self.params.get(name) is not None:
+                return defined_param.to_job(self.params.get(name))
         return self.params.get(name)
 
     def __eq__(self, other):
--- a/openquake/job/params.py
+++ b/openquake/job/params.py
@@ -185,9 +185,9 @@
 define_param("SINGLE_RUPTURE_MODEL", None, modes=("deterministic",))
 define_param('EXPOSURE', None)
 define_param('GMPE_LOGIC_TREE_FILE', None,
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'))
+             modes=('classical', 'event_based', 'disaggregation'))
 define_param('SOURCE_MODEL_LOGIC_TREE_FILE', None,
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'))
+             modes=('classical', 'event_based', 'disaggregation'))
 
 # Disaggregation parameters:
 define_param('DISAGGREGATION_RESULTS', 'disagg_results',
@@ -208,78 +208,78 @@
 
 # area sources
 define_param('INCLUDE_AREA_SOURCES', 'include_area_sources',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=str2bool)
 define_param('TREAT_AREA_SOURCE_AS', 'treat_area_source_as',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_db=map_enum)
 define_param('AREA_SOURCE_DISCRETIZATION',
              'area_source_discretization',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('AREA_SOURCE_MAGNITUDE_SCALING_RELATIONSHIP',
              'area_source_magnitude_scaling_relationship',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'))
+             modes=('classical', 'event_based', 'disaggregation'))
 
 # grid/point sources
 define_param('INCLUDE_GRID_SOURCES', 'include_grid_sources',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=str2bool)
 define_param('TREAT_GRID_SOURCE_AS', 'treat_grid_source_as',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'))
+             modes=('classical', 'event_based', 'disaggregation'))
 define_param('GRID_SOURCE_MAGNITUDE_SCALING_RELATIONSHIP',
              'grid_source_magnitude_scaling_relationship')
 
 # simple faults
 define_param('INCLUDE_FAULT_SOURCE', 'include_fault_source',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=str2bool)
 define_param('FAULT_RUPTURE_OFFSET', 'fault_rupture_offset',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('FAULT_SURFACE_DISCRETIZATION', 'fault_surface_discretization',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('FAULT_MAGNITUDE_SCALING_RELATIONSHIP',
              'fault_magnitude_scaling_relationship',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'))
+             modes=('classical', 'event_based', 'disaggregation'))
 define_param('FAULT_MAGNITUDE_SCALING_SIGMA',
              'fault_magnitude_scaling_sigma',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('RUPTURE_ASPECT_RATIO', 'rupture_aspect_ratio',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('RUPTURE_FLOATING_TYPE', 'rupture_floating_type',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_db=map_enum)
 
 # complex faults
 define_param('INCLUDE_SUBDUCTION_FAULT_SOURCE',
              'include_subduction_fault_source',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=str2bool)
 define_param('SUBDUCTION_FAULT_RUPTURE_OFFSET',
              'subduction_fault_rupture_offset',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('SUBDUCTION_FAULT_SURFACE_DISCRETIZATION',
              'subduction_fault_surface_discretization',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('SUBDUCTION_FAULT_MAGNITUDE_SCALING_RELATIONSHIP',
              'subduction_fault_magnitude_scaling_relationship',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'))
+             modes=('classical', 'event_based', 'disaggregation'))
 define_param('SUBDUCTION_FAULT_MAGNITUDE_SCALING_SIGMA',
              'subduction_fault_magnitude_scaling_sigma',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('SUBDUCTION_RUPTURE_ASPECT_RATIO',
              'subduction_rupture_aspect_ratio',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'))
+             modes=('classical', 'event_based', 'disaggregation'))
 define_param('SUBDUCTION_RUPTURE_FLOATING_TYPE',
              'subduction_rupture_floating_type',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_db=map_enum)
 
 # Everything else; please maintain alphabetical ordering.
@@ -297,34 +297,32 @@
 define_param('GMF_RANDOM_SEED', 'gmf_random_seed',
              modes=('event_based', 'deterministic'), to_job=int)
 define_param('GMPE_LT_RANDOM_SEED', 'gmpe_lt_random_seed',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
-             to_job=int)
+             modes=('classical', 'event_based', 'disaggregation'), to_job=int)
 define_param('GMPE_MODEL_NAME', 'gmpe_model_name')
 define_param('GMPE_TRUNCATION_TYPE', 'truncation_type', to_db=map_enum)
 define_param('GROUND_MOTION_CORRELATION', 'gm_correlated',
              modes=('deterministic', 'event_based'), to_job=str2bool)
 define_param('INTENSITY_MEASURE_LEVELS', 'imls',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=cttfl)
 define_param('INTENSITY_MEASURE_TYPE', 'imt', to_db=map_enum)
 define_param('INVESTIGATION_TIME', 'investigation_time', default=0.0,
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('LOSS_CURVES_OUTPUT_PREFIX', 'loss_curves_output_prefix')
 define_param('MAXIMUM_DISTANCE', 'maximum_distance',
-             modes=('classical', 'disaggregation', 'uhs'), to_job=float)
+             modes=('classical', 'disaggregation'), to_job=float)
 define_param('MINIMUM_MAGNITUDE', 'min_magnitude', default=0.0,
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
 define_param('NUMBER_OF_GROUND_MOTION_FIELDS_CALCULATIONS',
              'gmf_calculation_number', modes='deterministic', to_job=int)
 define_param('NUMBER_OF_LOGIC_TREE_SAMPLES', 'realizations',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
-             to_job=int)
+             modes=('classical', 'event_based', 'disaggregation'), to_job=int)
 define_param('NUMBER_OF_SEISMICITY_HISTORIES', 'histories',
              modes='event_based', to_job=int)
 define_param('PERIOD', 'period', default=0.0, to_job=float)
-define_param('POES', 'poes', modes=('classical', 'disaggregation', 'uhs'),
+define_param('POES', 'poes', modes=('classical', 'disaggregation'),
              to_job=cttfl)
 define_param('QUANTILE_LEVELS', 'quantile_levels', modes='classical',
              to_job=cttfl)
@@ -340,12 +338,11 @@
 define_param("SADIGH_SITE_TYPE", "sadigh_site_type", to_db=map_enum,
              java_name="Sadigh Site Type")
 define_param('SOURCE_MODEL_LT_RANDOM_SEED', 'source_model_lt_random_seed',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
-             to_job=int)
+             modes=('classical', 'event_based', 'disaggregation'), to_job=int)
 define_param('STANDARD_DEVIATION_TYPE', 'standard_deviation_type',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_db=map_enum)
 define_param('TRUNCATION_LEVEL', 'truncation_level', to_job=int)
 define_param('WIDTH_OF_MFD_BIN', 'width_of_mfd_bin',
-             modes=('classical', 'event_based', 'disaggregation', 'uhs'),
+             modes=('classical', 'event_based', 'disaggregation'),
              to_job=float)
--- a/openquake/utils/__init__.py
+++ b/openquake/utils/__init__.py
@@ -3,8 +3,6 @@
 
 import decimal
 
-from openquake import java
-
 
 def round_float(value):
     """
@@ -30,15 +28,3 @@
         decimal.Decimal(str(value)).quantize(
             decimal.Decimal(quantize_str),
             rounding=decimal.ROUND_HALF_EVEN))
-
-
-def list_to_jdouble_array(float_list):
-    """Convert a 1D list of floats to a 1D Java Double[] (as a jpype object).
-    """
-    jp = java.jvm()
-    jdouble = jp.JArray(jp.java.lang.Double)(len(float_list))
-
-    for i, val in enumerate(float_list):
-        jdouble[i] = jp.JClass('java.lang.Double')(val)
-
-    return jdouble
