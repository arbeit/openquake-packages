--- a/openquake/db/models.py
+++ b/openquake/db/models.py
@@ -17,6 +17,7 @@
 # version 3 along with OpenQuake.  If not, see
 # <http://www.gnu.org/licenses/lgpl-3.0.txt> for a copy of the LGPLv3 License.
 
+# pylint: disable=C0302
 
 '''
 Model representations of the OpenQuake DB tables.
@@ -551,7 +552,8 @@
     # the default is 3.0 and document it. I definitely don't remember why it's
     # 3.0.
     truncation_level = models.FloatField(default=3.0)
-    reference_vs30_value = models.FloatField()
+    reference_vs30_value = models.FloatField(
+        "Average shear-wave velocity in the upper 30 meters of a site")
     imls = FloatArrayField(null=True)
     poes = FloatArrayField(null=True)
     realizations = models.IntegerField(null=True)
@@ -655,9 +657,17 @@
     #   latlonpmf (Latitude-Longitude PMF)
     #   latlonmagpmf (Latitude-Longitude-Magnitude PMF)
     #   latlonmagepspmf (Latitude-Longitude-Magnitude-Epsilon PMF)
+    #   magtrtpmf (Magnitude-Tectonic Region Type PMF)
+    #   latlontrtpmf (Latitude-Longitude-Tectonic Region Type PMF)
     #   fulldisaggmatrix (The full disaggregation matrix; includes
     #       Lat, Lon, Magnitude, Epsilon, and Tectonic Region Type)
     disagg_results = CharArrayField(null=True)
+    VS30_TYPE_CHOICES = (
+       (u"measured", u"Value obtained from on-site measurements"),
+       (u"inferred", u"Estimated value"),
+    )
+    vs30_type = models.TextField(choices=VS30_TYPE_CHOICES, default="measured")
+    depth_to_1pt_0km_per_sec = models.FloatField(default=100.0)
 
     class Meta:  # pylint: disable=C0111,W0232
         db_table = 'uiapi\".\"oq_params'
@@ -801,6 +811,7 @@
     end_branch_label = models.TextField(null=True)
     category = models.TextField(null=True)
     unit = models.TextField(null=True)
+    timespan = models.FloatField(null=True)
     poe = models.FloatField(null=True)
 
     class Meta:  # pylint: disable=C0111,W0232
--- a/openquake/db/schema/comments.sql
+++ b/openquake/db/schema/comments.sql
@@ -234,6 +234,7 @@
 COMMENT ON COLUMN riskr.loss_map.end_branch_label IS 'End branch label';
 COMMENT ON COLUMN riskr.loss_map.category IS 'Loss category (e.g. economic_loss).';
 COMMENT ON COLUMN riskr.loss_map.unit IS 'Unit of measurement';
+COMMENT ON COLUMN riskr.loss_map.timespan IS 'timespan of years (for non deterministic loss maps, i.e. classical/probabilistic)';
 COMMENT ON COLUMN riskr.loss_map.poe IS 'Probability of exceedance (for probabilistic loss maps)';
 
 
--- a/openquake/db/schema/load.sql
+++ b/openquake/db/schema/load.sql
@@ -14,4 +14,4 @@
 INSERT INTO admin.organization(name) VALUES('GEM Foundation');
 INSERT INTO admin.oq_user(user_name, full_name, organization_id) VALUES('openquake', 'Default user', 1);
 
-INSERT INTO admin.revision_info(artefact, revision, step) VALUES('openquake', '0.4.4', 0);
+INSERT INTO admin.revision_info(artefact, revision, step) VALUES('openquake', '0.4.4', 15);
--- a/openquake/db/schema/openquake.sql
+++ b/openquake/db/schema/openquake.sql
@@ -969,6 +969,8 @@
     --      latlonpmf (Latitude-Longitude PMF)
     --      latlonmagpmf (Latitude-Longitude-Magnitude PMF)
     --      latlonmagepspmf (Latitude-Longitude-Magnitude-Epsilon PMF)
+    --      magtrtpmf (Magnitude-Tectonic Region Type PMF)
+    --      latlontrtpmf (Latitude-Longitude-Tectonic Region Type PMF)
     --      fulldisaggmatrix (The full disaggregation matrix; includes
     --          Lat, Lon, Magnitude, Epsilon, and Tectonic Region Type)
     disagg_results VARCHAR[]
@@ -980,10 +982,16 @@
                                          'magdistpmf', 'magdistepspmf',
                                          'latlonpmf', 'latlonmagpmf',
                                          'latlonmagepspmf',
+                                         'magtrtpmf', 'latlontrtpmf',
                                          'fulldisaggmatrix']::VARCHAR[]))
             OR
             ((job_type != 'disaggregation')
             AND (disagg_results IS NULL)))),
+    depth_to_1pt_0km_per_sec float NOT NULL DEFAULT 100.0
+        CONSTRAINT depth_to_1pt_0km_per_sec_above_zero
+        CHECK(depth_to_1pt_0km_per_sec > 0.0),
+    vs30_type VARCHAR NOT NULL DEFAULT 'measured' CONSTRAINT vs30_type_value
+        CHECK(vs30_type IN ('measured', 'inferred')),
     -- timestamp
     last_update timestamp without time zone
         DEFAULT timezone('UTC'::text, now()) NOT NULL
@@ -1133,6 +1141,8 @@
     end_branch_label VARCHAR,
     category VARCHAR,
     unit VARCHAR, -- e.g. USD, EUR
+    timespan float CONSTRAINT valid_timespan
+        CHECK (timespan > 0.0),
     -- poe is significant only for non-deterministic calculations
     poe float CONSTRAINT valid_poe
         CHECK ((NOT deterministic AND (poe >= 0.0) AND (poe <= 1.0))
--- a/openquake/hazard/deterministic.py
+++ b/openquake/hazard/deterministic.py
@@ -160,7 +160,7 @@
         gmpe = deserializer.deserialize(
             java.jclass("JsonPrimitive")(fqn), None, None)
 
-        tree_data = java.jclass("GmpeLogicTreeData")()
+        tree_data = java.jclass("GmpeLogicTreeData")
 
         tree_data.setGmpeParams(
             self.params["COMPONENT"],
--- a/openquake/hazard/opensha.py
+++ b/openquake/hazard/opensha.py
@@ -25,6 +25,7 @@
 import multiprocessing
 import numpy
 import random
+import functools
 
 from itertools import izip
 
@@ -38,6 +39,7 @@
 from openquake.hazard import job
 from openquake.hazard import tasks
 from openquake.job.mixins import Mixin
+from openquake.input import logictree
 from openquake.output import hazard as hazard_output
 from openquake.utils import config
 from openquake.utils import tasks as utils_tasks
@@ -58,16 +60,29 @@
 HAZARD_MAP_FILENAME_PREFIX = 'hazardmap'
 
 
-def preload(fn):
-    """A decorator for preload steps that must run on the Jobber node"""
+def create_java_cache(fn):
+    """A decorator for creating java cache object"""
 
-    def preloader(self, *args, **kwargs):
-        """Validate job"""
+    @functools.wraps(fn)
+    def decorated(self, *args, **kwargs):  # pylint: disable=C0111
         self.cache = java.jclass("KVS")(
                 config.get("kvs", "host"),
                 int(config.get("kvs", "port")))
-        self.calc = java.jclass("LogicTreeProcessor")(
-                self.cache, self.key)
+        return fn(self, *args, **kwargs)
+
+    return decorated
+
+
+def preload(fn):
+    """A decorator for preload steps that must run on the Jobber node"""
+
+    @functools.wraps(fn)
+    def preloader(self, *args, **kwargs):  # pylint: disable=C0111
+        source_model_lt = self.params.get('SOURCE_MODEL_LOGIC_TREE_FILE_PATH')
+        gmpe_lt = self.params.get('GMPE_LOGIC_TREE_FILE_PATH')
+        basepath = self.params.get('BASE_PATH')
+        self.calc = logictree.LogicTreeProcessor(basepath, source_model_lt,
+                                                 gmpe_lt)
         return fn(self, *args, **kwargs)
     return preloader
 
@@ -96,33 +111,20 @@
     """Contains common functionality for PSHA Mixins."""
 
     def store_source_model(self, seed):
-        """Generates an Earthquake Rupture Forecast, using the source zones and
-        logic trees specified in the job config file. Note that this has to be
-        done currently using the file itself, since it has nested references to
-        other files."""
-
+        """Generates a source model from the source model logic tree."""
         LOG.info("Storing source model from job config")
         key = kvs.tokens.source_model_key(self.job_id)
         print "source model key is", key
-        jpype = java.jvm()
-        try:
-            self.calc.sampleAndSaveERFTree(self.cache, key, seed)
-        except jpype.JavaException, ex:
-            unwrap_validation_error(
-                jpype, ex,
-                self.params.get("SOURCE_MODEL_LOGIC_TREE_FILE"))
+        mfd_bin_width = float(self.params.get('WIDTH_OF_MFD_BIN'))
+        self.calc.sample_and_save_source_model_logictree(kvs, key, seed,
+                                                         mfd_bin_width)
 
     def store_gmpe_map(self, seed):
         """Generates a hash of tectonic regions and GMPEs, using the logic tree
         specified in the job config file."""
         key = kvs.tokens.gmpe_key(self.job_id)
         print "GMPE map key is", key
-        jpype = java.jvm()
-        try:
-            self.calc.sampleAndSaveGMPETree(self.cache, key, seed)
-        except jpype.JavaException, ex:
-            unwrap_validation_error(
-                jpype, ex, self.params.get("GMPE_LOGIC_TREE_FILE"))
+        self.calc.sample_and_save_gmpe_logictree(kvs, key, seed)
 
     def generate_erf(self):
         """Generate the Earthquake Rupture Forecast from the currently stored
@@ -131,16 +133,17 @@
         sources = java.jclass("JsonSerializer").getSourceListFromCache(
                     self.cache, key)
         erf = java.jclass("GEM1ERF")(sources)
-        self.calc.setGEM1ERFParams(erf)
+        calc = java.jclass("LogicTreeProcessor")(self.cache, self.key)
+        calc.setGEM1ERFParams(erf)
         return erf
 
     def set_gmpe_params(self, gmpe_map):
         """Push parameters from configuration file into the GMPE objects"""
         jpype = java.jvm()
-        gmpe_lt_data = self.calc.createGmpeLogicTreeData()
+        set_gmpe_params = java.jclass("GmpeLogicTreeData").setGmpeParams
         for tect_region in gmpe_map.keySet():
             gmpe = gmpe_map.get(tect_region)
-            gmpe_lt_data.setGmpeParams(self.params['COMPONENT'],
+            set_gmpe_params(self.params['COMPONENT'],
                 self.params['INTENSITY_MEASURE_TYPE'],
                 jpype.JDouble(float(self.params['PERIOD'])),
                 jpype.JDouble(float(self.params['DAMPING'])),
@@ -187,9 +190,19 @@
                     self.params['REFERENCE_DEPTH_TO_2PT5KM_PER_SEC_PARAM']))
             sadigh = java.jclass("StringParameter")("Sadigh Site Type")
             sadigh.setValue(self.params['SADIGH_SITE_TYPE'])
+
+            depth1km = java.jclass("DoubleParameter")(jpype.JString(
+                "Depth 1.0 km/sec"))
+            depth1km.setValue(float(self.params['DEPTHTO1PT0KMPERSEC']))
+            vs30_type = java.jclass("StringParameter")("Vs30 Type")
+            # Enum values must be capitalized in the Java domain!
+            vs30_type.setValue(self.params['VS30_TYPE'].capitalize())
+
             site.addParameter(vs30)
             site.addParameter(depth25)
             site.addParameter(sadigh)
+            site.addParameter(depth1km)
+            site.addParameter(vs30_type)
             jsite_list.add(site)
         return jsite_list
 
@@ -393,6 +406,7 @@
 
     @java.jexception
     @preload
+    @create_java_cache
     def execute(self):
         """
         Trigger the calculation and serialization of hazard curves, mean hazard
@@ -603,7 +617,7 @@
 
         return nrml_path
 
-    @preload
+    @create_java_cache
     def compute_hazard_curve(self, sites, realization):
         """ Compute hazard curves, write them to KVS as JSON,
         and return a list of the KVS keys for each curve. """
@@ -709,6 +723,7 @@
 
     @java.jexception
     @preload
+    @create_java_cache
     def execute(self):
         """Main hazard processing block.
 
@@ -789,7 +804,7 @@
                 files.append(nrml_path)
         return files
 
-    @preload
+    @create_java_cache
     def compute_ground_motion_fields(self, site_list, history, realization,
                                      seed):
         """Ground motion field calculation, runs on the workers."""
--- /dev/null
+++ b/openquake/input/logictree.py
@@ -0,0 +1,1078 @@
+# -*- coding: utf-8 -*-
+
+# Copyright (c) 2010-2011, GEM Foundation.
+#
+# OpenQuake is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Lesser General Public License version 3
+# only, as published by the Free Software Foundation.
+#
+# OpenQuake is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Lesser General Public License version 3 for more details
+# (a copy is included in the LICENSE file that accompanied this code).
+#
+# You should have received a copy of the GNU Lesser General Public License
+# version 3 along with OpenQuake.  If not, see
+# <http://www.gnu.org/licenses/lgpl-3.0.txt> for a copy of the LGPLv3 License.
+
+"""
+Logic tree parser, verifier and processor. See specs
+at https://blueprints.launchpad.net/openquake/+spec/openquake-logic-tree-module
+"""
+# pylint: disable=C0302
+
+import os
+import re
+import random
+import itertools
+from decimal import Decimal
+try:
+    import simplejson as json
+except ImportError:
+    import json
+
+from lxml import etree
+
+from openquake.nrml import nrml_schema_file
+from openquake.java import jvm
+
+
+class LogicTreeError(Exception):
+    """
+    Base class for errors of loading, parsing and validation of logic trees.
+
+    :param filename:
+        The name of the file which contains an error. Supposed
+        to be relative to ``basepath``.
+    :param basepath:
+        Base path as given to :class:`LogicTree` constructor.
+    """
+    def __init__(self, filename, basepath, msg):
+        super(LogicTreeError, self).__init__(msg)
+        self.filename = filename
+        self.basepath = basepath
+
+    def get_filepath(self):
+        """
+        Reconstruct and return absolute path to affected file.
+        """
+        return os.path.join(self.basepath, self.filename)
+
+    def __str__(self):
+        return 'file %r: %s' % (self.get_filepath(), self.message)
+
+
+class ParsingError(LogicTreeError):
+    """
+    XML file failed to load: it is not readable or contains invalid xml.
+    """
+
+
+class ValidationError(LogicTreeError):
+    """
+    Logic tree file contains a logic error.
+
+    :param node:
+        XML node object that causes fail. Used to determine
+        the affected line number.
+
+    All other constructor parameters are passed to :class:`superclass'
+    <LogicTreeError>` constructor.
+    """
+    def __init__(self, node, *args, **kwargs):
+        super(ValidationError, self).__init__(*args, **kwargs)
+        self.lineno = node.sourceline
+
+    def __str__(self):
+        return 'file %r line %r: %s' % (self.get_filepath(), self.lineno,
+                                        self.message)
+
+
+class Branch(object):
+    """
+    Branch object, represents a ``<logicTreeBranch />`` element.
+
+    :param branch_id:
+        Value of ``@branchID`` attribute.
+    :param weight:
+        Decimal value of weight assigned to the branch. A text node contents
+        of ``<uncertaintyWeight />`` child node.
+    :param value:
+        The actual uncertainty parameter value. A text node contents
+        of ``<uncertaintyModel />`` child node. Type depends
+        on the branchset's uncertainty type.
+    """
+    def __init__(self, branch_id, weight, value):
+        self.branch_id = branch_id
+        self.weight = weight
+        self.value = value
+        self.child_branchset = None
+
+
+class BranchSet(object):
+    """
+    Branchset object, represents a ``<logicTreeBranchSet />`` element.
+
+    :param uncertainty_type:
+        String value. According to the spec one of:
+
+        gmpeModel
+            Branches contain references to different GMPEs. Values are parsed
+            as strings and are supposed to be one of supported GMPEs. See list
+            at :class:`GMPELogicTree`.
+        sourceModel
+            Branches contain references to different PSHA source models. Values
+            are treated as file names, relatively to base path.
+        maxMagGRRelative
+            Different values to add to Gutenberg-Richter ("GR") maximum
+            magnitude. Value should be interpretable as float.
+        bGRRelative
+            Values to add to GR "b" value. Parsed as float.
+        maxMagGRAbsolute
+            Values to replace GR maximum magnitude. Values expected to be
+            lists of floats separated by space, one float for each GR MFD
+            in a target source in order of appearance.
+        abGRAbsolute
+            Values to replace "a" and "b" values of GR MFD. Lists of pairs
+            of floats, one pair for one GR MFD in a target source.
+
+    :param filters:
+        Dictionary, a set of filters to specify which sources should
+        the uncertainty be applied to. Represented as branchset element's
+        attributes in xml:
+
+        applyToSources
+            The uncertainty should be applied only to specific sources.
+            This filter is required for absolute uncertainties (also
+            only one source can be used for those). Value should be the list
+            of source ids. Can be used only in source model logic tree.
+        applyToSourceType
+            Can be used in the source model logic tree definition. Allows
+            to specify to which source type (area, point, simple fault,
+            complex fault) the uncertainty applies to.
+        applyToTectonicRegionType
+            Can be used in both the source model and GMPE logic trees. Allows
+            to specify to which tectonic region type (Active Shallow Crust,
+            Stable Shallow Crust, etc.) the uncertainty applies to. This
+            filter is required for all branchsets in GMPE logic tree.
+    """
+    def __init__(self, uncertainty_type, filters):
+        self.branches = []
+        self.uncertainty_type = uncertainty_type
+        self.filters = filters
+
+    def sample(self, rnd=random):
+        """
+        Take a random branch (with respect to their weights) and return it.
+
+        :param rnd:
+            Random object. Should have method ``random()`` -- return uniformly
+            distributed random float number >= 0 and < 1.
+        :return:
+            :class:`Branch` object, one of branches in the branchet's list.
+        """
+        # Draw a random number and iterate through the branches in the set
+        # (adding up their weights) until the random value falls into
+        # the interval occupied by a branch. Return the latter.
+        diceroll = rnd.random()
+        acc = 0
+        for branch in self.branches:
+            acc += branch.weight
+            if acc >= diceroll:
+                return branch
+        raise AssertionError('do weights really sum up to 1.0?')
+
+    @classmethod
+    def _is_gr_mfd(cls, mfd):
+        """
+        Return ``True`` if ``mfd`` is opensha GR MFD object
+        (and in particular not evenly discretized function).
+        """
+        classname = 'org.opensha.sha.magdist.GutenbergRichterMagFreqDist'
+        return isinstance(mfd, jvm().JClass(classname))
+
+    @classmethod
+    def _is_point(cls, source):
+        """
+        Return ``True`` if ``source`` is opensha source of point type.
+        """
+        classname = 'org.opensha.sha.earthquake.rupForecastImpl.' \
+                    'GEM1.SourceData.GEMPointSourceData'
+        return isinstance(source, jvm().JClass(classname))
+
+    @classmethod
+    def _is_simplefault(cls, source):
+        """
+        Return ``True`` if ``source`` is opensha source of simple fault type.
+        """
+        classname = 'org.opensha.sha.earthquake.rupForecastImpl.' \
+                    'GEM1.SourceData.GEMFaultSourceData'
+        return isinstance(source, jvm().JClass(classname))
+
+    @classmethod
+    def _is_complexfault(cls, source):
+        """
+        Return ``True`` if ``source`` is opensha source of complex fault type.
+        """
+        classname = 'org.opensha.sha.earthquake.rupForecastImpl.' \
+                    'GEM1.SourceData.GEMSubductionFaultSourceData'
+        return isinstance(source, jvm().JClass(classname))
+
+    @classmethod
+    def _is_area(cls, source):
+        """
+        Return ``True`` if ``source`` is opensha source of area type.
+        """
+        classname = 'org.opensha.sha.earthquake.rupForecastImpl.' \
+                    'GEM1.SourceData.GEMAreaSourceData'
+        return isinstance(source, jvm().JClass(classname))
+
+    def filter_source(self, source):
+        # pylint: disable=R0911,R0912
+        """
+        Apply filters to ``source`` and return ``True`` if uncertainty should
+        be applied to it.
+        """
+        for key, value in self.filters.items():
+            if key == 'applyToTectonicRegionType':
+                if value != source.tectReg.name:
+                    return False
+            elif key == 'applyToSourceType':
+                if value == 'area':
+                    if not self._is_area(source):
+                        return False
+                elif value == 'point':
+                    if not self._is_point(source):
+                        return False
+                elif value == 'simpleFault':
+                    if not self._is_simplefault(source):
+                        return False
+                elif value == 'complexFault':
+                    if not self._is_complexfault(source):
+                        return False
+                else:
+                    raise AssertionError('unknown source type %r' % value)
+            elif key == 'applyToSources':
+                if source.id not in value:
+                    return False
+            else:
+                raise AssertionError('unknown filter %r' % key)
+        # All filters pass, return True.
+        return True
+
+    def apply_uncertainty(self, value, source):
+        """
+        Apply this branchset's uncertainty with value ``value`` to source
+        ``source``, if it passes :meth:`filters <filter_source>`.
+
+        This method is not called for uncertainties of types "gmpeModel"
+        and "sourceModel".
+
+        :param value:
+            The actual uncertainty value of :meth:`sampled <sample>` branch.
+            Type depends on uncertainty type.
+        :param source:
+            The opensha source data object.
+        :return:
+            ``None``, all changes are applied to MFD in place. Therefore
+            all sources have to be reinstantiated after processing is done
+            in order to sample the tree once again.
+        """
+        if not self.filter_source(source):
+            return
+
+        # TODO: handle exceptions in java methods and rethrow LogicTreeError
+        if self._is_complexfault(source) or self._is_simplefault(source):
+            # simple fault or complex fault - only one mfd always
+            mfdlist = [source.getMfd()]
+        elif self._is_point(source):
+            # point
+            mfdlist = source.getHypoMagFreqDistAtLoc().getMagFreqDistList()
+        elif self._is_area(source):
+            # area
+            mfdlist = source.getMagfreqDistFocMech().getMagFreqDistList()
+        else:
+            raise AssertionError('type of source %r is unknown' % source)
+
+        if self.uncertainty_type in ('abGRAbsolute', 'maxMagGRAbsolute'):
+            # Absolute uncertainties have lists of values -- one for each
+            # GR MFD in order of appearance.
+            valuelist = iter(value)
+        else:
+            # All other uncertainties always have one value which applies
+            # to all mfds, no matter how many are there.
+            valuelist = itertools.repeat(value)
+
+        for mfd in mfdlist:
+            # ignore all non-GR mfds
+            if self._is_gr_mfd(mfd):
+                mfd_value = next(valuelist)
+                self._apply_uncertainty_to_mfd(mfd, mfd_value)
+
+    def _apply_uncertainty_to_mfd(self, mfd, value):
+        """
+        Modify ``mfd`` object with uncertainty value ``value``.
+        """
+        # Need to cast to floats explicitly to make calls match java
+        # methods signatures in case when value is an integer.
+        if self.uncertainty_type == 'abGRAbsolute':
+            a, b = value
+            mfd.setAB(float(a), float(b))
+        elif self.uncertainty_type == 'bGRRelative':
+            mfd.incrementB(float(value))
+        elif self.uncertainty_type == 'maxMagGRRelative':
+            mfd.incrementMagUpper(float(value))
+        elif self.uncertainty_type == 'maxMagGRAbsolute':
+            mfd.setMagUpper(float(value))
+        else:
+            raise AssertionError('what is %s btw?' % self.uncertainty_type)
+
+
+class BaseLogicTree(object):
+    """
+    Common code for logic tree readers, parsers and verifiers --
+    :class:`GMPELogicTree` and :class:`SourceModelLogicTree`.
+
+    :param basepath:
+        Base path for logic tree itself and all files that it references.
+    :param filename:
+        Name of logic tree file, supposed to be relative to ``basepath``.
+    :raises ParsingError:
+        If logic tree file or any of the referenced files is unable to read
+        or parse.
+    :raises ValidationError:
+        If logic tree file has a logic error, which can not be prevented
+        by xml schema rules (like referencing sources with missing id).
+    """
+    NRML = 'http://openquake.org/xmlns/nrml/0.2'
+    FILTERS = ('applyToTectonicRegionType',
+               'applyToSources',
+               'applyToSourceType')
+
+    _xmlschema = None
+
+    @classmethod
+    def get_xmlschema(cls):
+        """
+        Create (if needed) and return ``etree.XMLSchema`` object
+        for verifying nrml-files correctness.
+
+        Once created schema object is cached in ``_xmlschema``
+        class attribute.
+        """
+        if not cls._xmlschema:
+            cls._xmlschema = etree.XMLSchema(file=nrml_schema_file())
+        return cls._xmlschema
+
+    def __init__(self, basepath, filename):
+        self.basepath = basepath
+        self.filename = filename
+        parser = etree.XMLParser(schema=self.get_xmlschema())
+        self.branches = {}
+        self.open_ends = set()
+        filestream = self._open_file(self.filename)
+        try:
+            tree = etree.parse(filestream, parser=parser)
+        except etree.XMLSyntaxError as exc:
+            # Wrap etree parsing exception to :exc:`ParsingError`.
+            raise ParsingError(self.filename, self.basepath, str(exc))
+        [tree] = tree.getroot().findall('{%s}logicTree' % self.NRML)
+        self.root_branchset = None
+        self.parse_tree(tree)
+
+    def parse_tree(self, tree_node):
+        """
+        Parse the whole tree and point ``root_branchset`` attribute
+        to the tree's root. Calls :meth:`validate_tree` when done.
+        """
+        levels = tree_node.findall('{%s}logicTreeBranchingLevel' % self.NRML)
+        for depth, branchinglevel_node in enumerate(levels):
+            self.parse_branchinglevel(branchinglevel_node, depth)
+        self.root_branchset = self.validate_tree(tree_node,
+                                                 self.root_branchset)
+
+    def _open_file(self, filename):
+        """
+        Open file named ``filename`` and return the file object.
+
+        :param fileame:
+            String, should be relative to tree's base path.
+        :raises ParsingError:
+            If file can not be opened.
+        """
+        # This was extracted to method mainly to simplify unittesting.
+        try:
+            return open(os.path.join(self.basepath, filename))
+        except IOError as exc:
+            raise ParsingError(filename, self.basepath, str(exc))
+
+    def parse_branchinglevel(self, branchinglevel_node, depth):
+        """
+        Parse one branching level.
+
+        :param branchinglevel_node:
+            ``etree.Element`` object with tag "logicTreeBranchingLevel".
+        :param depth:
+            The sequential number of this branching level, based on 0.
+
+        Enumerates children branchsets and call :meth:`parse_branchset`,
+        :meth:`validate_branchset`, :meth:`parse_branches` and finally
+        :meth:`apply_branchset` for each.
+
+        Keeps track of "open ends" -- the set of branches that don't have
+        any child branchset on this step of execution. After processing
+        of every branching level only those branches that are listed in it
+        can have child branchsets (if there is one on the next level).
+        """
+        new_open_ends = set()
+        branchsets = branchinglevel_node.findall('{%s}logicTreeBranchSet' %
+                                                self.NRML)
+        for number, branchset_node in enumerate(branchsets):
+            branchset = self.parse_branchset(branchset_node)
+            branchset = self.validate_branchset(branchset_node, depth, number,
+                                                branchset)
+            self.parse_branches(branchset_node, branchset)
+            if depth == 0 and number == 0:
+                self.root_branchset = branchset
+            else:
+                self.apply_branchset(branchset_node, branchset)
+            for branch in branchset.branches:
+                new_open_ends.add(branch)
+        self.open_ends.clear()
+        self.open_ends.update(new_open_ends)
+
+    def parse_branchset(self, branchset_node):
+        """
+        Create :class:`BranchSet` object using data in ``branchset_node``.
+
+        :param branchset_node:
+            ``etree.Element`` object with tag "logicTreeBranchSet".
+        :returns:
+            An instance of :class:`BranchSet` with filters applied but with
+            no branches (they're attached in :meth:`parse_branches`).
+        """
+        uncertainty_type = branchset_node.get('uncertaintyType')
+        filters = dict((filtername, branchset_node.get(filtername))
+                       for filtername in self.FILTERS
+                       if filtername in branchset_node.attrib)
+        filters = self.validate_filters(branchset_node, uncertainty_type,
+                                        filters)
+        branchset = BranchSet(uncertainty_type, filters)
+        return branchset
+
+    def parse_branches(self, branchset_node, branchset):
+        """
+        Create and attach branches at ``branchset_node`` to ``branchset``.
+
+        :param branchset_node:
+            Same as for :meth:`parse_branchset`.
+        :param branchset:
+            An instance of :class:`BranchSet`.
+
+        Checks that each branch has :meth:`valid <validate_uncertainty_value>`
+        value, unique id and that all branches have total weight of 1.0.
+
+        :return:
+            ``None``, all branches are attached to provided branchset.
+        """
+        weight_sum = 0
+        branches = branchset_node.findall('{%s}logicTreeBranch' % self.NRML)
+        for branchnode in branches:
+            weight = branchnode.find('{%s}uncertaintyWeight' % self.NRML).text
+            weight = Decimal(weight.strip())
+            weight_sum += weight
+            value_node = branchnode.find('{%s}uncertaintyModel' % self.NRML)
+            value = self.validate_uncertainty_value(
+                value_node, branchset, value_node.text.strip()
+            )
+            branch_id = branchnode.get('branchID')
+            branch = Branch(branch_id, weight, value)
+            if branch_id in self.branches:
+                raise ValidationError(
+                    branchnode, self.filename, self.basepath,
+                    "branchID %r is not unique" % branch_id
+                )
+            self.branches[branch_id] = branch
+            branchset.branches.append(branch)
+        if weight_sum != 1.0:
+            raise ValidationError(
+                branchset_node, self.filename, self.basepath,
+                "branchset weights don't sum up to 1.0"
+            )
+
+    def apply_branchset(self, branchset_node, branchset):
+        # pylint: disable=W0613
+        """
+        Apply ``branchset`` to all "open end" branches.
+        See :meth:`parse_branchinglevel`.
+
+        :param branchset_node:
+            Same as for :meth:`parse_branchset`.
+        :param branchset:
+            An instance of :class:`BranchSet` to make it child
+            for "open-end" branches.
+
+        Can be overridden by subclasses if they want to apply branchests
+        to branches selectively.
+        """
+        for branch in self.open_ends:
+            branch.child_branchset = branchset
+
+    def validate_tree(self, tree_node, root_branchset):
+        """
+        Check the whole parsed tree for consistency and sanity.
+
+        Abstract method, must be overriden by subclasses.
+
+        :param tree_node:
+            ``etree.Element`` object with tag "logicTree".
+        :param root_branchset:
+            An instance of :class:`BranchSet` which is about to become
+            the root branchset for this tree.
+        :return:
+            An object to make it root branchset.
+        """
+        raise NotImplementedError()
+
+    def validate_uncertainty_value(self, node, branchset, value):
+        """
+        Check the value ``value`` for correctness to be set for one
+        of branchet's branches.
+
+        Abstract method, must be overriden by subclasses.
+
+        :param node:
+            ``etree.Element`` object with tag "uncertaintyModel" (the one
+            that contains the subject value).
+        :param branchset:
+            An instance of :class:`BranchSet` which will have the branch
+            with provided value attached once it's validated.
+        :param value:
+            The actual value to be checked. Type depends on branchset's
+            uncertainty type.
+        :return:
+            The value to replace an original (for example, with type casted).
+        """
+        raise NotImplementedError()
+
+    def validate_filters(self, node, uncertainty_type, filters):
+        """
+        Check that filters ``filters`` are valid for given uncertainty type.
+
+        Abstract method, must be overriden by subclasses.
+
+        :param node:
+            ``etree.Element`` object with tag "logicTreeBranchSet".
+        :param uncertainty_type:
+            String specifying the uncertainty type.
+            See the list in :class:`BranchSet`.
+        :param filters:
+            Filters dictionary.
+        :return:
+            The filters dictionary to replace an original.
+        """
+        raise NotImplementedError()
+
+    def validate_branchset(self, branchset_node, depth, number, branchset):
+        """
+        Check that branchset is valid.
+
+        Abstract method, must be overriden by subclasses.
+
+        :param branchset_node:
+            ``etree.Element`` object with tag "logicTreeBranchSet".
+        :param depth:
+            The number of branching level that contains the branchset,
+            based on 0.
+        :param number:
+            The number of branchset inside the branching level,
+            based on 0.
+        :param branchset:
+            An instance of :class:`BranchSet`.
+        """
+        raise NotImplementedError()
+
+
+class SourceModelLogicTree(BaseLogicTree):
+    """
+    Source model logic tree parser.
+    """
+    SOURCE_TYPES = ('point', 'area', 'complexFault', 'simpleFault')
+
+    def __init__(self, *args, **kwargs):
+        self.source_ids_to_num_gr_mfds = {}
+        self.tectonic_region_types = set()
+        self.source_types = set()
+        super(SourceModelLogicTree, self).__init__(*args, **kwargs)
+
+    def validate_tree(self, tree_node, root_branchset):
+        """
+        See superclass' method for description and signature specification.
+
+        Does not check anything, returns ``root_branchset`` intact.
+        """
+        return root_branchset
+
+    def validate_uncertainty_value(self, node, branchset, value):
+        """
+        See superclass' method for description and signature specification.
+
+        Checks that the following conditions are met:
+
+        * For uncertainty of type "sourceModel": referenced file must exist
+          and be readable. This is checked in :meth:`collect_source_model_data`
+          along with saving the source model information.
+        * For absolute uncertainties: the number of values must match
+          the number of GR MFDs in source. The source (only one) itself
+          must be referenced in branchset's filter "applyToSources".
+        * For all other cases: value should be a single float value.
+        """
+        _float_re = re.compile(r'^(\+|\-)?(\d+|\d*\.\d+)$')
+        if branchset.uncertainty_type == 'sourceModel':
+            self.collect_source_model_data(value)
+            return os.path.join(self.basepath, value)
+        elif branchset.uncertainty_type == 'abGRAbsolute' \
+                or branchset.uncertainty_type == 'maxMagGRAbsolute':
+            [source_id] = branchset.filters['applyToSources']
+            num_numbers_expected = self.source_ids_to_num_gr_mfds[source_id]
+            assert num_numbers_expected != 0
+            if branchset.uncertainty_type == 'abGRAbsolute':
+                num_numbers_expected *= 2
+            values = []
+            for single_number in value.split():
+                if not _float_re.match(single_number):
+                    break
+                values.append(float(single_number))
+                if len(values) > num_numbers_expected:
+                    break
+            else:
+                if len(values) == num_numbers_expected:
+                    if branchset.uncertainty_type == 'abGRAbsolute':
+                        return zip(*((iter(values), ) * 2))
+                    else:
+                        return values
+            raise ValidationError(
+                node, self.filename, self.basepath,
+                'expected list of %d float(s) separated by space, ' \
+                'as source %r has %d GR MFD(s)' % (num_numbers_expected,
+                source_id, self.source_ids_to_num_gr_mfds[source_id])
+            )
+        else:
+            if not _float_re.match(value):
+                raise ValidationError(
+                    node, self.filename, self.basepath,
+                    'expected single float value'
+                )
+            return float(value)
+
+    def validate_filters(self, branchset_node, uncertainty_type, filters):
+        """
+        See superclass' method for description and signature specification.
+
+        Checks that the following conditions are met:
+
+        * "sourceModel" uncertainties can not have filters.
+        * Absolute uncertainties must have only one filter --
+          "applyToSources", with only one source id.
+        * All other uncertainty types can have either no or one filter.
+        * Filter "applyToSources" must mention only source ids that
+          exist in source models.
+        * Filter "applyToTectonicRegionType" must mention only tectonic
+          region types that exist in source models.
+        * Filter "applyToSourceType" must mention only source types
+          that exist in source models.
+        """
+        if uncertainty_type == 'sourceModel' and filters:
+            raise ValidationError(
+                branchset_node, self.filename, self.basepath,
+                'filters are not allowed on source model uncertainty'
+            )
+        if len(filters) > 1:
+            raise ValidationError(
+                branchset_node, self.filename, self.basepath,
+                "only one filter is allowed per branchset"
+            )
+        if 'applyToSources' in filters:
+            source_ids = filters['applyToSources'].split()
+            nonexistent_source_ids = set(source_ids)
+            nonexistent_source_ids.difference_update(
+                self.source_ids_to_num_gr_mfds
+            )
+            if nonexistent_source_ids:
+                raise ValidationError(
+                    branchset_node, self.filename, self.basepath,
+                    'source ids %s are not defined in source models' %
+                    list(nonexistent_source_ids)
+                )
+            filters['applyToSources'] = source_ids
+        if 'applyToTectonicRegionType' in filters:
+            if not filters['applyToTectonicRegionType'] \
+                    in self.tectonic_region_types:
+                raise ValidationError(
+                    branchset_node, self.filename, self.basepath,
+                    "source models don't define sources of tectonic region " \
+                    "type %r" % filters['applyToTectonicRegionType']
+                )
+        if 'applyToSourceType' in filters:
+            if not filters['applyToSourceType'] in self.source_types:
+                raise ValidationError(
+                    branchset_node, self.filename, self.basepath,
+                    "source models don't define sources of type %r" %
+                    filters['applyToSourceType']
+                )
+
+        if not filters:
+            filter_ = filter_value = None
+        else:
+            [[filter_, filter_value]] = filters.items()
+        if uncertainty_type in ('abGRAbsolute', 'maxMagGRAbsolute'):
+            if not filter_ or not filter_ == 'applyToSources' \
+                    or not len(filter_value) == 1:
+                raise ValidationError(
+                    branchset_node, self.filename, self.basepath,
+                    "uncertainty of type %r must define 'applyToSources' " \
+                    "with only one source id" % uncertainty_type
+                )
+        return filters
+
+    def validate_branchset(self, branchset_node, depth, number, branchset):
+        """
+        See superclass' method for description and signature specification.
+
+        Checks that the following conditions are met:
+
+        * First branching level must contain exactly one branchset, which
+          must be of type "sourceModel".
+        * All other branchsets must not be of type "sourceModel"
+          or "gmpeModel".
+        """
+        if depth == 0:
+            if number > 0:
+                raise ValidationError(
+                    branchset_node, self.filename, self.basepath,
+                    'there must be only one branch set '
+                    'on first branching level'
+                )
+            elif branchset.uncertainty_type != 'sourceModel':
+                raise ValidationError(
+                    branchset_node, self.filename, self.basepath,
+                    'first branchset must define an uncertainty '
+                    'of type "sourceModel"'
+                )
+        else:
+            if branchset.uncertainty_type == 'sourceModel':
+                raise ValidationError(
+                    branchset_node, self.filename, self.basepath,
+                    'uncertainty of type "sourceModel" can be defined '
+                    'on first branchset only'
+                )
+            elif branchset.uncertainty_type == 'gmpeModel':
+                raise ValidationError(
+                    branchset_node, self.filename, self.basepath,
+                    'uncertainty of type "gmpeModel" is not allowed '
+                    'in source model logic tree'
+                )
+        return branchset
+
+    def apply_branchset(self, branchset_node, branchset):
+        """
+        See superclass' method for description and signature specification.
+
+        Parses branchset node's attribute ``@applyToBranches`` to apply
+        following branchests to preceding branches selectively. Branching
+        level can have more than one branchset exactly for this: different
+        branchsets can apply to different open ends.
+
+        Checks that branchset tries to be applied only to branches on previous
+        branching level which do not have a child branchset yet.
+        """
+        apply_to_branches = branchset_node.get('applyToBranches')
+        if apply_to_branches:
+            apply_to_branches = apply_to_branches.split()
+            for branch_id in apply_to_branches:
+                if not branch_id in self.branches:
+                    raise ValidationError(
+                        branchset_node, self.filename, self.basepath,
+                        'branch %r is not yet defined' % branch_id
+                    )
+                branch = self.branches[branch_id]
+                if branch.child_branchset is not None:
+                    raise ValidationError(
+                        branchset_node, self.filename, self.basepath,
+                        'branch %r already has child branchset' % branch_id
+                    )
+                if not branch in self.open_ends:
+                    raise ValidationError(
+                        branchset_node, self.filename, self.basepath,
+                        'applyToBranches must reference only branches '
+                        'from previous branching level'
+                    )
+                branch.child_branchset = branchset
+        else:
+            super(SourceModelLogicTree, self).apply_branchset(branchset_node,
+                                                              branchset)
+
+    def collect_source_model_data(self, filename):
+        """
+        Parse source model file and collect information about source ids,
+        source types and tectonic region types available in it and also
+        the number of GR MFDs for each source. That information is used then
+        for :meth:`validate_filters` and :meth:`validate_uncertainty_value`.
+        """
+        all_source_types = set('{%s}%sSource' % (self.NRML, tagname)
+                               for tagname in self.SOURCE_TYPES)
+        tectonic_region_type_tag = '{%s}tectonicRegion' % self.NRML
+        sourcetype_slice = slice(len('{%s}' % self.NRML), - len('Source'))
+        eventstream = etree.iterparse(self._open_file(filename),
+                                      tag='{%s}*' % self.NRML,
+                                      schema=self.get_xmlschema())
+        while True:
+            try:
+                _, node = next(eventstream)
+            except StopIteration:
+                break
+            except etree.XMLSyntaxError as exc:
+                raise ParsingError(filename, self.basepath, str(exc))
+            if not node.tag in all_source_types:
+                if node.tag == tectonic_region_type_tag:
+                    self.tectonic_region_types.add(node.text)
+            else:
+                source_id = node.attrib['{http://www.opengis.net/gml}id']
+                source_type = node.tag[sourcetype_slice]
+                if source_type == 'point' or source_type == 'area':
+                    mfds = len(node.findall(
+                        '{%s}ruptureRateModel/{%s}truncatedGutenbergRichter' %
+                        (self.NRML, self.NRML)
+                    ))
+                else:
+                    mfds = 1
+                self.source_ids_to_num_gr_mfds[source_id] = mfds
+
+                self.source_types.add(source_type)
+
+                # saving memory by removing already processed nodes.
+                # see http://lxml.de/parsing.html#modifying-the-tree
+                node.clear()
+                parent = node.getparent()
+                prev = node.getprevious()
+                while prev is not None:
+                    parent.remove(prev)
+                    prev = node.getprevious()
+
+
+class GMPELogicTree(BaseLogicTree):
+    """
+    GMPE logic tree parser.
+
+    :param tectonic_region_types:
+        Set of all tectonic region type names that are used in corresponding
+        source models. Used to check that there are GMPEs for each, but
+        no unattended ones.
+    """
+    #: The list of supported GMPEs. List items refer to class names in package
+    #: ``org.opensha.sha.imr.attenRelImpl``.
+    GMPEs = frozenset("""\
+        Abrahamson_2000_AttenRel
+        AS_1997_AttenRel
+        AS_2008_AttenRel
+        AW_2010_AttenRel
+        BA_2008_AttenRel
+        BC_2004_AttenRel
+        BJF_1997_AttenRel
+        BS_2003_AttenRel
+        BW_1997_AttenRel
+        Campbell_1997_AttenRel
+        CB_2003_AttenRel
+        CB_2008_AttenRel
+        CL_2002_AttenRel
+        CS_2005_AttenRel
+        CY_2008_AttenRel
+        DahleEtAl_1995_AttenRel
+        Field_2000_AttenRel
+        GouletEtAl_2006_AttenRel
+        McVerryetal_2000_AttenRel
+        SadighEtAl_1997_AttenRel
+        SEA_1999_AttenRel
+        WC94_DisplMagRel""".split()
+    )
+
+    def __init__(self, tectonic_region_types, *args, **kwargs):
+        self.tectonic_region_types = frozenset(tectonic_region_types)
+        self.defined_tectonic_region_types = set()
+        super(GMPELogicTree, self).__init__(*args, **kwargs)
+
+    def validate_uncertainty_value(self, node, branchset, value):
+        """
+        See superclass' method for description and signature specification.
+
+        Checks that the value is one of :attr:`GMPEs`.
+        """
+        if not value in self.GMPEs:
+            raise ValidationError(
+                node, self.filename, self.basepath,
+                'gmpe %r is not available' % value
+            )
+        return value
+
+    def validate_filters(self, node, uncertainty_type, filters):
+        """
+        See superclass' method for description and signature specification.
+
+        Checks that there is only one filter -- "applyToTectonicRegionType",
+        its value is used only once and appears in the set of types, provided
+        to constructor.
+        """
+        if not filters \
+                or len(filters) > 1 \
+                or filters.keys() != ['applyToTectonicRegionType']:
+            raise ValidationError(
+                node, self.filename, self.basepath,
+                'branch sets in gmpe logic tree must define only '
+                '"applyToTectonicRegionType" filter'
+            )
+        trt = filters['applyToTectonicRegionType']
+        if not trt in self.tectonic_region_types:
+            raise ValidationError(
+                node, self.filename, self.basepath,
+                "source models don't define sources of tectonic region "
+                "type %r" % trt
+            )
+        if trt in self.defined_tectonic_region_types:
+            raise ValidationError(
+                node, self.filename, self.basepath,
+                'gmpe uncertainty for tectonic region type %r has already '
+                'been defined' % trt
+            )
+        self.defined_tectonic_region_types.add(trt)
+        return filters
+
+    def validate_tree(self, tree_node, root_branchset):
+        """
+        See superclass' method for description and signature specification.
+
+        Checks that for all tectonic region types that are defined in source
+        models there is a branchset defined.
+        """
+        missing_trts = self.tectonic_region_types \
+                       - self.defined_tectonic_region_types
+        if missing_trts:
+            raise ValidationError(
+                tree_node, self.filename, self.basepath,
+                'the following tectonic region types are defined '
+                'in source model logic tree but not in gmpe logic tree: %s' %
+                list(sorted(missing_trts))
+            )
+        return root_branchset
+
+    def validate_branchset(self, branchset_node, depth, number, branchset):
+        """
+        See superclass' method for description and signature specification.
+
+        Checks that uncertainty type is "gmpeModel" (only those are allowed)
+        and that there is only one branchset in each branching level.
+        """
+        if not branchset.uncertainty_type == 'gmpeModel':
+            raise ValidationError(
+                branchset_node, self.filename, self.basepath,
+                'only uncertainties of type "gmpeModel" are allowed '
+                'in gmpe logic tree'
+            )
+        if number != 0:
+            raise ValidationError(
+                branchset_node, self.filename, self.basepath,
+                'only one branchset on each branching level is allowed '
+                'in gmpe logic tree'
+            )
+        return branchset
+
+
+class LogicTreeProcessor(object):
+    """
+    Logic tree processor. High-level interface to dealing with logic trees.
+
+    :param basepath:
+        Base path for both logic tree files.
+    :param source_model_logictree_path:
+        Source model logic tree's filename, relative to ``basepath``.
+    :param gmpe_logictree_path:
+        GMPE logic tree's filename, relative to ``basepath``.
+    """
+    def __init__(self, basepath, source_model_logictree_path,
+                 gmpe_logictree_path):
+        self.source_model_lt = SourceModelLogicTree(
+            basepath, source_model_logictree_path
+        )
+        trts = self.source_model_lt.tectonic_region_types
+        self.gmpe_lt = GMPELogicTree(trts, basepath, gmpe_logictree_path)
+
+    def sample_and_save_source_model_logictree(self, cache, key, random_seed,
+                                               mfd_bin_width):
+        """
+        Call :meth:`sample_source_model_logictree` and save the result
+        in the cache.
+
+        :param cache:
+            A cache object. Supposed to have method ``set(key, data)``.
+        :param key:
+            A cache key to save the serialized source model logic tree.
+        """
+        json_result = self.sample_source_model_logictree(random_seed,
+                                                         mfd_bin_width)
+        cache.set(key, json_result)
+
+    def sample_source_model_logictree(self, random_seed, mfd_bin_width):
+        """
+        Perform a Monte-Carlo sampling of source model logic tree.
+
+        :param random_seed:
+            An integer random seed value to initialize random generator
+            before doing random sampling.
+        :param mfd_bin_width:
+            Float, the width of sources' MFD histograms bins.
+        :return:
+            String, json-serialized source model sample. For serialization
+            the java class ``org.gem.JsonSerializer`` is used.
+        """
+        rnd = random.Random(random_seed)
+        sm_reader = jvm().JClass('org.gem.engine.hazard.'
+                                 'parsers.SourceModelReader')
+        branch = self.source_model_lt.root_branchset.sample(rnd)
+        sources = sm_reader(branch.value, float(mfd_bin_width)).read()
+        while True:
+            branchset = branch.child_branchset
+            if branchset is None:
+                break
+            branch = branchset.sample(rnd)
+            for source in sources:
+                branchset.apply_uncertainty(branch.value, source)
+
+        serializer = jvm().JClass('org.gem.JsonSerializer')
+        return serializer.getJsonSourceList(sources)
+
+    def sample_and_save_gmpe_logictree(self, cache, key, random_seed):
+        """
+        Same as :meth:`sample_and_save_source_model_logictree`, but for GMPE
+        logic trees.
+        """
+        cache.set(key, self.sample_gmpe_logictree(random_seed))
+
+    def sample_gmpe_logictree(self, random_seed):
+        """
+        Same as :meth:`sample_source_model_logictree`, but for GMPE logic tree.
+
+        :return:
+            Json dictionary, with keys equal to tectonic region types
+            and values representing fully qualified java GMPE class names.
+        """
+        rnd = random.Random(random_seed)
+        value_prefix = 'org.opensha.sha.imr.attenRelImpl.'
+        result = {}
+        branchset = self.gmpe_lt.root_branchset
+        while branchset:
+            branch = branchset.sample(rnd)
+            trt = branchset.filters['applyToTectonicRegionType']
+            assert trt not in result
+            result[trt] = value_prefix + branch.value
+            branchset = branch.child_branchset
+        return json.dumps(result)
--- a/openquake/java.py
+++ b/openquake/java.py
@@ -29,6 +29,12 @@
 from functools import wraps
 
 from openquake import nrml
+from openquake.utils import config
+
+
+# JVM max. memory size (in MB) to be used (per celery worker process!)
+DEFAULT_JVM_MAX_MEM = 768
+
 
 JAVA_CLASSES = {
     'LogicTreeProcessor': "org.gem.engine.LogicTreeProcessor",
@@ -173,15 +179,56 @@
     jpype.JClass("org.apache.log4j.PropertyConfigurator").configure(props)
 
 
+def get_jvm_max_mem():
+    """
+    Determine what the JVM maximum memory size should be.
+
+    :returns: the maximum JVM memory size considering the possible sources in
+        the following order
+        * the value of the `OQ_JVM_MAXMEM` environment variable
+        * the setting in the config file
+        * a fixed default (`768` MB).
+    """
+
+    def str2int(a_dict, key):
+        """Return `False` unless int(a_dict[key]) yields a valid integer."""
+        if not a_dict:
+            return False
+        val = a_dict.get(key)
+        if val is None:
+            return False
+        val = val.strip()
+        try:
+            val = int(val)
+        except ValueError:
+            return False
+        else:
+            return val
+
+    result = str2int(os.environ, "OQ_JVM_MAXMEM")
+    if result:
+        return result
+
+    result = str2int(config.get_section("java"), "max_mem")
+    if result:
+        return result
+
+    return DEFAULT_JVM_MAX_MEM
+
+
 def jvm():
-    """Return the jpype module, after guaranteeing the JVM is running and
-    the classpath has been loaded properly."""
+    """
+    Return the jpype module, after guaranteeing the JVM is running and
+    the classpath has been loaded properly.
+    """
     jarpaths = (os.path.abspath(
                     os.path.join(os.path.dirname(__file__), "../dist")),
                 '/usr/share/java')
 
     if not jpype.isJVMStarted():
+        max_mem = get_jvm_max_mem()
         jpype.startJVM(jpype.getDefaultJVMPath(),
+            "-Xmx%sM" % max_mem,
             "-Djava.ext.dirs=%s:%s" % jarpaths,
             # setting Schema path here is ugly, but it's better than
             # doing it before all XML parsing calls
--- a/openquake/job/__init__.py
+++ b/openquake/job/__init__.py
@@ -20,9 +20,11 @@
 
 import os
 import re
+import subprocess
 import urlparse
+import logging
 
-from ConfigParser import ConfigParser
+from ConfigParser import ConfigParser, RawConfigParser
 from datetime import datetime
 from django.db import transaction, close_connection
 from django.contrib.gis.db import models
@@ -30,8 +32,10 @@
 from lxml import etree
 
 from openquake import flags
+from openquake import java
 from openquake import kvs
 from openquake import logs
+from openquake import OPENQUAKE_ROOT
 from openquake import shapes
 from openquake import xml
 from openquake.parser import exposure
@@ -47,6 +51,7 @@
     ARRAY_RE)
 from openquake.kvs import mark_job_as_current
 from openquake.logs import LOG
+from openquake.utils import config as oq_config
 
 RE_INCLUDE = re.compile(r'^(.*)_INCLUDE')
 
--- a/openquake/job/config.py
+++ b/openquake/job/config.py
@@ -40,10 +40,13 @@
 SITES = "SITES"
 DETERMINISTIC_MODE = "Deterministic"
 DISAGGREGATION_MODE = "Disaggregation"
-CALCULATION_MODE = "CALCULATION_MODE"
 BASE_PATH = "BASE_PATH"
 COMPUTE_HAZARD_AT_ASSETS = "COMPUTE_HAZARD_AT_ASSETS_LOCATIONS"
 
+DEPTHTO1PT0KMPERSEC = "DEPTHTO1PT0KMPERSEC"
+VS30_TYPE = "VS30_TYPE"
+HAZARD_TASKS = "HAZARD_TASKS"
+
 
 def to_float_array(value):
     """Convert string value to floating point value array"""
@@ -65,7 +68,6 @@
 
     def __str__(self):
         msg = 'The job configuration contained some errors:\n\n'
-
         return msg + '\n'.join(self.errors)
 
 
@@ -80,8 +82,8 @@
             yield v
 
     def is_valid(self):
-        """Return true if all validators defined in this set
-        are valid, false otherwise.
+        """Return `True` if all validators defined in this set
+        are valid, `False` otherwise.
 
         :returns: the status of this set and the related error messages.
         :rtype: when valid, a (True, []) tuple is returned. When invalid, a
@@ -110,7 +112,7 @@
         self.validators.append(validator)
 
 
-class RiskMandatoryParametersValidator(object):
+class MandatoryParamsValidator(object):
     """Validator that checks if the mandatory parameters
     for risk processing are specified."""
 
@@ -119,27 +121,81 @@
         self.params = params
 
     def is_valid(self):
-        """Return true if the mandatory risk parameters are specified,
-        false otherwise. When invalid returns also the error messages.
+        """
+        Return `True` if the mandatory parameters are specified, `False`
+        otherwise.
 
         :returns: the status of this validator and the related error messages.
         :rtype: when valid, a (True, []) tuple is returned. When invalid, a
             (False, [ERROR_MESSAGE#1, ERROR_MESSAGE#2, ..., ERROR_MESSAGE#N])
             tuple is returned
         """
-
-        mandatory_params = [EXPOSURE, INPUT_REGION, REGION_GRID_SPACING]
-
-        if RISK_SECTION in self.sections:
-            for mandatory_param in mandatory_params:
+        if self.SECTION_OF_INTEREST in self.sections:
+            for mandatory_param in self.MANDATORY_PARAMS:
                 if mandatory_param not in self.params.keys():
-                    return (False, [
-                            "With RISK processing, EXPOSURE, REGION_VERTEX " +
-                            "and REGION_GRID_SPACING must be specified"])
+                    msg = ("Parameter '%s' not supplied in section '%s'" %
+                           (mandatory_param, self.SECTION_OF_INTEREST))
+                    return (False, [msg])
 
         return (True, [])
 
 
+class RiskMandatoryParamsValidator(MandatoryParamsValidator):
+    """
+    Validator that checks whether the mandatory parameters
+    for risk processing are specified.
+    """
+    SECTION_OF_INTEREST = RISK_SECTION
+    MANDATORY_PARAMS = [EXPOSURE, INPUT_REGION, REGION_GRID_SPACING]
+
+    def __init__(self, sections, params):
+        super(
+            RiskMandatoryParamsValidator, self).__init__(sections, params)
+
+
+class HazardMandatoryParamsValidator(MandatoryParamsValidator):
+    """
+    Validator that checks whether the mandatory parameters
+    for hazard processing are specified.
+    """
+    SECTION_OF_INTEREST = HAZARD_SECTION
+    MANDATORY_PARAMS = [DEPTHTO1PT0KMPERSEC, VS30_TYPE]
+
+    def __init__(self, sections, params):
+        super(
+            HazardMandatoryParamsValidator, self).__init__(sections, params)
+
+    def is_valid(self):
+        """
+        Return `True` if the mandatory parameters are specified, `False`
+        otherwise.
+
+        This will additionally check that all mandatory hazard parameters have
+        the "java_name" property set.
+
+        :returns: the status of this validator and the related error messages.
+        :rtype: when valid, a (True, []) tuple is returned. When invalid, a
+            (False, [ERROR_MESSAGE#1, ERROR_MESSAGE#2, ..., ERROR_MESSAGE#N])
+            tuple is returned
+        """
+        result, msgs = super(HazardMandatoryParamsValidator, self).is_valid()
+        # The check failed in the base class already, just return.
+        if not result:
+            return (result, msgs)
+        # The check in the base class succeeded. Now -- in addition -- make
+        # sure that we have a 'java_name' set for each mandatory hazard
+        # parameter.
+        params_lacking_java_name = [p for p in self.MANDATORY_PARAMS
+                                    if PARAMS[p].java_name is None]
+        if params_lacking_java_name:
+            msg = ("The following mandatory hazard parameter(s) lack "
+                   "a 'java_name' property: %s"
+                   % ", ".join(params_lacking_java_name))
+            return(False, [msg])
+        else:
+            return (result, msgs)
+
+
 class ComputationTypeValidator(object):
     """Validator that checks if the user has specified the correct
     algorithm to use for grabbing the sites to compute."""
@@ -148,8 +204,8 @@
         self.params = params
 
     def is_valid(self):
-        """Return true if the user has specified the region
-        or the set of sites, false otherwise.
+        """Return `True` if the user has specified the region
+        or the set of sites, `False` otherwise.
         """
         has_input_region = INPUT_REGION in self.params
         has_sites = SITES in self.params
@@ -178,8 +234,8 @@
         self.sections = sections
 
     def is_valid(self):
-        """Return true if the deterministic calculation mode
-        specified is for an hazard + risk job, false otherwise."""
+        """Return `True` if the deterministic calculation mode
+        specified is for an hazard + risk job, `False` otherwise."""
 
         if RISK_SECTION not in self.sections \
                 and self.params[CALCULATION_MODE] == DETERMINISTIC_MODE:
@@ -295,6 +351,69 @@
         return (len(errors) == 0, errors)
 
 
+def validate_single_param(param, name, value, errors):
+    """Validates a single parameter.
+
+    :param param: the parameter to be validated
+    :type param: a `namedtuple` with parameter data. See
+        py:class:`openquake.job.params.Param`
+    :param str name: parameter name
+    :param str value: parameter value
+    :param list errors: string list with parameter validation errors.
+        Another error will be appended to it if the parameter at hand
+        fails to validate.
+    """
+    invalid = False
+    description = ""
+    value = value.strip()
+    try:
+        if param.type in (models.BooleanField,
+                            models.NullBooleanField):
+            description = 'true/false value'
+            invalid = value.lower() not in ('0', '1', 'true', 'false')
+        elif param.type is models.PolygonField:
+            description = 'polygon value'
+            # check the array contains matching pairs and at least 3
+            # vertices (allow an empty array)
+            length = len(to_float_array(value))
+            invalid = length != 0 and (length % 2 == 1 or length < 6)
+        elif param.type is models.MultiPointField:
+            description = 'multi-point value'
+            # just check the array contains matching pairs
+            length = len(to_float_array(value))
+            invalid = length % 2 == 1
+        elif param.type is FloatArrayField:
+            description = 'floating point array value'
+            value = to_float_array(value)
+        elif param.type is CharArrayField:
+            description = 'string array value'
+
+            # before converting to an array of strings,
+            # transform the value to appropriate db input
+            if param.to_db is not None:
+                value = param.to_db(value)
+            value = to_str_array(value)
+        elif param.type is models.FloatField:
+            description = 'floating point value'
+            value = float(value)
+        elif param.type is models.IntegerField:
+            description = 'integer value'
+            value = int(value)
+        elif param.to_db is not None:
+            description = 'value'
+            value = param.to_db(value)
+        else:
+            raise RuntimeError(
+                "Invalid parameter type %s for parameter %s" % (
+                    param.type.__name__, name))
+    except (KeyError, ValueError):
+        invalid = True
+
+    if invalid:
+        errors.append("Value '%s' is not a valid %s for parameter %s" %
+                      (value, description, name))
+
+
 class BasicParameterValidator(object):
     """Validator that checks the type of configuration parameters"""
 
@@ -306,59 +425,15 @@
         errors = []
 
         for name, value in self.params.items():
-            param = PARAMS[name]
-            value = value.strip()
-
-            if param.type in (None, models.TextField) and param.to_db is None:
+            param = PARAMS.get(name)
+            if param is None:
+                # Ignore unknown parameters.
                 continue
-
-            invalid = False
-            try:
-                if param.type in (models.BooleanField,
-                                    models.NullBooleanField):
-                    description = 'true/false value'
-                    invalid = value.lower() not in ('0', '1', 'true', 'false')
-                elif param.type is models.PolygonField:
-                    description = 'polygon value'
-                    # check the array contains matching pairs and at least 3
-                    # vertices (allow an empty array)
-                    length = len(to_float_array(value))
-                    invalid = length != 0 and (length % 2 == 1 or length < 6)
-                elif param.type is models.MultiPointField:
-                    description = 'multi-point value'
-                    # just check the array contains matching pairs
-                    length = len(to_float_array(value))
-                    invalid = length % 2 == 1
-                elif param.type is FloatArrayField:
-                    description = 'floating point array value'
-                    value = to_float_array(value)
-                elif param.type is CharArrayField:
-                    description = 'string array value'
-
-                    # before converting to an array of strings,
-                    # transform the value to appropriate db input
-                    if param.to_db is not None:
-                        value = param.to_db(value)
-                    value = to_str_array(value)
-                elif param.type is models.FloatField:
-                    description = 'floating point value'
-                    value = float(value)
-                elif param.type is models.IntegerField:
-                    description = 'integer value'
-                    value = int(value)
-                elif param.to_db is not None:
-                    description = 'value'
-                    value = param.to_db(value)
-                else:
-                    raise RuntimeError(
-                        "Invalid parameter type %s for parameter %s" % (
-                            param.type.__name__, name))
-            except (KeyError, ValueError):
-                invalid = True
-
-            if invalid:
-                errors.append("Value '%s' is not a valid %s for parameter %s" %
-                              (value, description, name))
+            else:
+                if (param.type in (None, models.TextField)
+                    and param.to_db is None):
+                    continue
+                validate_single_param(param, name, value, errors)
 
         return (len(errors) == 0, errors)
 
@@ -377,7 +452,8 @@
         :py:class:`openquake.config.ValidatorSet`
     """
 
-    exposure = RiskMandatoryParametersValidator(sections, params)
+    hazard = HazardMandatoryParamsValidator(sections, params)
+    exposure = RiskMandatoryParamsValidator(sections, params)
     deterministic = DeterministicComputationValidator(sections, params)
     hazard_comp_type = ComputationTypeValidator(params)
     file_path = FilePathValidator(params)
@@ -389,6 +465,7 @@
     validators.add(exposure)
     validators.add(parameter)
     validators.add(file_path)
+    validators.add(hazard)
 
     if params.get(CALCULATION_MODE) == DISAGGREGATION_MODE:
         validators.add(DisaggregationValidator(params))
--- a/openquake/job/params.py
+++ b/openquake/job/params.py
@@ -31,7 +31,7 @@
 ARRAY_RE = re.compile('[ ,]+')
 
 # pylint: disable=C0103
-Param = namedtuple('Param', 'column type default modes to_db')
+Param = namedtuple('Param', 'column type default modes to_db java_name')
 
 # TODO unify with utils/oqrunner/config_writer.py
 CALCULATION_MODE = {
@@ -82,6 +82,8 @@
     'MagDistEpsPMF': 'magdistepspmf',
     'LatLonPMF': 'latlonpmf',
     'LatLonMagEpsPMF': 'latlonmagepspmf',
+    'MagTRTPMF': 'magtrtpmf',
+    'LatLonTRTPMF': 'latlontrtpmf',
     'FullDisaggMatrix': 'fulldisaggmatrix',
 }
 
@@ -111,7 +113,8 @@
 
 
 # pylint: disable=W0212
-def define_param(name, column, modes=None, default=None, to_db=None):
+def define_param(name, column, modes=None, default=None, to_db=None,
+                 java_name=None):
     """
     Adds a new parameter definition to the PARAMS dictionary
 
@@ -126,6 +129,7 @@
         explicitly defined in a job config.
     :param to_db: A function to transform this parameter for storage in the
         database. Defaults to `None` if no transformation is required.
+    :param str java_name: the name of the parameter in the Java domain.
     """
 
     if modes is None:
@@ -140,11 +144,13 @@
 
     if column == None:
         PARAMS[name] = Param(column=column, type=None, default=default,
-                             modes=modes, to_db=None)
+                             modes=modes, to_db=None, java_name=java_name)
     else:
         column_type = type(OqParams._meta.get_field_by_name(column)[0])
         PARAMS[name] = Param(column=column, type=column_type,
-                             default=default, modes=modes, to_db=to_db)
+                             default=default, modes=modes, to_db=to_db,
+                             java_name=java_name)
+
 
 # general params
 define_param('CALCULATION_MODE', None)
@@ -153,11 +159,15 @@
 define_param('REGION_VERTEX', 'region')
 define_param('OUTPUT_DIR', None)
 define_param('BASE_PATH', None)
-
+define_param("DEPTHTO1PT0KMPERSEC", "depth_to_1pt_0km_per_sec",
+             default=100.0, java_name="Depth 1.0 km/sec")
+define_param("VS30_TYPE", "vs30_type", default="measured",
+             java_name="Vs30 Type")
+define_param("HAZARD_TASKS", None, modes=("classical",))
 
 # input files
 define_param('VULNERABILITY', None)
-define_param('SINGLE_RUPTURE_MODEL', None, modes=('deterministic'))
+define_param("SINGLE_RUPTURE_MODEL", None, modes=("deterministic",))
 define_param('EXPOSURE', None)
 define_param('GMPE_LOGIC_TREE_FILE', None,
              modes=('classical', 'event_based', 'disaggregation'))
@@ -277,13 +287,15 @@
 define_param('PERIOD', 'period', default=0.0)
 define_param('POES', 'poes', modes=('classical', 'disaggregation'))
 define_param('QUANTILE_LEVELS', 'quantile_levels', modes='classical')
-define_param('REFERENCE_DEPTH_TO_2PT5KM_PER_SEC_PARAM',
-             'reference_depth_to_2pt5km_per_sec_param')
-define_param('REFERENCE_VS30_VALUE', 'reference_vs30_value')
+define_param("REFERENCE_DEPTH_TO_2PT5KM_PER_SEC_PARAM",
+             "reference_depth_to_2pt5km_per_sec_param",
+             java_name="Depth 2.5 km/sec")
+define_param("REFERENCE_VS30_VALUE", "reference_vs30_value", java_name="Vs30")
 define_param('RISK_CELL_SIZE', 'risk_cell_size')
 define_param('RUPTURE_SURFACE_DISCRETIZATION',
              'rupture_surface_discretization', modes='deterministic')
-define_param('SADIGH_SITE_TYPE', 'sadigh_site_type', to_db=map_enum)
+define_param("SADIGH_SITE_TYPE", "sadigh_site_type", to_db=map_enum,
+             java_name="Sadigh Site Type")
 define_param('SOURCE_MODEL_LT_RANDOM_SEED', 'source_model_lt_random_seed',
              modes=('classical', 'event_based', 'disaggregation'))
 define_param('STANDARD_DEVIATION_TYPE', 'standard_deviation_type',
--- /dev/null
+++ b/openquake/nrml/schema/examples/disaggregation.xml
@@ -0,0 +1,164 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<nrml xmlns:gml="http://www.opengis.net/gml"
+      xmlns="http://openquake.org/xmlns/nrml/0.2"
+      gml:id="IDXXX">
+    <disaggregationResultField poE="0.1" IMT="PGA" endBranchLabel="1" gml:id="ID000">
+            <disaggregationResultNode gml:id="ID001">
+                    <site>
+                        <gml:Point gml:id="ID002">
+                                <gml:pos>0.0 0.0</gml:pos>
+                        </gml:Point>
+                    </site>
+                    <disaggregationMatrixSet groundMotionValue="0.25">
+                        <disaggregationMatrix disaggregationPMFType="MagnitudePMF">
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0">
+                                <PMFValue>0.5712358122430375</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0">
+                                <PMFValue>0.29011581094474054</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0">
+                                <PMFValue>0.11426899352410452</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0">
+                                <PMFValue>0.024379383288120258</PMFValue>
+                            </disaggregationMatrixValue>
+                        </disaggregationMatrix>
+                        <disaggregationMatrix disaggregationPMFType="MagnitudeDistancePMF">
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0" distanceBin="0.0 20.0">
+                                <PMFValue>0.5119738341488401</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0" distanceBin="20.0 40.0">
+                                <PMFValue>0.059017845649720894</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0" distanceBin="40.0 60.0">
+                                <PMFValue>2.4413244447648748E-4</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0" distanceBin="0.0 20.0">
+                                <PMFValue>0.1260826589262519</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0" distanceBin="20.0 40.0">
+                                <PMFValue>0.14179662905319743</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0" distanceBin="40.0 60.0">
+                                <PMFValue>0.021143296784018918</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0" distanceBin="0.0 20.0">
+                                <PMFValue>0.0222956256157868</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0" distanceBin="20.0 40.0">
+                                <PMFValue>0.06261187407114774</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0" distanceBin="40.0 60.0">
+                                <PMFValue>0.026172273253654746</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0" distanceBin="0.0 20.0">
+                                <PMFValue>0.002410856483027559</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0" distanceBin="20.0 40.0">
+                                <PMFValue>0.011386898679088028</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0" distanceBin="40.0 60.0">
+                                <PMFValue>0.008865269078930038</PMFValue>
+                            </disaggregationMatrixValue>
+                        </disaggregationMatrix>
+                        <disaggregationMatrix disaggregationPMFType="MagnitudeDistanceEpsilonPMF">
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0" distanceBin="0.0 20.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.07347313940931072</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0" distanceBin="0.0 20.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0" distanceBin="40.0 60.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0" distanceBin="0.0 20.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.07877863624842021</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0" distanceBin="20.0 40.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0" distanceBin="40.0 60.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0" distanceBin="0.0 20.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.00931680853091606</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0" distanceBin="20.0 40.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0" distanceBin="40.0 60.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0" distanceBin="0.0 20.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.0011254862137668473</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0" distanceBin="20.0 40.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>4.268519846775424E-4</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0" distanceBin="40.0 60.0" epsilonBin="-1.5 -0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0" distanceBin="0.0 20.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.4007774720000059</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0" distanceBin="0.0 20.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="5.0 6.0" distanceBin="40.0 60.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0" distanceBin="0.0 20.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.007674859547269292</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0" distanceBin="20.0 40.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.0076743607416970856</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="6.0 7.0" distanceBin="40.0 60.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0" distanceBin="0.0 20.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.01178525598425748</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0" distanceBin="20.0 40.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.019903935764837406</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="7.0 8.0" distanceBin="40.0 60.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0" distanceBin="0.0 20.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.0012853702692607117</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0" distanceBin="20.0 40.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.009263963836460708</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue magnitudeBin="8.0 9.0" distanceBin="40.0 60.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.0019997196454611906</PMFValue>
+                            </disaggregationMatrixValue>
+                        </disaggregationMatrix>
+                        <disaggregationMatrix disaggregationPMFType="LatitudeLongitudeMagnitudeEpsilonPMF">
+                            <disaggregationMatrixValue latitudeBin="-0.6 -0.3" longitudeBin="-0.6 -0.3" magnitudeBin="5.0 6.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue latitudeBin="-0.6 -0.3" longitudeBin="-0.3 -0.1" magnitudeBin="5.0 6.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.00465311226798915</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue latitudeBin="-0.6 -0.3" longitudeBin="-0.1 0.1" magnitudeBin="5.0 6.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.009308218812576716</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue latitudeBin="-0.6 -0.3" longitudeBin="0.1 0.3" magnitudeBin="5.0 6.0" epsilonBin="-0.5 0.5">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                        </disaggregationMatrix>
+                        <disaggregationMatrix disaggregationPMFType="LatitudeLongitudeMagnitudeEpsilonTectonicRegionTypePMF">
+                            <disaggregationMatrixValue latitudeBin="-0.6 -0.3" longitudeBin="-0.6 -0.3" magnitudeBin="5.0 6.0" epsilonBin="-0.5 0.5" tectonicRegionTypeBin="Active Shallow Crust">
+                                <PMFValue>0.00004353335</PMFValue>
+                            </disaggregationMatrixValue>
+                            <disaggregationMatrixValue latitudeBin="-0.6 -0.3" longitudeBin="-0.3 -0.1" magnitudeBin="5.0 6.0" epsilonBin="-0.5 0.5" tectonicRegionTypeBin="Stable Shallow Crust">
+                                <PMFValue>0.0</PMFValue>
+                            </disaggregationMatrixValue>
+                        </disaggregationMatrix>
+                    </disaggregationMatrixSet>
+            </disaggregationResultNode>
+    </disaggregationResultField>
+</nrml>
--- /dev/null
+++ b/openquake/nrml/schema/examples/disaggregation_binary.xml
@@ -0,0 +1,21 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<nrml xmlns:gml="http://www.opengis.net/gml"
+      xmlns="http://openquake.org/xmlns/nrml/0.2"
+      gml:id="IDXXX">
+    <disaggregationResultField poE="0.1" IMT="PGA" endBranchLabel="1" gml:id="ID000">
+            <disaggregationResultNode gml:id="ID001">
+                    <site>
+                        <gml:Point gml:id="ID002">
+                                <gml:pos>0.0 0.0</gml:pos>
+                        </gml:Point>
+                    </site>
+                    <disaggregationMatrixSet groundMotionValue="0.25">
+                        <disaggregationMatrixBinaryFile disaggregationPMFType="MagnitudePMF" path="/path"/>
+                        <disaggregationMatrixBinaryFile disaggregationPMFType="MagnitudeDistancePMF" path="/path"/>
+                        <disaggregationMatrixBinaryFile disaggregationPMFType="MagnitudeDistanceEpsilonPMF" path="/path"/>
+                        <disaggregationMatrixBinaryFile disaggregationPMFType="LatitudeLongitudeMagnitudeEpsilonPMF" path="/path"/>
+                        <disaggregationMatrixBinaryFile disaggregationPMFType="LatitudeLongitudeMagnitudeEpsilonTectonicRegionTypePMF" path="/path"/>
+                    </disaggregationMatrixSet>
+            </disaggregationResultNode>
+    </disaggregationResultField>
+</nrml>
--- a/openquake/nrml/schema/examples/logic-tree-gmpe.xml
+++ b/openquake/nrml/schema/examples/logic-tree-gmpe.xml
@@ -3,28 +3,28 @@
       xmlns="http://openquake.org/xmlns/nrml/0.2"
       gml:id="n1">
       
-    <logicTreeSet>
-        <logicTree id="lt1" tectonicRegion="Active Shallow Crust">
-            <logicTreeBranchSet branchingLevel="1" uncertaintyType="gmpeModel">
-                <logicTreeBranch>
+    <logicTree logicTreeID="lt1">
+        <logicTreeBranchingLevel branchingLevelID="bl1">
+            <logicTreeBranchSet uncertaintyType="gmpeModel" applyToTectonicRegionType="Active Shallow Crust" branchSetID="bs1">
+                <logicTreeBranch branchID="b1">
                     <uncertaintyModel>BA_2008_AttenRel</uncertaintyModel>
                     <uncertaintyWeight>0.5</uncertaintyWeight>
                 </logicTreeBranch>
                 
-                <logicTreeBranch>
+                <logicTreeBranch branchID="b2">
                     <uncertaintyModel>CB_2008_AttenRel</uncertaintyModel>
                     <uncertaintyWeight>0.5</uncertaintyWeight>
                 </logicTreeBranch>
             </logicTreeBranchSet>
-        </logicTree>
+        </logicTreeBranchingLevel>
         
-        <logicTree id="lt2" tectonicRegion="Subduction Interface">
-            <logicTreeBranchSet branchingLevel="1" uncertaintyType="gmpeModel">
-                <logicTreeBranch>
+        <logicTreeBranchingLevel branchingLevelID="bl2">
+            <logicTreeBranchSet uncertaintyType="gmpeModel" applyToTectonicRegionType="Subduction Interface" branchSetID="bs2">
+                <logicTreeBranch branchID="b3">
                     <uncertaintyModel>McVerryetal_2000_AttenRel</uncertaintyModel>
                     <uncertaintyWeight>1.0</uncertaintyWeight>
                 </logicTreeBranch>
             </logicTreeBranchSet>
-        </logicTree>
-    </logicTreeSet>
+        </logicTreeBranchingLevel>
+    </logicTree>
 </nrml>
--- a/openquake/nrml/schema/examples/logic-tree-source-model.xml
+++ b/openquake/nrml/schema/examples/logic-tree-source-model.xml
@@ -3,57 +3,59 @@
       xmlns="http://openquake.org/xmlns/nrml/0.2"
       gml:id="n1">
       
-    <logicTreeSet>
-        <config/>
-        <logicTree id="lt1">
-        
-            <logicTreeBranchSet branchingLevel="1" uncertaintyType="sourceModel">
-                <logicTreeBranch>
+    <logicTree logicTreeID="lt1">
+        <logicTreeBranchingLevel branchingLevelID="bl1">
+            <logicTreeBranchSet uncertaintyType="sourceModel" branchSetID="bs1">
+                <logicTreeBranch branchID="b1">
                     <uncertaintyModel>source_model_1.xml</uncertaintyModel>
                     <uncertaintyWeight>0.5</uncertaintyWeight>
                 </logicTreeBranch>
                 
-                <logicTreeBranch>
+                <logicTreeBranch branchID="b2">
                     <uncertaintyModel>source_model_2.xml</uncertaintyModel>
                     <uncertaintyWeight>0.5</uncertaintyWeight>
                 </logicTreeBranch>
             </logicTreeBranchSet>
+        </logicTreeBranchingLevel>
             
-            <logicTreeBranchSet branchingLevel="2" uncertaintyType="maxMagnitudeGutenbergRichterRelative">
-                <logicTreeBranch>
+        <logicTreeBranchingLevel branchingLevelID="bl2">
+            <logicTreeBranchSet uncertaintyType="maxMagGRRelative" branchSetID="bs2">
+                <logicTreeBranch branchID="b3">
                     <uncertaintyModel>0.2</uncertaintyModel>
                     <uncertaintyWeight>0.2</uncertaintyWeight>
                 </logicTreeBranch>
                 
-                <logicTreeBranch>
+                <logicTreeBranch branchID="b4">
                     <uncertaintyModel>0.0</uncertaintyModel>
                     <uncertaintyWeight>0.6</uncertaintyWeight>
                 </logicTreeBranch>
                 
-                <logicTreeBranch>
+                <logicTreeBranch branchID="b5">
                     <uncertaintyModel>-0.2</uncertaintyModel>
                     <uncertaintyWeight>0.2</uncertaintyWeight>
                 </logicTreeBranch>
                 
             </logicTreeBranchSet>
+        </logicTreeBranchingLevel>
             
-            <logicTreeBranchSet branchingLevel="3" uncertaintyType="bValueGutenbergRichterRelative">
-                <logicTreeBranch>
+        <logicTreeBranchingLevel branchingLevelID="bl3">
+            <logicTreeBranchSet uncertaintyType="bGRRelative" branchSetID="bs3">
+                <logicTreeBranch branchID="b6">
                     <uncertaintyModel>0.1</uncertaintyModel>
                     <uncertaintyWeight>0.2</uncertaintyWeight>
                 </logicTreeBranch>
                 
-                <logicTreeBranch>
+                <logicTreeBranch branchID="b7">
                     <uncertaintyModel>0.0</uncertaintyModel>
                     <uncertaintyWeight>0.6</uncertaintyWeight>
                 </logicTreeBranch>
                 
-                <logicTreeBranch>
+                <logicTreeBranch branchID="b8">
                     <uncertaintyModel>-0.1</uncertaintyModel>
                     <uncertaintyWeight>0.2</uncertaintyWeight>
                 </logicTreeBranch>
             </logicTreeBranchSet>
+        </logicTreeBranchingLevel>
             
-        </logicTree>
-    </logicTreeSet>
+    </logicTree>
 </nrml>
--- a/openquake/nrml/schema/gmlsf.xsd
+++ b/openquake/nrml/schema/gmlsf.xsd
@@ -18,7 +18,7 @@
    <!-- ============================================================= -->
    <!-- === includes and imports                                  === -->
    <!-- ============================================================= -->
-   <import namespace="http://www.w3.org/1999/xlink" schemaLocation="http://schemas.opengis.net/xlink/1.0.0/xlinks.xsd"/>
+   <import namespace="http://www.w3.org/1999/xlink" schemaLocation="./xlinks.xsd"/>
    <!-- =========================================================== -->
    <!-- === Subset of geometryAggregates.xsd for this profile ===== -->
    <!-- =========================================================== -->
--- a/openquake/nrml/schema/gmlsf2.xsd
+++ b/openquake/nrml/schema/gmlsf2.xsd
@@ -16,7 +16,7 @@
    <!-- =========================================================== -->
    <!-- === includes and imports                                === -->
    <!-- =========================================================== -->
-   <import namespace="http://www.w3.org/1999/xlink" schemaLocation="http://schemas.opengis.net/xlink/1.0.0/xlinks.xsd"/>
+   <import namespace="http://www.w3.org/1999/xlink" schemaLocation="./xlinks.xsd"/>
    <!-- =========================================================== -->
    <!-- === Subset of geometryAggregates.xsd for this profile ===== -->
    <!-- =========================================================== -->
--- a/openquake/nrml/schema/nrml.xsd
+++ b/openquake/nrml/schema/nrml.xsd
@@ -6,7 +6,7 @@
            xmlns:gml="http://www.opengis.net/gml"
            targetNamespace="http://openquake.org/xmlns/nrml/0.2"
            elementFormDefault="qualified"
-           xml:lang="en"> 
+           xml:lang="en">
 
     <xs:import namespace="http://www.opengis.net/gmlsf" schemaLocation="./gmlsfLevels.xsd"/>
     <xs:import namespace="http://www.opengis.net/gml" schemaLocation="./gmlsf.xsd"/>
@@ -32,11 +32,12 @@
                     <xs:choice minOccurs="0" maxOccurs="1">
                         <xs:element ref="hazardResult"/>
                         <xs:element ref="sourceModel"/>
-                        <xs:element ref="logicTreeSet"/>
                         <xs:element ref="rupture"/>
                         <xs:element ref="riskResult"/>
                         <xs:element ref="exposurePortfolio"/>
                         <xs:element ref="vulnerabilityModel"/>
+                        <xs:element ref="logicTree"/>
+                        <xs:element ref="disaggregationResultField"/>
                     </xs:choice>
                 </xs:sequence>
             </xs:extension>
--- a/openquake/nrml/schema/nrml_hazard.xsd
+++ b/openquake/nrml/schema/nrml_hazard.xsd
@@ -10,11 +10,11 @@
     <xs:import namespace="http://www.opengis.net/gml" schemaLocation="./gmlsf.xsd"/>
 	<xs:include schemaLocation="nrml_common.xsd"/>
 	<xs:include schemaLocation="nrml_seismic.xsd"/>
-	
+
 	<!-- ============================================================= -->
-	
+
 	<xs:complexType name="HazardProcessing">
-	
+
         <!-- NOTE: renamed timeSpanDuration (OpenSHA name) to investigationTimeSpan.
              This parameter should be given in the unit years, since the base
              SI unit (seconds) would yield values that are not instructive.
@@ -25,9 +25,9 @@
         <xs:attribute name="saPeriod" type="NonNegativeDoubleType"/>
         <xs:attribute name="saDamping" type="NonNegativeDoubleType"/>
     </xs:complexType>
-    
+
     <!-- ============================================================= -->
-    
+
 	<!-- TODO: add useful enum items (T&O group) -->
 	<xs:simpleType name="Vs30Method">
         <xs:annotation>
@@ -38,7 +38,7 @@
             <xs:enumeration value="fixed value"/>
         </xs:restriction>
     </xs:simpleType>
-    
+
     <xs:simpleType name="GroundMotionComponent">
         <xs:restriction base="xs:string">
             <xs:enumeration value="average"/>
@@ -48,17 +48,17 @@
             <xs:enumeration value="vertical"/>
         </xs:restriction>
     </xs:simpleType>
-    
+
     <xs:simpleType name="TruncationType">
         <xs:restriction base="xs:string">
             <xs:enumeration value="none"/>
-            
+
             <!-- NOTE: removed the whitespace in enum values -->
             <xs:enumeration value="one_sided"/>
             <xs:enumeration value="two_sided"/>
         </xs:restriction>
     </xs:simpleType>
-    
+
     <xs:simpleType name="StdDevType">
         <xs:restriction base="xs:string">
             <xs:enumeration value="none"/>
@@ -67,7 +67,7 @@
             <xs:enumeration value="intra"/>
         </xs:restriction>
     </xs:simpleType>
-    
+
 	<xs:complexType name="GMPEParametersType">
         <xs:annotation>
             <xs:documentation>Describe the IMR (GMPE) related information</xs:documentation>
@@ -78,7 +78,7 @@
 
         <xs:attribute name="period" type="NonNegativeDoubleType"/>
         <xs:attribute name="damping" type="NonNegativeDoubleType"/>
-        
+
         <xs:attribute name="truncationType" type="TruncationType"/>
         <xs:attribute name="truncationLevel" type="NonNegativeDoubleType"/>
         <xs:attribute name="stdDevType" type="StdDevType"/>
@@ -88,7 +88,7 @@
 	<!-- GML substitution groups -->
 
     <!-- ground motion field (GMF) -->
-    
+
     <xs:element name="groundMotionFieldSet" type="GroundMotionFieldSet" substitutionGroup="gml:_Feature"/>
     <xs:complexType name="GroundMotionFieldSet">
         <xs:annotation>
@@ -114,8 +114,8 @@
                 <xs:sequence>
                     <xs:element ref="GMFNode" minOccurs="1" maxOccurs="unbounded"/>
                 </xs:sequence>
-                
-                <!-- NOTE: the optional attribute ruptureReference refers to the 
+
+                <!-- NOTE: the optional attribute ruptureReference refers to the
                      gml:id of one of the ruptures -->
                 <xs:attribute name="ruptureReference" type="xs:IDREF"/>
             </xs:extension>
@@ -132,9 +132,9 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <!-- hazardCurve -->
-    
+
     <xs:element name="hazardCurveField" type="HazardCurveField" substitutionGroup="gml:_Feature"/>
     <xs:complexType name="HazardCurveField">
         <xs:complexContent>
@@ -148,7 +148,7 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="HCNode" type="HCNodeType" substitutionGroup="fieldNode"/>
     <xs:complexType name="HCNodeType">
         <xs:complexContent>
@@ -167,9 +167,9 @@
         </xs:sequence>
         <xs:attribute name="investigationTimeSpan" type="NonNegativeDoubleType"/>
     </xs:complexType>
-    
+
     <!-- hazardMap -->
-    
+
     <xs:element name="hazardMap" type="HazardMap" substitutionGroup="gml:_Feature"/>
     <xs:complexType name="HazardMap">
         <xs:complexContent>
@@ -184,7 +184,7 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="HMNode" type="HMNodeType" substitutionGroup="fieldNode"/>
     <xs:complexType name="HMNodeType">
         <xs:complexContent>
@@ -205,7 +205,7 @@
             </xs:restriction>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="HMSite" type="HMSiteType" substitutionGroup="site"/>
     <xs:complexType name="HMSiteType">
         <xs:complexContent>
@@ -217,9 +217,90 @@
         </xs:complexContent>
     </xs:complexType>
 
+    <!-- Disaggregation -->
+
+    <xs:element name="disaggregationResultField" type="DisaggregationResultFieldType" substitutionGroup="gml:_Feature"/>
+    <xs:complexType name="DisaggregationResultFieldType">
+        <xs:complexContent>
+            <xs:extension base="gml:AbstractFeatureType">
+                <xs:sequence>
+                    <xs:element ref="disaggregationResultNode" minOccurs="1" maxOccurs="unbounded"/>
+                </xs:sequence>
+                <xs:attribute name="poE" type="NormalizedDoubleType" use="required"/>
+                <xs:attribute name="IMT" type="IMTType" use="required"/>
+                <xs:attribute name="endBranchLabel" type="xs:string"/>
+                <xs:attributeGroup ref="QuantileGroup"/>
+            </xs:extension>
+        </xs:complexContent>
+    </xs:complexType>
+
+    <xs:element name="disaggregationResultNode" type="DisaggregationResultNodeType" substitutionGroup="fieldNode"/>
+    <xs:complexType name="DisaggregationResultNodeType">
+        <xs:complexContent>
+            <xs:extension base="FieldNode">
+                <xs:sequence>
+                    <xs:element name="disaggregationMatrixSet" type="DisaggregationMatrixSetType"/>
+                </xs:sequence>
+            </xs:extension>
+        </xs:complexContent>
+    </xs:complexType>
+
+    <xs:complexType name="DisaggregationMatrixSetType">
+        <xs:choice>
+            <xs:sequence>
+                <xs:element name="disaggregationMatrixBinaryFile" type="DisaggregationMatrixBinaryFileType" maxOccurs="unbounded"/>
+            </xs:sequence>
+            <xs:sequence>
+                <xs:element name="disaggregationMatrix" type="DisaggregationMatrixType" maxOccurs="unbounded"/>
+            </xs:sequence>
+        </xs:choice>
+        <xs:attribute name="groundMotionValue" type="NonNegativeDoubleType" use="required"/>
+    </xs:complexType>
+
+    <xs:complexType name="DisaggregationMatrixBinaryFileType">
+        <xs:attribute name="path" type="xs:string" use="required"/>
+        <xs:attribute name="disaggregationPMFType" type="DisaggregationPMFType" use="required"/>
+    </xs:complexType>
+
+    <xs:complexType name="DisaggregationMatrixType">
+        <xs:sequence>
+            <xs:element name="disaggregationMatrixValue" type="DisaggregationMatrixValue" maxOccurs="unbounded"/>
+        </xs:sequence>
+        <xs:attribute name="disaggregationPMFType" type="DisaggregationPMFType" use="required"/>
+    </xs:complexType>
+
+    <xs:simpleType name="DisaggregationPMFType">
+        <xs:restriction base="xs:string">
+            <xs:enumeration value="MagnitudePMF"/>
+            <xs:enumeration value="DistancePMF"/>
+            <xs:enumeration value="TectonicRegionTypePMF"/>
+            <xs:enumeration value="MagnitudeTectonicRegionTypePMF"/>
+            <xs:enumeration value="MagnitudeDistancePMF"/>
+            <xs:enumeration value="MagnitudeDistanceEpsilonPMF"/>
+            <xs:enumeration value="LatitudeLongitudePMF"/>
+            <xs:enumeration value="LatitudeLongitudeMagnitudePMF"/>
+            <xs:enumeration value="LatitudeLongitudeEpsilonPMF"/>
+            <xs:enumeration value="LatitudeLongitudeMagnitudeEpsilonPMF"/>
+            <xs:enumeration value="LatitudeLongitudeTectonicRegionTypePMF"/>
+            <xs:enumeration value="LatitudeLongitudeMagnitudeEpsilonTectonicRegionTypePMF"/> <!-- In db schema as 'fulldisaggmatrix'-->
+        </xs:restriction>
+    </xs:simpleType>
+
+    <xs:complexType name="DisaggregationMatrixValue">
+        <xs:sequence>
+            <xs:element name="PMFValue" type="NormalizedDoubleType"/>
+        </xs:sequence>
+        <xs:attribute name="latitudeBin" type="gml:doubleList"></xs:attribute>
+        <xs:attribute name="longitudeBin" type="gml:doubleList"></xs:attribute>
+        <xs:attribute name="magnitudeBin" type="gml:doubleList"></xs:attribute>
+        <xs:attribute name="distanceBin" type="gml:doubleList"></xs:attribute>
+        <xs:attribute name="epsilonBin" type="gml:doubleList"></xs:attribute>
+        <xs:attribute name="tectonicRegionTypeBin" type="TectonicRegion"></xs:attribute>
+    </xs:complexType>
+
     <!-- ============================================================= -->
     <!-- child elements of nrml -->
-    
+
     <xs:element name="hazardResult" type="HazardResult" substitutionGroup="gml:_Feature"/>
     <xs:complexType name="HazardResult">
         <xs:complexContent>
@@ -232,10 +313,11 @@
                         </xs:sequence>
                         <xs:element ref="groundMotionFieldSet"/>
                         <xs:element ref="hazardMap"/>
+                        <xs:element ref="disaggregationResultField"></xs:element>
                     </xs:choice>
                 </xs:sequence>
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
 </xs:schema>
--- a/openquake/nrml/schema/nrml_risk.xsd
+++ b/openquake/nrml/schema/nrml_risk.xsd
@@ -37,7 +37,7 @@
         </xs:restriction>
     </xs:simpleType>
     
-    <xs:simpleType name="LossMapPoE">
+    <xs:simpleType name="PoE">
         <xs:restriction base="xs:double">
             <xs:minInclusive value="0"/>
             <xs:maxInclusive value="1"/>
@@ -131,25 +131,12 @@
                 <xs:sequence>
                     <xs:element ref="LMNode" minOccurs="1" maxOccurs="unbounded"/>
                 </xs:sequence>
-                <xs:attribute name="endBranchLabel" type="xs:string"/>
-                <xs:attribute name="lossCategory" type="LossCategory"/>
-                <xs:attribute name="unit" type="AssetValueUnit"/>
-            </xs:extension>
-        </xs:complexContent>
-    </xs:complexType>
-
-    <xs:element name="lossMapProbabilistic" type="LossMapProbabilistic" substitutionGroup="gml:_Feature"/>
-    <xs:complexType name="LossMapProbabilistic">
-        <xs:complexContent>
-            <xs:extension base="gml:AbstractFeatureType">
-                <xs:sequence>
-                    <xs:element ref="LMNode" minOccurs="1" maxOccurs="unbounded"/>
-                </xs:sequence>
+                <xs:attribute name="calculator" type="xs:string"/>
                 <xs:attribute name="endBranchLabel" type="xs:string"/>
                 <xs:attribute name="lossCategory" type="LossCategory"/>
                 <xs:attribute name="unit" type="AssetValueUnit"/>
                 <xs:attribute name="timeSpan" type="xs:double"/>
-                <xs:attribute name="poE" type="LossMapPoE"/>
+                <xs:attribute name="poE" type="PoE"/>
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
@@ -167,8 +154,11 @@
 
     <xs:complexType name="LMLossType">
         <xs:sequence>
-            <xs:element name="mean" type="NonNegativeDoubleType"/>
-            <xs:element name="stdDev" type="NonNegativeDoubleType"/>
+            <xs:choice minOccurs="1" maxOccurs="2">
+                <xs:element name="mean" type="NonNegativeDoubleType"/>
+                <xs:element name="stdDev" type="NonNegativeDoubleType"/>
+                <xs:element name="value" type="NonNegativeDoubleType"/>
+            </xs:choice>
         </xs:sequence>
         <xs:attribute name="assetRef" type="xs:ID" use="required"/>
     </xs:complexType>
--- a/openquake/nrml/schema/nrml_seismic.xsd
+++ b/openquake/nrml/schema/nrml_seismic.xsd
@@ -42,7 +42,7 @@
 
     <xs:simpleType name="TectonicRegion">
         <xs:restriction base="xs:string">
-            
+
             <xs:enumeration value="Active Shallow Crust"/>
             <xs:enumeration value="Stable Shallow Crust"/>
             <xs:enumeration value="Subduction Interface"/>
@@ -54,9 +54,9 @@
 
     <!-- ============================================================= -->
     <!-- seismic source geometry -->
-    
+
     <!-- complex fault -->
-    
+
     <xs:complexType name="ComplexFaultGeometry">
         <xs:complexContent>
             <xs:restriction base="gml:MultiGeometryPropertyType">
@@ -66,7 +66,7 @@
             </xs:restriction>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="faultEdges" type="FaultEdges" substitutionGroup="gml:MultiCurve"/>
     <xs:complexType name="FaultEdges">
         <xs:complexContent>
@@ -78,7 +78,7 @@
             </xs:restriction>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="faultTopEdge" type="FaultEdge" substitutionGroup="gml:curveMember"/>
     <xs:element name="faultBottomEdge" type="FaultEdge" substitutionGroup="gml:curveMember"/>
     <xs:complexType name="FaultEdge">
@@ -92,7 +92,7 @@
     </xs:complexType>
 
     <!-- simple fault -->
-    
+
     <xs:element name="simpleFaultGeometry" type="SimpleFaultGeometry" substitutionGroup="gml:_Feature"/>
     <xs:complexType name="SimpleFaultGeometry">
         <xs:complexContent>
@@ -106,10 +106,10 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <!-- ============================================================= -->
     <!-- seismic source -->
-    
+
     <xs:element name="_seismicSource" type="AbstractSeismicSource" substitutionGroup="gml:_Feature" abstract="true"/>
     <xs:complexType name="AbstractSeismicSource" abstract="true">
         <xs:complexContent>
@@ -126,23 +126,23 @@
             <xs:sequence minOccurs="1" maxOccurs="unbounded">
                 <xs:element name="ruptureRateModel" type="RuptureRateModel"/>
             </xs:sequence>
-            
+
             <xs:element name="ruptureDepthDistribution" type="RuptureDepthDistribution"/>
-            
+
             <!-- NOTE: we could use meters here, as in QuakeML (basic SI unit) -->
             <xs:element name="hypocentralDepth" type="NonNegativeDoubleType"/>
         </xs:sequence>
     </xs:group>
-    
+
     <xs:complexType name="RuptureDepthDistribution">
         <xs:sequence>
             <xs:element name="magnitude" type="MagnitudeList"/>
-            
+
             <!-- NOTE: we could use meters here, as in QuakeML (basic SI unit) -->
             <xs:element name="depth" type="NonNegativeDoubleList"/>
         </xs:sequence>
     </xs:complexType>
-    
+
     <xs:element name="pointSource" type="PointSource" substitutionGroup="_seismicSource"/>
     <xs:complexType name="PointSource">
         <xs:complexContent>
@@ -154,7 +154,7 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="areaSource" type="AreaSource" substitutionGroup="_seismicSource"/>
     <xs:complexType name="AreaSource">
         <xs:complexContent>
@@ -166,7 +166,7 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:complexType name="AreaBoundary">
         <xs:complexContent>
             <xs:restriction base="gml:SurfacePropertyType">
@@ -176,7 +176,7 @@
             </xs:restriction>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="simpleFaultSource" type="SimpleFaultSource" substitutionGroup="_seismicSource"/>
     <xs:complexType name="SimpleFaultSource">
         <xs:complexContent>
@@ -189,7 +189,7 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="complexFaultSource" type="ComplexFaultSource" substitutionGroup="_seismicSource"/>
     <xs:complexType name="ComplexFaultSource">
         <xs:complexContent>
@@ -204,16 +204,16 @@
     </xs:complexType>
 
     <!-- ============================================================= -->
-    
+
     <xs:complexType name="RuptureRateModel">
         <xs:sequence>
             <xs:element ref="magnitudeFrequencyDistribution"/>
             <xs:element name="focalMechanism" type="qml:FocalMechanism"/>
         </xs:sequence>
     </xs:complexType>
-        
+
     <xs:element name="magnitudeFrequencyDistribution" abstract="true"/>
-    
+
     <xs:element name="truncatedGutenbergRichter" type="TruncatedGutenbergRichter"
         substitutionGroup="magnitudeFrequencyDistribution"/>
     <xs:complexType name="TruncatedGutenbergRichter">
@@ -235,7 +235,7 @@
             </xs:extension>
         </xs:simpleContent>
     </xs:complexType>
-    
+
     <!-- ============================================================= -->
     <!-- rupture -->
 
@@ -250,7 +250,7 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="pointRupture" type="PointRupture" substitutionGroup="rupture"/>
     <xs:complexType name="PointRupture">
         <xs:complexContent>
@@ -262,7 +262,7 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="simpleFaultRupture" type="SimpleFaultRupture" substitutionGroup="rupture"/>
     <xs:complexType name="SimpleFaultRupture">
         <xs:complexContent>
@@ -274,7 +274,7 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="complexFaultRupture" type="ComplexFaultRupture" substitutionGroup="rupture"/>
     <xs:complexType name="ComplexFaultRupture">
         <xs:complexContent>
@@ -286,7 +286,7 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
+
     <xs:element name="arbitrarilyComplexRupture" type="ArbitrarilyComplexRupture" substitutionGroup="rupture"/>
     <xs:complexType name="ArbitrarilyComplexRupture">
         <xs:complexContent>
@@ -301,42 +301,93 @@
 
     <!-- ============================================================= -->
     <!-- logic tree -->
-    
+
     <xs:simpleType name="LogicTreeBranchUncertaintyType">
         <xs:restriction base="xs:string">
             <xs:enumeration value="gmpeModel"/>
             <xs:enumeration value="sourceModel"/>
-            <xs:enumeration value="maxMagnitudeGutenbergRichterRelative"/>
-            <xs:enumeration value="bValueGutenbergRichterRelative"/>
+            <xs:enumeration value="maxMagGRRelative"/>
+            <xs:enumeration value="bGRRelative"/>
+            <xs:enumeration value="abGRAbsolute"/>
+            <xs:enumeration value="maxMagGRAbsolute"/>
         </xs:restriction>
     </xs:simpleType>
-    
+
+    <xs:simpleType name="SourceType">
+        <xs:restriction base="xs:string">
+            <xs:enumeration value="area"/>
+            <xs:enumeration value="point"/>
+            <xs:enumeration value="simpleFault"/>
+            <xs:enumeration value="complexFault"/>
+        </xs:restriction>
+    </xs:simpleType>
+
+    <xs:simpleType name="CorrelationType">
+        <xs:restriction base="xs:string">
+            <xs:enumeration value="none"/>
+            <xs:enumeration value="full"/>
+        </xs:restriction>
+    </xs:simpleType>
+
     <xs:complexType name="LogicTreeBranch">
         <xs:sequence>
             <xs:element name="uncertaintyModel" type="xs:string"/>
             <xs:element name="uncertaintyWeight" type="NonNegativeDoubleType"/>
         </xs:sequence>
+        <xs:attribute name="branchID" type="xs:ID" use="required">
+        </xs:attribute>
     </xs:complexType>
+    <!-- a LogicTreeBranch is defined by an uncertainityModel (a string specifying a specific realization of
+        the epistemic uncertainty of type uncertaintyType; e.g. it can be the file path of a source model file,
+        or it can be a numeric value specifying a particular parameter value, etc.. )-->
 
     <xs:complexType name="LogicTreeBranchSet">
         <xs:sequence minOccurs="1" maxOccurs="unbounded">
-            <xs:element name="logicTreeBranch" type="LogicTreeBranch"/>
+            <xs:element name="logicTreeBranch" type="LogicTreeBranch" />
         </xs:sequence>
-        <xs:attribute name="branchingLevel" type="xs:positiveInteger" use="required"/>
+        <xs:attribute name="branchSetID" type="xs:ID" use="required"></xs:attribute>
         <xs:attribute name="uncertaintyType" type="LogicTreeBranchUncertaintyType" use="required"/>
+        <xs:attribute name="applyToBranches" type="gml:NCNameList" use="optional" default="ALL"></xs:attribute>
+        <xs:attribute name="applyToSources" type="gml:NCNameList" use="optional"></xs:attribute>
+        <xs:attribute name="applyToSourceType" type="SourceType" use="optional"></xs:attribute>
+        <xs:attribute name="applyToTectonicRegionType" type="TectonicRegion" use="optional"></xs:attribute>
+    </xs:complexType>
+    <!-- a LogicTreeBranchSet is defined as a sequence of LogicTreeBranch elements. A branch set has two required
+    attributes (ID and uncertaintyType (defining the type of epistemic uncertainty the branch set is defining)).
+    Optional attributes are:
+    - applyToBranches: to be used to specify to which LogicTreeBranch elements (one or more),
+    in the previous branching level, the branch set is linked to. The default is the keyword ALL, which means
+    that a branch set is by default linked to all branches in the previous branching level.
+    - applyToSources: it can be used in the Source Model Logic Tree definition, it allows to specify to which source in a source model the
+    uncertainty applies to.
+    - applyToSourceType: it can be used in the Source Model Logic Tree definition, it allows to specify to which source type
+    (area, point, simple fault, complex fault) the uncertainty applies to.
+    - applyToTectonicRegionType: it can be used in both the Source Model and GMPE Logic Tree definition, it allows to specify to which tectonic
+    region type (Active Shallow Crust, Stable Shallow Crust, etc.) the uncertainty applies to.-->
+
+    <xs:complexType name="LogicTreeBranchingLevel">
+        <xs:sequence minOccurs="1" maxOccurs="unbounded">
+            <xs:element name="logicTreeBranchSet" type="LogicTreeBranchSet"></xs:element>
+        </xs:sequence>
+        <xs:attribute name="branchingLevelID" type="xs:ID" use="required"></xs:attribute>
     </xs:complexType>
+    <!-- a LogicTreeBranchingLevel is defined as a sequence of LogicTreeBranchSet elements. Each LogicTreeBranchSet
+    defines a particular epistemic uncertainty inside a branching level.-->
 
     <xs:complexType name="LogicTree">
         <xs:sequence minOccurs="1" maxOccurs="unbounded">
-            <xs:element name="logicTreeBranchSet" type="LogicTreeBranchSet"/>
+            <xs:element name="logicTreeBranchingLevel" type="LogicTreeBranchingLevel"/>
         </xs:sequence>
-        <xs:attribute name="id" type="xs:string" use="required"/>
-        <xs:attribute name="tectonicRegion" type="TectonicRegion"/>
+        <xs:attribute name="logicTreeID" type="xs:ID" use="required"/>
     </xs:complexType>
+    <!-- a LogicTree is defined as a sequence of LogicTreeBranchingLevel elements. The position in the sequence
+    specifies in which level of the tree the branching level is located. That is,
+    the first LogicTreeBranchingLevel element in the sequence represents the first branching level in the tree,
+    the second element the second branching level in the tree, and so on.-->
 
     <!-- ============================================================= -->
     <!-- child elements of nrml -->
-    
+
     <xs:element name="sourceModel" type="SourceModel" substitutionGroup="gml:_Feature"/>
     <xs:complexType name="SourceModel">
         <xs:complexContent>
@@ -348,13 +399,6 @@
             </xs:extension>
         </xs:complexContent>
     </xs:complexType>
-    
-    <xs:element name="logicTreeSet" type="LogicTreeSet"/>
-    <xs:complexType name="LogicTreeSet">
-        <xs:sequence>
-            <xs:element name="config" type="Config" minOccurs="0" maxOccurs="1"/>
-            <xs:element name="logicTree" type="LogicTree" minOccurs="1" maxOccurs="unbounded"/>
-        </xs:sequence>
-    </xs:complexType>
 
+    <xs:element name="logicTree" type="LogicTree"/>
 </xs:schema>
--- /dev/null
+++ b/openquake/nrml/schema/xlinks.xsd
@@ -0,0 +1,122 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!-- File: xlinks.xsd  -->
+<schema targetNamespace="http://www.w3.org/1999/xlink" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2001/XMLSchema" xmlns:xsd="http://www.w3.org/2001/XMLSchema" version="2.0">
+	<annotation>
+		<appinfo source="urn:opengis:specification:gml:schema-xlinks:v3.0c2">xlinks.xsd v3.0b2 2001-07</appinfo>
+		<documentation>
+			GML 3.0 candidate xlinks schema. Copyright (c) 2001 OGC, All Rights Reserved.
+		</documentation>
+	</annotation>
+	<!-- ==============================================================
+       global declarations
+  	=============================================================== -->
+	<!-- locator attribute -->
+	<attribute name="href" type="anyURI"/>
+	<!-- semantic attributes -->
+	<attribute name="role" type="anyURI"/>
+	<attribute name="arcrole" type="anyURI"/>
+	<attribute name="title" type="string"/>
+	<!-- behavior attributes -->
+	<attribute name="show">
+		<annotation>
+			<documentation>
+        The 'show' attribute is used to communicate the desired presentation
+        of the ending resource on traversal from the starting resource; it's
+        value should be treated as follows:
+        new - load ending resource in a new window, frame, pane, or other
+              presentation context
+        replace - load the resource in the same window, frame, pane, or
+                  other presentation context
+        embed - load ending resource in place of the presentation of the
+                starting resource
+        other - behavior is unconstrained; examine other markup in the
+                link for hints
+        none - behavior is unconstrained
+      </documentation>
+		</annotation>
+		<simpleType>
+			<restriction base="string">
+				<enumeration value="new"/>
+				<enumeration value="replace"/>
+				<enumeration value="embed"/>
+				<enumeration value="other"/>
+				<enumeration value="none"/>
+			</restriction>
+		</simpleType>
+	</attribute>
+	<attribute name="actuate">
+		<annotation>
+			<documentation>
+        The 'actuate' attribute is used to communicate the desired timing
+        of traversal from the starting resource to the ending resource;
+        it's value should be treated as follows:
+        onLoad - traverse to the ending resource immediately on loading
+                 the starting resource
+        onRequest - traverse from the starting resource to the ending
+                    resource only on a post-loading event triggered for
+                    this purpose
+        other - behavior is unconstrained; examine other markup in link
+                for hints
+        none - behavior is unconstrained
+      </documentation>
+		</annotation>
+		<simpleType>
+			<restriction base="string">
+				<enumeration value="onLoad"/>
+				<enumeration value="onRequest"/>
+				<enumeration value="other"/>
+				<enumeration value="none"/>
+			</restriction>
+		</simpleType>
+	</attribute>
+	<!-- traversal attributes -->
+	<attribute name="label" type="string"/>
+	<attribute name="from" type="string"/>
+	<attribute name="to" type="string"/>
+	<!-- ==============================================================
+       Attributes grouped by XLink type, as specified in the W3C
+       Proposed Recommendation (dated 2000-12-20)
+	============================================================== -->
+	<attributeGroup name="simpleLink">
+		<attribute name="type" type="string" fixed="simple" form="qualified"/>
+		<attribute ref="xlink:href" use="optional"/>
+		<attribute ref="xlink:role" use="optional"/>
+		<attribute ref="xlink:arcrole" use="optional"/>
+		<attribute ref="xlink:title" use="optional"/>
+		<attribute ref="xlink:show" use="optional"/>
+		<attribute ref="xlink:actuate" use="optional"/>
+	</attributeGroup>
+	<attributeGroup name="extendedLink">
+		<attribute name="type" type="string" fixed="extended" form="qualified"/>
+		<attribute ref="xlink:role" use="optional"/>
+		<attribute ref="xlink:title" use="optional"/>
+	</attributeGroup>
+	<attributeGroup name="locatorLink">
+		<attribute name="type" type="string" fixed="locator" form="qualified"/>
+		<attribute ref="xlink:href" use="required"/>
+		<attribute ref="xlink:role" use="optional"/>
+		<attribute ref="xlink:title" use="optional"/>
+		<attribute ref="xlink:label" use="optional"/>
+	</attributeGroup>
+	<attributeGroup name="arcLink">
+		<attribute name="type" type="string" fixed="arc" form="qualified"/>
+		<attribute ref="xlink:arcrole" use="optional"/>
+		<attribute ref="xlink:title" use="optional"/>
+		<attribute ref="xlink:show" use="optional"/>
+		<attribute ref="xlink:actuate" use="optional"/>
+		<attribute ref="xlink:from" use="optional"/>
+		<attribute ref="xlink:to" use="optional"/>
+	</attributeGroup>
+	<attributeGroup name="resourceLink">
+		<attribute name="type" type="string" fixed="resource" form="qualified"/>
+		<attribute ref="xlink:role" use="optional"/>
+		<attribute ref="xlink:title" use="optional"/>
+		<attribute ref="xlink:label" use="optional"/>
+	</attributeGroup>
+	<attributeGroup name="titleLink">
+		<attribute name="type" type="string" fixed="title" form="qualified"/>
+	</attributeGroup>
+	<attributeGroup name="emptyLink">
+		<attribute name="type" type="string" fixed="none" form="qualified"/>
+	</attributeGroup>
+</schema>
--- a/openquake/output/risk.py
+++ b/openquake/output/risk.py
@@ -21,7 +21,7 @@
 NRML serialization of risk-related data sets.
 - loss ratio curves
 - loss curves
-- loss map
+- loss maps for Deterministic, Probabilistic and Classical
 """
 
 from collections import defaultdict
@@ -40,6 +40,37 @@
 NAMESPACES = {'gml': GML_NS, 'nrml': NRML_NS}
 
 
+def new_loss_deterministic_node(lmnode_el, loss_dict, asset_dict):
+    """
+    Create a new asset loss node under a pre-existing parent LMNode.
+    """
+    loss_el = etree.SubElement(lmnode_el,
+                            xml.RISK_LOSS_MAP_LOSS_CONTAINER_TAG)
+
+    loss_el.set(xml.RISK_LOSS_MAP_ASSET_REF_ATTR,
+                str(asset_dict['assetID']))
+    mean_loss = etree.SubElement(
+        loss_el, xml.RISK_LOSS_MAP_MEAN_LOSS_TAG)
+    mean_loss.text = "%s" % loss_dict['mean_loss']
+    stddev = etree.SubElement(loss_el,
+                    xml.RISK_LOSS_MAP_STANDARD_DEVIATION_TAG)
+    stddev.text = "%s" % loss_dict['stddev_loss']
+
+
+def new_loss_nondeterministic_node(lmnode_el, loss_dict, asset_dict):
+    """
+    Create a new asset loss node under a pre-existing parent LMNode.
+    """
+    loss_el = etree.SubElement(lmnode_el,
+                            xml.RISK_LOSS_MAP_LOSS_CONTAINER_TAG)
+
+    loss_el.set(xml.RISK_LOSS_MAP_ASSET_REF_ATTR,
+                str(asset_dict['assetID']))
+    value = etree.SubElement(
+        loss_el, xml.RISK_LOSS_MAP_VALUE)
+    value.text = "%s" % loss_dict['value']
+
+
 class BaseXMLWriter(nrml.TreeNRMLWriter):
     """
     This is the base class which prepares the XML document (for risk) to be
@@ -166,42 +197,8 @@
             self.loss_map_node.set(
                 key, metadata.get(key, self.DEFAULT_METADATA[key]))
 
-    def write(self, site, values):
-        """Writes an asset element with loss map ratio information.
-        This method assumes that `riskResult` and `lossMap` element
-        data has already been written.
-
-        :param site: the region location of the data being written
-        :type site: :py:class:`openquake.shapes.Site`
-
-        :param values: contains a list of pairs in the form
-            (loss dict, asset dict) with all the data
-            to be written related to the given site
-        :type values: tuple with the following members
-            :py:class:`dict` (loss dict) with the following keys:
-                ***mean_loss*** - the Mean Loss for a certain Node/Site
-                ***stddev_loss*** - the Standard Deviation for a certain
-                    Node/Site
-
-            :py:class:`dict` (asset dict)
-                ***assetID*** - the assetID
-        """
-        def new_loss_node(lmnode_el, loss_dict, asset_dict):
-            """
-            Create a new asset loss node under a pre-existing parent LMNode.
-            """
-            loss_el = etree.SubElement(lmnode_el,
-                                    xml.RISK_LOSS_MAP_LOSS_CONTAINER_TAG)
-
-            loss_el.set(xml.RISK_LOSS_MAP_ASSET_REF_ATTR,
-                        str(asset_dict['assetID']))
-            mean_loss = etree.SubElement(
-                loss_el, xml.RISK_LOSS_MAP_MEAN_LOSS_TAG)
-            mean_loss.text = "%s" % loss_dict['mean_loss']
-            stddev = etree.SubElement(loss_el,
-                            xml.RISK_LOSS_MAP_STANDARD_DEVIATION_TAG)
-            stddev.text = "%s" % loss_dict['stddev_loss']
-
+    def _generate_lmnode(self, site):
+        """ convenience method to generate a new lmnode """
         # Generate an id for the new LMNode
         # Note: ids are created start at '1'
         self.lmnode_counter += 1
@@ -224,11 +221,36 @@
         pos_el = etree.SubElement(point_el, xml.GML_POS_TAG)
         pos_el.text = "%s %s" % (site.longitude, site.latitude)
 
+        return lmnode_el
+
+    def write(self, site, values):
+        """Writes an asset element with loss map ratio information.
+        This method assumes that `riskResult` and `lossMap` element
+        data has already been written.
+
+        :param site: the region location of the data being written
+        :type site: :py:class:`openquake.shapes.Site`
+
+        :param values: contains a list of pairs in the form
+            (loss dict, asset dict) with all the data
+            to be written related to the given site
+        :type values: tuple with the following members
+            :py:class:`dict` (loss dict) with the following keys:
+                ***mean_loss*** - the Mean Loss for a certain Node/Site
+                ***stddev_loss*** - the Standard Deviation for a certain
+                    Node/Site
+
+            :py:class:`dict` (asset dict)
+                ***assetID*** - the assetID
+        """
+
+        lmnode_el = self._generate_lmnode(site)
+
         # now add the loss nodes as a child of the LMNode
         # we have loss data in first position, asset data in second position
         # ({'stddev_loss': 100, 'mean_loss': 0}, {'assetID': 'a1711'})
         for value in values:
-            new_loss_node(lmnode_el, value[0], value[1])
+            new_loss_deterministic_node(lmnode_el, value[0], value[1])
 
     def _get_site_elem_for_site(self, site):
         """
@@ -249,15 +271,47 @@
         return None
 
 
+class LossMapNonDeterministicXMLWriter(LossMapXMLWriter):
+    """
+    This class serializes loss maps to NRML for Non Deterministic calculators
+
+    Additionally in this loss map we have a timespan and a poe
+
+    timeSpan is an integer representing time in years
+    poE is a float between 0 and 1 (extremes included)
+
+    """
+    DEFAULT_METADATA = {
+        'nrmlID': 'undefined', 'riskResultID': 'undefined',
+        'lossMapID': 'undefined', 'endBranchLabel': 'undefined',
+        'lossCategory': 'undefined', 'unit': 'undefined',
+        'timeSpan': 'undefined', 'poE': 'undefined'}
+
+    def write_metadata(self, metadata):
+        super(LossMapNonDeterministicXMLWriter, self).write_metadata(metadata)
+
+        # set the rest of the <lossMap> attributes for non deterministic
+        for key in ('timeSpan', 'poE'):
+            self.loss_map_node.set(
+                key, str(metadata.get(key, self.DEFAULT_METADATA[key])))
+
+    def write(self, site, values):
+        lmnode_el = self._generate_lmnode(site)
+
+        for value in values:
+            new_loss_nondeterministic_node(lmnode_el, value[0], value[1])
+
 LOSS_MAP_METADATA_KEYS = [
     ('loss_map_ref', 'lossMapID'),
     ('end_branch_label', 'endBranchLabel'),
     ('category', 'lossCategory'),
     ('unit', 'unit'),
     ('deterministic', 'deterministic'),
+    # timespan is for non-deterministic loss maps
+    ('timespan', 'timeSpan'),
     # poe is for non-deterministic loss maps
     # enforced by a SQL constraint
-    ('poe', 'poe'),
+    ('poe', 'poE'),
 ]
 
 
@@ -364,6 +418,7 @@
           'riskResultID': 'test_rr_id',
           'lossMapID': 'test_lm_id',
           'deterministic': False,
+          'timespan': 1,
           'poe': 0.01,
           'endBranchLabel': 'test_ebl',
           'lossCategory': 'economic_loss',
@@ -425,11 +480,13 @@
                 ***assetID*** - the assetID
         """
         for loss, asset in values:
+
             kwargs = {
                 'loss_map_id': self.metadata.id,
                 'asset_ref': asset['assetID'],
                 'location': "POINT(%s %s)" % (site.longitude, site.latitude),
             }
+
             if self.metadata.deterministic:
                 kwargs.update({
                     'value': float(loss.get('mean_loss')),
@@ -440,6 +497,7 @@
                     'value': float(loss.get('value')),
                     'std_dev': 0.0,
                 })
+
             self.bulk_inserter.add_entry(**kwargs)
 
     def _insert_metadata(self, metadata):
@@ -454,6 +512,7 @@
             kwargs[key] = metadata.get(metadata_key)
 
         self.metadata = models.LossMap(**kwargs)
+
         self.metadata.save()
 
 
@@ -473,6 +532,7 @@
     :returns: None or an instance of
         :py:class:`output.risk.LossMapXMLWriter` or
         :py:class:`output.risk.LossMapDBWriter`
+        :py:class:`output.risk.LossMapNonDeterministicXMLWriter`
     """
     writers = []
 
@@ -483,9 +543,7 @@
         if deterministic:
             writers.append(LossMapXMLWriter(nrml_path))
         else:
-            # No XML schema for non-deterministic maps yet (see bug 805434)
-            pass
-
+            writers.append(LossMapNonDeterministicXMLWriter(nrml_path))
     return writer.compose_writers(writers)
 
 
--- a/openquake/risk/common.py
+++ b/openquake/risk/common.py
@@ -22,6 +22,7 @@
 or loss curves.
 """
 
+from collections import OrderedDict
 from numpy import mean
 
 from openquake import shapes
@@ -37,14 +38,16 @@
     Return zero if the given PoE is greater than the
     highest PoE defined.
     """
+    # dups in the curve have to be skipped
+    loss_curve = shapes.Curve(unique_curve(curve))
 
-    if curve.ordinate_out_of_bounds(probability):
-        if probability < curve.y_values[-1]:
-            return curve.x_values[-1]
+    if loss_curve.ordinate_out_of_bounds(probability):
+        if probability < loss_curve.y_values[-1]:
+            return loss_curve.x_values[-1]
         else:
             return 0.0
 
-    return curve.abscissa_for(probability)
+    return loss_curve.abscissa_for(probability)
 
 
 def compute_loss_curve(loss_ratio_curve, asset):
@@ -107,3 +110,13 @@
         data.append(element)
 
     return data
+
+
+def unique_curve(curve):
+    """ extracts unique values from a curve """
+    seen = OrderedDict()
+
+    for ordinate, abscissa in zip(curve.ordinates, curve.abscissae):
+        seen[ordinate] = abscissa
+
+    return zip(seen.values(), seen.keys())
--- a/openquake/risk/job/classical_psha.py
+++ b/openquake/risk/job/classical_psha.py
@@ -35,7 +35,6 @@
 from openquake.risk.common import  compute_loss_curve
 from openquake.risk.job import general
 
-
 LOGGER = logs.LOG
 
 
@@ -58,7 +57,10 @@
         for task in celery_tasks:
             try:
                 # TODO(chris): Figure out where to put that timeout.
-                task.wait(timeout=None)
+                task.wait()
+                if not task.successful():
+                    raise Exception(task.result)
+
             except TimeoutError:
                 # TODO(jmc): Cancel and respawn this task
                 return
@@ -96,10 +98,18 @@
                             point.row, point.column)
             for asset in kvs.get_list_json_decoded(asset_key):
                 LOGGER.debug("processing asset %s" % (asset))
+
                 loss_ratio_curve = self.compute_loss_ratio_curve(
                     point, asset, hazard_curve)
 
-                self.compute_loss_curve(point, loss_ratio_curve, asset)
+                if loss_ratio_curve:
+                    loss_curve = self.compute_loss_curve(point,
+                            loss_ratio_curve, asset)
+
+                    for loss_poe in general.conditional_loss_poes(self.params):
+                        general.compute_conditional_loss(self.job_id,
+                                point.column, point.row, loss_curve, asset,
+                                loss_poe)
 
         return True
 
@@ -126,6 +136,8 @@
 
         kvs.set(loss_key, loss_curve.to_json())
 
+        return loss_curve
+
     def compute_loss_ratio_curve(self, point, asset, hazard_curve):
         """ Computes the loss ratio curve and stores in kvs
             the curve itself
--- a/openquake/risk/job/general.py
+++ b/openquake/risk/job/general.py
@@ -33,6 +33,7 @@
 from openquake.output import risk as risk_output
 from openquake.parser import exposure
 from openquake.parser import vulnerability
+from openquake.risk import common
 from openquake.utils.tasks import check_job_status
 
 from celery.decorators import task
@@ -82,7 +83,8 @@
             if writer:
                 metadata = {
                     "deterministic": False,
-                    "poe": loss_poe,
+                    "timeSpan": self.params["INVESTIGATION_TIME"],
+                    "poE": loss_poe,
                 }
 
                 writer.serialize(
@@ -90,6 +92,7 @@
                     + self.asset_losses_per_site(
                         loss_poe,
                         self.grid_assets_iterator(self.region.grid)))
+                LOG.info('Loss Map is at: %s' % path)
 
     return output_writer
 
@@ -102,6 +105,22 @@
         "CONDITIONAL_LOSS_POE", "").split()]
 
 
+def compute_conditional_loss(job_id, col, row, loss_curve, asset, loss_poe):
+    """Compute the conditional loss for a loss curve and Probability of
+    Exceedance (PoE)."""
+
+    loss_conditional = common.compute_conditional_loss(
+        loss_curve, loss_poe)
+
+    key = kvs.tokens.loss_key(
+            job_id, row, col, asset["assetID"], loss_poe)
+
+    LOG.debug("Conditional loss is %s, write to key %s" %
+            (loss_conditional, key))
+
+    kvs.set(key, loss_conditional)
+
+
 @task
 def compute_risk(job_id, block_id, **kwargs):
     """ A task for computing risk, calls the mixed in compute_risk method """
@@ -271,9 +290,11 @@
         for point, asset in assets_iterator:
             key = kvs.tokens.loss_key(self.job_id, point.row, point.column,
                     asset["assetID"], loss_poe)
+
             loss_value = kvs.get(key)
             LOG.debug("Loss for asset %s at %s %s is %s" %
                 (asset["assetID"], asset['lon'], asset['lat'], loss_value))
+
             if loss_value:
                 risk_site = shapes.Site(asset['lon'], asset['lat'])
                 loss = {
--- a/openquake/risk/job/probabilistic.py
+++ b/openquake/risk/job/probabilistic.py
@@ -31,7 +31,6 @@
 from openquake import logs
 from openquake import shapes
 
-from openquake.risk import common
 from openquake.risk import probabilistic_event_based as prob
 from openquake.parser import vulnerability
 
@@ -212,8 +211,9 @@
                         point.column, point.row, loss_ratio_curve, asset)
 
                     for loss_poe in general.conditional_loss_poes(self.params):
-                        self.compute_conditional_loss(point.column, point.row,
-                                loss_curve, asset, loss_poe)
+                        general.compute_conditional_loss(self.job_id,
+                                point.column, point.row, loss_curve, asset,
+                                loss_poe)
 
         return aggregate_curve.losses
 
@@ -237,21 +237,6 @@
         return prob.compute_loss_ratios(
             vuln_function, gmf_slice, epsilon_provider, asset)
 
-    def compute_conditional_loss(self, col, row, loss_curve, asset, loss_poe):
-        """Compute the conditional loss for a loss curve and Probability of
-        Exceedance (PoE)."""
-
-        loss_conditional = common.compute_conditional_loss(
-            loss_curve, loss_poe)
-
-        key = kvs.tokens.loss_key(
-                self.job_id, row, col, asset["assetID"], loss_poe)
-
-        LOGGER.debug("Conditional loss is %s, write to key %s" %
-                (loss_conditional, key))
-
-        kvs.set(key, loss_conditional)
-
     def compute_loss_ratio_curve(
             self, col, row, asset, gmf_slice, loss_ratios):
         """Compute the loss ratio curve for a single asset."""
--- a/openquake/settings.py
+++ b/openquake/settings.py
@@ -23,6 +23,9 @@
 from openquake.utils import config
 
 
+DB_SECTION = config.get_section('database')
+
+
 def _db_cfg(db_name):
     """
     Helper method to create db config items for the various roles and schemas.
@@ -42,34 +45,34 @@
 
 
     """
-    db_section = config.get_section('database')
 
     return dict(
         ENGINE='django.contrib.gis.db.backends.postgis',
-        NAME=db_section.get('name', 'openquake'),
-        USER=db_section.get('%s_user' % db_name, 'openquake'),
-        PASSWORD=db_section.get('%s_password' % db_name, ''),
-        HOST=db_section.get('host', ''),
-        PORT=db_section.get('port', ''),
+        NAME=DB_SECTION.get('name', 'openquake'),
+        USER=DB_SECTION.get('%s_user' % db_name, 'openquake'),
+        PASSWORD=DB_SECTION.get('%s_password' % db_name, ''),
+        HOST=DB_SECTION.get('host', ''),
+        PORT=DB_SECTION.get('port', ''),
     )
 
 
 _DB_NAMES = (
     'admin',
-    'eqcat_read',
-    'eqcat_write',
     'job_init',
     'job_superv',
     'oqmif',
     'reslt_writer',
 )
+
 DATABASES = dict((db, _db_cfg(db)) for db in _DB_NAMES)
+
+DEFAULT_USER = 'admin'
 # We need a 'default' database to make Django happy:
 DATABASES['default'] = {
     'ENGINE': 'django.db.backends.postgresql_psycopg2',
     'NAME': 'openquake',
-    'USER': 'openquake',
-    'PASSWORD': '',
+    'USER': DB_SECTION.get('%s_user' % DEFAULT_USER, 'oq_admin'),
+    'PASSWORD': DB_SECTION.get('%s_password' % DEFAULT_USER, 'openquake'),
     'HOST': '',
     'PORT': '',
 }
--- a/openquake/shapes.py
+++ b/openquake/shapes.py
@@ -17,7 +17,6 @@
 # version 3 along with OpenQuake.  If not, see
 # <http://www.gnu.org/licenses/lgpl-3.0.txt> for a copy of the LGPLv3 License.
 
-
 """Collection of base classes for processing spatially-related data."""
 
 import hashlib
@@ -29,6 +28,7 @@
 from numpy import zeros
 from numpy import empty
 from numpy import allclose
+from numpy import sin, cos, arctan2, sqrt, radians
 
 from shapely import geometry
 from scipy.interpolate import interp1d
@@ -876,3 +876,31 @@
     ewkt %= (', '.join(vertices), vertices[0])
 
     return ewkt
+
+
+def hdistance(site1, site2):
+    """Compute the great circle surface distance between two points
+    using the Haversine formula.
+
+    :param site1: first point
+    :type site1: :py:class:`shapes.Site`
+    :param site2: second point
+    :type site2: :py:class:`shapes.Site`
+    :returns: the distance between the two points in km
+    :rtype: float
+    """
+
+    lat1 = radians(site1.latitude)
+    lat2 = radians(site2.latitude)
+
+    lon1 = radians(site1.longitude)
+    lon2 = radians(site2.longitude)
+
+    dlon = lon2 - lon1
+    dlat = lat2 - lat1
+
+    a = (sin(dlat / 2)) ** 2 + cos(lat1) * cos(lat2) * (sin(dlon / 2.0)) ** 2
+    c = 2.0 * arctan2(sqrt(a), sqrt(1.0 - a))
+
+    # earth's mean radius
+    return 6371.0072 * c
--- a/openquake/utils/db/loader.py
+++ b/openquake/utils/db/loader.py
@@ -27,9 +27,6 @@
 """
 
 
-import csv
-import datetime
-
 import numpy
 
 from openquake import java
@@ -406,96 +403,3 @@
                       input_id=self.input_id))
 
         return results
-
-
-class CsvModelLoader(object):
-    """
-        Csv Model Loader which gets data from a particular CSV source and
-        "serializes" the data to the database
-    """
-    def __init__(self, src_model_path):
-        """
-            :param src_model_path: path to a source model file
-            :type src_model_path: str
-        """
-
-        self.src_model_path = src_model_path
-        self.csv_reader = None
-        self.csv_fd = open(self.src_model_path, 'r')
-
-    def _read_model(self):
-        """
-            Just initializes the csv DictReader
-        """
-        self.csv_reader = csv.DictReader(self.csv_fd, delimiter=',')
-
-    def serialize(self):
-        """
-            Reads the model
-            Writes to the db
-        """
-        self._read_model()
-        self._write_to_db(self.csv_reader)
-
-    # pylint: disable=R0201
-    def _date_to_timestamp(self, *args):
-        """
-            Quick helper function to have a timestamp for the
-            openquake postgres database
-        """
-
-        catalog_date = datetime.datetime(*args)
-        return catalog_date.strftime('%Y-%m-%d %H:%M:%S')
-
-    def _write_to_db(self, csv_reader):
-        """
-            :param csv_reader: DictReader instance
-            :type csv_reader: DictReader object `csv.DictReader`
-        """
-
-        mags = ['mb_val', 'mb_val_error',
-            'ml_val', 'ml_val_error',
-            'ms_val', 'ms_val_error',
-            'mw_val', 'mw_val_error']
-
-        for row in csv_reader:
-
-            timestamp = self._date_to_timestamp(int(row['year']),
-                int(row['month']), int(row['day']), int(row['hour']),
-                int(row['minute']), int(row['second']))
-
-            surface = models.Surface(semi_minor=row['semi_minor'],
-                semi_major=row['semi_major'],
-                strike=row['strike'])
-            surface.save()
-
-            for mag in mags:
-                row[mag] = row[mag].strip()
-
-                # if m*val* are empty or a series of blank spaces, we assume
-                # that the val is -999 for convention (ask Graeme if we want to
-                # change this)
-                if len(row[mag]) == 0:
-                    row[mag] = None
-                else:
-                    row[mag] = float(row[mag])
-
-            magnitude = models.Magnitude(mb_val=row['mb_val'],
-                                mb_val_error=row['mb_val_error'],
-                                ml_val=row['ml_val'],
-                                ml_val_error=row['ml_val_error'],
-                                ms_val=row['ms_val'],
-                                ms_val_error=row['ms_val_error'],
-                                mw_val=row['mw_val'],
-                                mw_val_error=row['mw_val_error'])
-            magnitude.save()
-
-            wkt = 'SRID=4326;POINT(%s %s)' % (
-                row['longitude'], row['latitude'])
-            catalog = models.Catalog(owner_id=1, time=timestamp,
-                surface=surface, eventid=row['eventid'],
-                agency=row['agency'], identifier=row['identifier'],
-                time_error=row['time_error'], depth=row['depth'],
-                depth_error=row['depth_error'], magnitude=magnitude,
-                point=wkt)
-            catalog.save()
--- a/openquake/utils/tasks.py
+++ b/openquake/utils/tasks.py
@@ -31,14 +31,6 @@
 from openquake import logs
 
 
-class WrongTaskParameters(Exception):
-    """The user specified wrong paramaters for the celery task function."""
-
-
-class TaskFailed(Exception):
-    """At least on (sub)task failed."""
-
-
 def distribute(cardinality, the_task, (name, data), other_args=None,
                flatten_results=False):
     """Runs `the_task` in a task set with the given `cardinality`.
@@ -81,7 +73,11 @@
 
     subtasks = []
 
+    logs.HAZARD_LOG.info("cardinality: %s" % cardinality)
+
     data_length = len(data)
+    logs.HAZARD_LOG.info("data_length: %s" % data_length)
+
     start = 0
     end = chunk_size = int(data_length / float(cardinality))
     if chunk_size == 0:
@@ -90,6 +86,8 @@
         cardinality = data_length if data_length > 0 else 1
         end = chunk_size = 1
 
+    logs.HAZARD_LOG.info("chunk_size: %s" % chunk_size)
+
     for _ in xrange(cardinality - 1):
         data_portion = data[start:end]
         subtask = the_task.subtask(**kwargs(data_portion))
@@ -101,6 +99,8 @@
     subtask = the_task.subtask(**kwargs(data_portion))
     subtasks.append(subtask)
 
+    logs.HAZARD_LOG.info("#subtasks: %s" % len(subtasks))
+
     # At this point we have created all the subtasks and each one got a
     # portion of the data that is to be processed. Now we will create and run
     # the task set.
@@ -129,6 +129,8 @@
         know.
     :raises TaskFailed: When at least one subtask fails (raises an exception).
     """
+    logs.HAZARD_LOG.info("cardinality: %s" % cardinality)
+
     assert isinstance(kwargs, dict), "Parameters must be passed in a dict."
     subtasks = []
     for tidx in xrange(cardinality):
@@ -138,6 +140,8 @@
         subtask = the_task.subtask(**task_args)
         subtasks.append(subtask)
 
+    logs.HAZARD_LOG.info("#subtasks: %s" % len(subtasks))
+
     # At this point we have created all the subtasks.
     the_results = _handle_subtasks(subtasks, flatten_results)
     return the_results
@@ -161,18 +165,12 @@
     # Wait for all subtasks to complete.
     while not result.ready():
         time.sleep(0.25)
-    try:
-        the_results = result.join()
-    except TypeError, exc:
-        raise WrongTaskParameters(exc.args[0])
-    except Exception, exc:
-        # At least one subtask failed.
-        raise TaskFailed(exc.args[0])
-
-    if flatten_results:
-        if the_results:
-            if isinstance(the_results, list) or isinstance(the_results, tuple):
-                the_results = list(itertools.chain(*the_results))
+
+    the_results = result.join()
+
+    if flatten_results and the_results:
+        if isinstance(the_results, list) or isinstance(the_results, tuple):
+            the_results = list(itertools.chain(*the_results))
 
     return the_results
 
--- a/openquake/xml.py
+++ b/openquake/xml.py
@@ -75,6 +75,7 @@
 RISK_LOSS_MAP_LOSS_CONTAINER_TAG = "%sloss" % NRML
 RISK_LOSS_MAP_MEAN_LOSS_TAG = "%smean" % NRML
 RISK_LOSS_MAP_STANDARD_DEVIATION_TAG = "%sstdDev" % NRML
+RISK_LOSS_MAP_VALUE = "%svalue" % NRML
 RISK_LOSS_MAP_LOSS_CATEGORY_ATTR = "lossCategory"
 RISK_LOSS_MAP_UNIT_ATTR = "unit"
 RISK_LOSS_MAP_ASSET_REF_ATTR = "assetRef"
@@ -103,7 +104,7 @@
         self.expected_tag = expected_tag
 
     _HUMANIZE_FILE = {
-        'logicTreeSet': 'logic tree',
+        'logicTree': 'logic tree',
         'sourceModel': 'source model',
         'exposurePortfolio': 'exposure portfolio',
         'vulnerabilityModel': 'vulnerability model',
